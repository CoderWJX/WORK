Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 16, 'max_epochs': 100, 'learning_rate': 0.0015, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_loss', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 16, 'max_epochs': 100, 'learning_rate': 0.0015, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_loss', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False, 'dataset_extra_fixed_fields': {'r_max': 6.0}, 'validation_dataset_extra_fixed_fields': {'r_max': 6.0}, 'dataset_config': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml', 'metrics_config': PosixPath('/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml'), 'base_model_file': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/best_model.pth', 'output_fields': []}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
RescaleOutput(
  (model): GradientOutput(
    (func): SequentialGraphNetwork(
      (one_hot): OneHotAtomEncoding()
      (radial_basis): RadialBasisEdgeEncoding(
        (basis): NormalizedBasis(
          (basis): BesselBasis()
        )
        (cutoff): PolynomialCutoff()
      )
      (spharm): SphericalHarmonicEdgeAttrs(
        (sh): SphericalHarmonics()
      )
      (allegro): Allegro_Module(
        (latents): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (env_embed_mlps): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (tps): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (linears): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (env_linears): ModuleList(
          (0): Identity()
          (1): Identity()
          (2): Identity()
        )
        (_env_weighter): MakeWeightedChannels()
        (final_latent): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng): ScalarMLP(
        (_module): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng_sum): EdgewiseEnergySum()
      (per_species_rescale): PerSpeciesScaleShift()
      (total_energy_sum): AtomwiseReduce()
    )
  )
)
Number of weights: 43096
! Starting training ...

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      0    51         1.63         1.03        0.596         1.39          153         1.48


  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Initial Validation          0   14.451   0.0015         1.19        0.824         2.01         1.51         91.5         1.66
Wall time: 14.450951393926516
! Best model        0    2.012

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1   100        0.448         0.44      0.00815        0.895         8.66        0.147
      1   200        0.344        0.326       0.0174        0.832         13.5        0.228
      1   300        0.267        0.262      0.00533        0.717          7.2        0.112
      1   400        0.199        0.192      0.00716        0.633         5.92         0.14
      1   401        0.242        0.233      0.00907        0.741         8.51        0.177

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1    51        0.214        0.211      0.00311        0.664         6.69       0.0747


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               1   90.901   0.0015          0.4        0.017        0.416         0.85         10.3        0.167
! Validation          1   90.901   0.0015        0.215      0.00366        0.218        0.655         6.39       0.0886
Wall time: 90.90116307814606
! Best model        1    0.218

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2   100        0.148        0.146      0.00228         0.56         5.72        0.078
      2   200        0.183        0.181      0.00258        0.618         4.04       0.0873
      2   300        0.162        0.155      0.00645        0.549         6.47        0.119
      2   400        0.164        0.162      0.00281        0.592         8.97       0.0828
      2   401        0.131        0.129       0.0017        0.537         2.97       0.0591

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2    51        0.171         0.17       0.0016        0.591         4.64        0.052


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               2  149.594   0.0015        0.186      0.00373         0.19        0.605         5.72       0.0903
! Validation          2  149.594   0.0015         0.16      0.00266        0.163        0.572         5.24       0.0779
Wall time: 149.59455800708383
! Best model        2    0.163

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3   100        0.182         0.18      0.00148        0.614         4.25       0.0634
      3   200        0.153        0.152      0.00128        0.539         3.02       0.0585
      3   300        0.134        0.131      0.00315        0.519         4.92        0.095
      3   400        0.109        0.106      0.00272        0.465         3.82       0.0785
      3   401        0.109        0.109     9.11e-05        0.512        0.886       0.0185

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3    51        0.131         0.13      0.00112        0.516         6.06       0.0594


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               3  206.097   0.0015        0.132       0.0032        0.135        0.514         5.13       0.0825
! Validation          3  206.097   0.0015         0.12      0.00124        0.122        0.497         3.59       0.0524
Wall time: 206.09776078001596
! Best model        3    0.122

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4   100        0.113        0.113     0.000323        0.484          1.9       0.0271
      4   200        0.137        0.129      0.00846        0.521         15.1        0.166
      4   300        0.117        0.116     0.000817        0.454         2.45       0.0514
      4   400       0.0931       0.0923     0.000754        0.431          2.2       0.0413
      4   401       0.0725       0.0702      0.00229        0.405         3.24       0.0675

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4    51        0.109        0.108     0.000422        0.469         3.24       0.0347


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               4  263.372   0.0015        0.106      0.00342         0.11        0.464          4.9       0.0794
! Validation          4  263.372   0.0015        0.101      0.00125        0.102        0.455         3.17       0.0503
Wall time: 263.37254849192686
! Best model        4    0.102

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5   100       0.0892       0.0886     0.000665        0.428         1.98       0.0427
      5   200       0.0544       0.0541     0.000263        0.331         1.14       0.0291
      5   300       0.0761       0.0756     0.000477        0.401         2.18       0.0345
      5   400       0.0753        0.074      0.00122        0.396         3.77       0.0503
      5   401       0.0594       0.0577      0.00173        0.364         3.64       0.0758

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5    51       0.0964       0.0961     0.000248        0.448         1.82       0.0253


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               5  320.170   0.0015         0.09      0.00173       0.0917        0.428         3.73       0.0601
! Validation          5  320.170   0.0015       0.0881      0.00152       0.0896        0.426         3.14       0.0529
Wall time: 320.16991101391613
! Best model        5    0.090

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6   100       0.0915         0.09      0.00151         0.43         4.58       0.0459
      6   200        0.104       0.0999      0.00451        0.433         7.59         0.12
      6   300       0.0747       0.0744     0.000344        0.394         1.42       0.0283
      6   400       0.0807       0.0798     0.000903        0.407         2.89       0.0458
      6   401        0.139        0.138      0.00144        0.542         7.65       0.0728

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6    51       0.0815       0.0796      0.00194        0.412         8.24        0.079


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               6  377.359   0.0015       0.0821      0.00213       0.0842        0.409         4.17       0.0676
! Validation          6  377.359   0.0015       0.0765       0.0025        0.079        0.397         4.74       0.0851
Wall time: 377.3591313390061
! Best model        6    0.079

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7   100       0.0762       0.0749      0.00121        0.401         2.85       0.0515
      7   200       0.0684       0.0678     0.000633        0.378         2.86       0.0412
      7   300       0.0686       0.0676        0.001         0.37          2.5       0.0354
      7   400       0.0866        0.085      0.00159         0.42         5.18       0.0696
      7   401       0.0623       0.0603      0.00194        0.353         2.97       0.0831

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7    51       0.0742       0.0739     0.000266        0.399         2.27       0.0247


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               7  435.861   0.0015       0.0745      0.00165       0.0761         0.39         3.64       0.0592
! Validation          7  435.861   0.0015       0.0684     0.000579        0.069        0.376         2.07       0.0316
Wall time: 435.8608985969331
! Best model        7    0.069

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8   100       0.0838       0.0813      0.00256        0.414          5.2       0.0889
      8   200        0.081       0.0773      0.00366        0.402         6.83        0.111
      8   300       0.0653       0.0634      0.00181        0.354         4.01       0.0777
      8   400       0.0619       0.0613     0.000581        0.361            2       0.0351
      8   401       0.0439       0.0398      0.00412        0.292         5.95        0.124

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8    51       0.0698       0.0693     0.000532        0.387         3.93       0.0373


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               8  492.020   0.0015       0.0688      0.00203       0.0709        0.375         4.08       0.0663
! Validation          8  492.020   0.0015       0.0656      0.00069       0.0663         0.37         2.39       0.0385
Wall time: 492.02063873806037
! Best model        8    0.066

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9   100       0.0674        0.067     0.000387        0.376         3.21       0.0308
      9   200       0.0411       0.0407     0.000406        0.286            2       0.0292
      9   300       0.0683       0.0607      0.00755        0.353         7.29       0.0877
      9   400       0.0619       0.0613     0.000635        0.348         2.27       0.0347
      9   401       0.0626       0.0622     0.000449        0.385         1.87       0.0389

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9    51       0.0658       0.0652     0.000606        0.374         3.87       0.0385


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               9  550.489   0.0015       0.0639      0.00107        0.065        0.361         2.96       0.0469
! Validation          9  550.489   0.0015       0.0608      0.00133       0.0621        0.354         3.21       0.0563
Wall time: 550.4896567740943
! Best model        9    0.062

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10   100        0.067       0.0662     0.000812        0.357         4.01       0.0458
     10   200       0.0449       0.0442     0.000685         0.31         2.28       0.0451
     10   300        0.126        0.123      0.00296         0.49         5.55       0.0872
     10   400       0.0545       0.0539      0.00063        0.335         1.94       0.0404
     10   401       0.0581       0.0575     0.000628        0.342         3.46       0.0484

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10    51       0.0693       0.0679      0.00138         0.38         6.84       0.0634


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              10  607.426   0.0015       0.0632      0.00121       0.0644        0.358         2.99       0.0485
! Validation         10  607.426   0.0015       0.0651      0.00213       0.0672        0.366         4.35       0.0777
Wall time: 607.4267955359537

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11   100       0.0503       0.0501     0.000242        0.321         1.18       0.0262
     11   200       0.0507       0.0496      0.00109         0.32         2.59       0.0541
     11   300       0.0624        0.062     0.000424        0.365         2.66       0.0274
     11   400       0.0752       0.0745     0.000669        0.374         2.93       0.0417
     11   401       0.0264       0.0263     0.000106        0.248        0.954       0.0199

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11    51       0.0599       0.0593     0.000672        0.359         4.04       0.0388


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              11  664.809   0.0015       0.0579      0.00101        0.059        0.344          2.9       0.0464
! Validation         11  664.809   0.0015       0.0566     0.000747       0.0573        0.343         2.55       0.0425
Wall time: 664.8097484989557
! Best model       11    0.057

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12   100       0.0493       0.0486     0.000706        0.326         2.14       0.0395
     12   200       0.0503       0.0499     0.000398        0.318         1.29       0.0308
     12   300       0.0517       0.0513     0.000423        0.317         1.69        0.032
     12   400       0.0692       0.0686     0.000545        0.373         2.43       0.0405
     12   401       0.0537       0.0511      0.00264        0.321         2.74       0.0855

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12    51       0.0619       0.0616     0.000261        0.363         1.89       0.0231


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              12  723.119   0.0015       0.0569      0.00105        0.058        0.341         2.95        0.047
! Validation         12  723.119   0.0015       0.0574      0.00105       0.0584        0.344         2.58       0.0459
Wall time: 723.1195794481318

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13   100       0.0525       0.0517     0.000774        0.327         1.64       0.0393
     13   200         0.06       0.0596     0.000407        0.348         2.35       0.0351
     13   300       0.0562       0.0556     0.000629         0.34            3       0.0402
     13   400       0.0581        0.057      0.00102        0.352         3.93       0.0522
     13   401        0.123        0.123     0.000423        0.506         2.37       0.0367

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13    51       0.0647       0.0603      0.00441        0.364         12.5        0.124


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              13  780.403   0.0015       0.0552      0.00098       0.0562        0.336         2.83       0.0454
! Validation         13  780.403   0.0015         0.06      0.00444       0.0645        0.355         6.89        0.122
Wall time: 780.4037013130728

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14   100        0.049       0.0479      0.00109        0.312         2.36       0.0488
     14   200       0.0557       0.0552      0.00052        0.321         2.14       0.0383
     14   300       0.0533       0.0525     0.000806        0.322         2.49        0.046
     14   400       0.0501       0.0495     0.000627        0.317         2.23       0.0421
     14   401        0.039       0.0379      0.00105          0.3         5.98       0.0623

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14    51       0.0561       0.0559     0.000195        0.349         1.79       0.0225


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              14  838.060   0.0015       0.0542      0.00125       0.0555        0.333         3.22       0.0526
! Validation         14  838.060   0.0015       0.0535     0.000364       0.0539        0.332         1.62       0.0228
Wall time: 838.0602766140364
! Best model       14    0.054

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15   100       0.0566       0.0564     0.000174        0.338         1.92         0.02
     15   200       0.0414       0.0408     0.000582        0.291         2.11       0.0359
     15   300       0.0587       0.0562      0.00253        0.332         3.82       0.0511
     15   400        0.058       0.0568       0.0012        0.349         3.27       0.0487
     15   401       0.0247       0.0246     0.000166        0.226        0.859       0.0181

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15    51       0.0523       0.0518     0.000528        0.336         3.25       0.0374


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              15  895.820   0.0015       0.0521     0.000987       0.0531        0.326         2.84        0.046
! Validation         15  895.820   0.0015       0.0498     0.000496       0.0503         0.32          2.1       0.0302
Wall time: 895.8205777220428
! Best model       15    0.050

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16   100       0.0535       0.0531     0.000455        0.326         2.36       0.0347
     16   200       0.0438       0.0425      0.00127          0.3         3.31       0.0441
     16   300       0.0665       0.0613      0.00519        0.347         8.15        0.133
     16   400       0.0466       0.0464     0.000199        0.299         1.49       0.0233
     16   401      0.00588      0.00583     4.58e-05        0.111        0.366       0.0131

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16    51       0.0528       0.0524     0.000434        0.336         3.49       0.0343


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              16  953.065   0.0015       0.0502      0.00156       0.0518        0.321         3.42       0.0567
! Validation         16  953.065   0.0015       0.0496     0.000514       0.0501        0.321         2.17       0.0333
Wall time: 953.0651498429943
! Best model       16    0.050

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17   100       0.0619       0.0605       0.0014        0.344         4.24       0.0679
     17   200       0.0505        0.048      0.00243        0.314         5.48       0.0937
     17   300       0.0435       0.0433     0.000197        0.302         1.04       0.0237
     17   400       0.0435       0.0433     0.000155        0.301          1.4       0.0202
     17   401       0.0369       0.0366     0.000318        0.262         1.31       0.0298

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17    51       0.0516       0.0508      0.00074        0.332         4.47       0.0448


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              17 1011.063   0.0015       0.0486      0.00141         0.05        0.316         3.37       0.0547
! Validation         17 1011.063   0.0015       0.0468     0.000754       0.0476         0.31         2.75       0.0418
Wall time: 1011.0633420050144
! Best model       17    0.048

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18   100       0.0348       0.0345     0.000299        0.271         1.27       0.0267
     18   200        0.045       0.0441     0.000835        0.308         4.98       0.0476
     18   300       0.0503       0.0485       0.0018         0.32         3.26       0.0459
     18   400       0.0578       0.0576     0.000183        0.341         2.08       0.0212
     18   401       0.0248       0.0232      0.00165        0.212         2.94       0.0785

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18    51        0.049       0.0487     0.000346        0.322         3.01       0.0323


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              18 1070.085   0.0015       0.0467      0.00074       0.0474         0.31         2.44        0.039
! Validation         18 1070.085   0.0015       0.0456     0.000389        0.046        0.307          1.9       0.0279
Wall time: 1070.0849091841374
! Best model       18    0.046

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19   100       0.0371       0.0368      0.00028        0.278         1.32       0.0273
     19   200       0.0396       0.0379      0.00168        0.268         3.53       0.0751
     19   300       0.0479       0.0474     0.000525        0.316         3.74        0.041
     19   400       0.0383       0.0379     0.000361        0.287         1.68        0.025
     19   401       0.0453       0.0441      0.00122        0.311         5.28        0.054

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19    51       0.0485       0.0461      0.00246        0.315         9.05       0.0916


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              19 1127.158   0.0015       0.0453     0.000711       0.0461        0.304         2.38       0.0383
! Validation         19 1127.158   0.0015        0.045      0.00266       0.0477        0.304         5.15       0.0923
Wall time: 1127.1580089600757

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20   100       0.0379       0.0376     0.000313         0.27         1.47       0.0253
     20   200       0.0399       0.0393     0.000649        0.284         2.11       0.0432
     20   300       0.0542       0.0528      0.00139        0.325          4.9       0.0639
     20   400       0.0478       0.0445      0.00333        0.309         7.07        0.107
     20   401       0.0681       0.0627      0.00545        0.337         23.4        0.143

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20    51       0.0443       0.0438     0.000529        0.308         3.83       0.0376


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              20 1185.427   0.0015       0.0453      0.00112       0.0464        0.304         3.01       0.0488
! Validation         20 1185.427   0.0015       0.0424     0.000461       0.0429        0.295         1.99        0.032
Wall time: 1185.4275576011278
! Best model       20    0.043

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21   100       0.0355       0.0346     0.000924        0.275         2.99        0.052
     21   200       0.0503       0.0491      0.00121        0.329         3.63       0.0621
     21   300       0.0425       0.0422     0.000252        0.296         1.56       0.0262
     21   400       0.0472       0.0465     0.000694        0.317         3.17       0.0423
     21   401       0.0057      0.00499     0.000708       0.0922         1.42       0.0508

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21    51       0.0475       0.0465     0.000949        0.318         5.07       0.0503


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              21 1243.280   0.0015       0.0443      0.00106       0.0454        0.301         2.96       0.0485
! Validation         21 1243.280   0.0015       0.0438      0.00134       0.0451        0.301         3.89       0.0621
Wall time: 1243.280788361095

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22   100        0.045       0.0448     0.000211        0.298         1.17       0.0242
     22   200       0.0483       0.0442      0.00401        0.308          6.2        0.114
     22   300       0.0391       0.0385     0.000592        0.278         1.99       0.0442
     22   400       0.0468       0.0461     0.000708        0.306         2.96       0.0366
     22   401        0.044       0.0431     0.000918        0.311         2.75       0.0573

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22    51       0.0499       0.0491     0.000802         0.33         5.04       0.0503


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              22 1300.634   0.0015       0.0444     0.000987       0.0454        0.301         2.77       0.0456
! Validation         22 1300.634   0.0015       0.0459      0.00117        0.047        0.307         3.46        0.055
Wall time: 1300.6342991539277

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23   100       0.0328       0.0323     0.000442        0.258         1.64        0.037
     23   200       0.0449       0.0442     0.000734        0.312         2.88       0.0483
     23   300       0.0382       0.0381     0.000113        0.283         1.49       0.0178
     23   400       0.0488       0.0482     0.000533        0.319         2.52       0.0414
     23   401       0.0186       0.0161      0.00251        0.177         3.71       0.0968

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23    51       0.0436       0.0432     0.000393        0.306         3.27       0.0333


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              23 1358.153   0.0015        0.042     0.000664       0.0427        0.292         2.36       0.0378
! Validation         23 1358.153   0.0015       0.0404     0.000735       0.0412        0.287         2.51       0.0411
Wall time: 1358.1536298941355
! Best model       23    0.041

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24   100        0.048        0.044      0.00408        0.301          7.1        0.121
     24   200       0.0377       0.0374     0.000337        0.285         2.05       0.0301
     24   300       0.0402         0.04     0.000203        0.287          1.3       0.0229
     24   400       0.0409       0.0404     0.000568        0.292         2.27       0.0401
     24   401         0.03       0.0298     0.000222        0.224         1.03       0.0284

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24    51        0.042       0.0418     0.000193        0.299         1.66       0.0193


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              24 1415.104   0.0015       0.0416     0.000981       0.0426        0.291         2.63        0.043
! Validation         24 1415.104   0.0015       0.0394     0.000488       0.0399        0.285         1.86       0.0323
Wall time: 1415.104432567954
! Best model       24    0.040

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25   100       0.0357       0.0353     0.000442        0.276         2.36        0.032
     25   200       0.0379       0.0374     0.000553        0.283         2.53       0.0403
     25   300       0.0531        0.047      0.00617        0.319         12.9        0.141
     25   400       0.0461       0.0458     0.000219        0.305         2.07       0.0254
     25   401       0.0715       0.0707      0.00076        0.369         2.51        0.044

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25    51       0.0528       0.0514      0.00136        0.335         6.92       0.0666


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              25 1472.250   0.0015       0.0438      0.00143       0.0452        0.297         3.04       0.0496
! Validation         25 1472.250   0.0015        0.049      0.00133       0.0503        0.317          3.8       0.0576
Wall time: 1472.2504618209787

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26   100       0.0349       0.0348     8.07e-05        0.268        0.718        0.014
     26   200       0.0395       0.0389     0.000622        0.275         3.28       0.0409
     26   300       0.0401       0.0396     0.000533         0.28         2.42       0.0284
     26   400       0.0448       0.0441     0.000699        0.303         2.89       0.0458
     26   401       0.0306       0.0303     0.000387        0.255         1.61       0.0341

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26    51       0.0423       0.0415     0.000811          0.3         5.12       0.0498


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              26 1531.469   0.0015       0.0408     0.000587       0.0414        0.288         2.21       0.0355
! Validation         26 1531.469   0.0015       0.0407     0.000737       0.0415         0.29         2.73       0.0464
Wall time: 1531.4695210480131

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27   100       0.0406       0.0387      0.00182        0.286         4.89       0.0703
     27   200       0.0544       0.0533      0.00112        0.328         2.49       0.0332
     27   300       0.0447       0.0443     0.000373        0.309         2.29       0.0308
     27   400       0.0449       0.0441     0.000812        0.296          2.8       0.0467
     27   401        0.131        0.131     0.000468        0.527          3.2       0.0317

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27    51       0.0479       0.0468      0.00107        0.315         6.18       0.0603


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              27 1588.827   0.0015         0.04     0.000652       0.0407        0.285         2.28       0.0373
! Validation         27 1588.827   0.0015       0.0429      0.00119       0.0441        0.297         3.42       0.0597
Wall time: 1588.8272866299376

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28   100       0.0367       0.0356      0.00111        0.273         3.75        0.058
     28   200       0.0511       0.0491        0.002        0.309         4.66       0.0785
     28   300       0.0399       0.0396     0.000304        0.286         1.63       0.0273
     28   400       0.0481       0.0473     0.000869         0.29         2.86       0.0511
     28   401       0.0281       0.0264      0.00171        0.247         6.32       0.0795

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28    51       0.0437       0.0434     0.000222        0.307         2.11       0.0238


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              28 1646.800   0.0015       0.0396      0.00068       0.0403        0.284         2.34       0.0374
! Validation         28 1646.800   0.0015       0.0403     0.000375       0.0406        0.287         1.66       0.0258
Wall time: 1646.8004364320077

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29   100       0.0483       0.0467      0.00161        0.276         2.85       0.0356
     29   200       0.0402       0.0398     0.000402        0.287         1.71       0.0333
     29   300       0.0352       0.0339      0.00125        0.266         2.81       0.0558
     29   400       0.0364       0.0363     0.000143        0.271         1.06       0.0184
     29   401       0.0579       0.0563      0.00163        0.339         5.07       0.0779

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29    51       0.0415       0.0408     0.000686        0.295         4.84        0.046


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              29 1704.177   0.0015       0.0387     0.000583       0.0393        0.281         2.19       0.0354
! Validation         29 1704.177   0.0015       0.0383     0.000563       0.0389         0.28         2.45       0.0398
Wall time: 1704.1778638139367
! Best model       29    0.039

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30   100       0.0498       0.0497     9.29e-05        0.315        0.999       0.0157
     30   200       0.0394       0.0391     0.000275        0.288         2.39       0.0287
     30   300       0.0356       0.0351     0.000484        0.265         1.59       0.0345
     30   400       0.0331       0.0329     0.000224        0.261         1.24       0.0218
     30   401       0.0689       0.0687      0.00023        0.358         1.76        0.029

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30    51       0.0407       0.0404     0.000339        0.296         2.76       0.0298


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              30 1760.572   0.0015        0.039     0.000472       0.0395        0.282            2       0.0318
! Validation         30 1760.572   0.0015       0.0392     0.000376       0.0396        0.285         1.83       0.0272
Wall time: 1760.5728383469395

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31   100       0.0338       0.0331     0.000669        0.267         2.49       0.0451
     31   200       0.0306       0.0304     0.000244        0.255        0.998       0.0237
     31   300       0.0566       0.0564      0.00015        0.274         1.17       0.0185
     31   400       0.0332       0.0331      9.2e-05        0.256        0.853       0.0158
     31   401       0.0383       0.0383     1.73e-05        0.289        0.348      0.00725

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31    51       0.0385       0.0382     0.000341        0.288         2.82       0.0295


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              31 1818.604   0.0015       0.0378     0.000483       0.0383        0.277         1.99       0.0324
! Validation         31 1818.604   0.0015       0.0368     0.000247       0.0371        0.274         1.47       0.0232
Wall time: 1818.604353416944
! Best model       31    0.037

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32   100       0.0421       0.0416     0.000555        0.274          2.2       0.0404
     32   200       0.0363       0.0361     0.000218        0.276         1.58       0.0234
     32   300       0.0337       0.0336     0.000166        0.259         1.01       0.0184
     32   400       0.0372       0.0369     0.000281        0.275         1.36       0.0276
     32   401        0.038       0.0377     0.000353        0.283         1.32       0.0276

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32    51       0.0395       0.0391     0.000404         0.29          3.5       0.0329


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              32 1877.813   0.0015       0.0376     0.000544       0.0381        0.276         2.07       0.0336
! Validation         32 1877.813   0.0015       0.0383     0.000488       0.0388         0.28         1.98       0.0343
Wall time: 1877.8129490420688

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33   100       0.0488       0.0485     0.000244        0.294         1.66        0.025
     33   200        0.043       0.0425     0.000533        0.299          3.7       0.0399
     33   300       0.0388       0.0386     0.000263        0.281         1.44       0.0268
     33   400        0.039       0.0388     0.000122        0.282         1.23       0.0158
     33   401       0.0555       0.0541      0.00148        0.353         5.82       0.0742

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33    51       0.0631       0.0605      0.00261        0.358         9.04       0.0904


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              33 1935.005   0.0015       0.0379      0.00077       0.0387        0.278          2.2       0.0359
! Validation         33 1935.005   0.0015       0.0591      0.00472       0.0638        0.351          5.8        0.111
Wall time: 1935.0052990459371

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34   100       0.0416       0.0412     0.000449        0.284         1.79       0.0334
     34   200       0.0442       0.0441     0.000141        0.307         1.13       0.0206
     34   300       0.0356       0.0355     0.000145        0.265        0.968       0.0186
     34   400       0.0438       0.0433     0.000511        0.298         2.23       0.0264
     34   401       0.0379       0.0374     0.000457        0.285         4.26       0.0405

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34    51       0.0378       0.0376     0.000205        0.285          2.4        0.025


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              34 1991.344   0.0015        0.037       0.0005       0.0375        0.274         2.04        0.033
! Validation         34 1991.344   0.0015       0.0367     0.000274        0.037        0.274         1.54       0.0257
Wall time: 1991.3446001999546
! Best model       34    0.037

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35   100       0.0435       0.0426     0.000957          0.3         3.52       0.0569
     35   200        0.034       0.0337      0.00029        0.265         1.17       0.0227
     35   300        0.048       0.0473     0.000677        0.293         1.75        0.042
     35   400       0.0296       0.0296     7.38e-05        0.244        0.843       0.0135
     35   401       0.0216       0.0214     0.000176        0.215        0.824        0.024

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35    51       0.0397       0.0394     0.000318        0.293         2.81       0.0301


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              35 2048.926   0.0015       0.0365     0.000486        0.037        0.273            2       0.0323
! Validation         35 2048.926   0.0015       0.0369     0.000473       0.0373        0.276         2.07       0.0348
Wall time: 2048.9262443899643

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36   100       0.0358       0.0344      0.00139        0.264         4.62       0.0707
     36   200        0.038       0.0376     0.000436        0.284         2.25       0.0374
     36   300       0.0306       0.0301     0.000461        0.242         2.02       0.0322
     36   400       0.0306       0.0303     0.000318        0.249         1.55       0.0295
     36   401        0.033       0.0326     0.000361        0.264         1.69       0.0351

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36    51        0.039       0.0386     0.000368        0.289         3.49       0.0334


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              36 2107.230   0.0015       0.0365     0.000604       0.0371        0.272         2.15        0.035
! Validation         36 2107.230   0.0015        0.036     0.000468       0.0365        0.273         2.19       0.0336
Wall time: 2107.2303324791137
! Best model       36    0.036

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37   100       0.0393       0.0389     0.000481        0.284         1.92       0.0357
     37   200       0.0387       0.0384     0.000273        0.283         2.06       0.0262
     37   300       0.0454       0.0453     0.000116        0.303         1.11       0.0168
     37   400       0.0295       0.0294     0.000131        0.244         1.01       0.0171
     37   401        0.023        0.023     4.54e-05         0.21        0.459      0.00984

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37    51       0.0407       0.0405     0.000286        0.296         2.97       0.0292


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              37 2164.782   0.0015       0.0356     0.000451       0.0361        0.269         1.97       0.0316
! Validation         37 2164.782   0.0015        0.037     0.000287       0.0373        0.276         1.69        0.026
Wall time: 2164.7818994079717

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38   100       0.0263       0.0243        0.002        0.216         6.87       0.0836
     38   200       0.0306         0.03     0.000573        0.248          1.9       0.0389
     38   300       0.0439       0.0428      0.00112        0.279         2.83       0.0421
     38   400       0.0551       0.0529      0.00219        0.316         3.41       0.0403
     38   401       0.0343       0.0343     8.79e-05        0.281         1.18       0.0177

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38    51       0.0367       0.0364     0.000266         0.28         2.44       0.0241


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              38 2221.824   0.0015        0.036     0.000706       0.0367         0.27         2.42       0.0399
! Validation         38 2221.824   0.0015       0.0346     0.000236       0.0349        0.265          1.5       0.0235
Wall time: 2221.82401244808
! Best model       38    0.035

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39   100       0.0313       0.0305     0.000739        0.256         2.81       0.0483
     39   200       0.0351       0.0347     0.000446        0.261         1.72       0.0372
     39   300       0.0396       0.0392     0.000426        0.251         1.71       0.0363
     39   400       0.0318       0.0314     0.000313        0.251         1.24       0.0271
     39   401       0.0341       0.0341     1.09e-05         0.27        0.166      0.00531

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39    51       0.0368        0.036     0.000821         0.28         5.19       0.0506


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              39 2278.895   0.0015       0.0357     0.000562       0.0363        0.269         2.15       0.0347
! Validation         39 2278.895   0.0015       0.0341     0.000625       0.0347        0.264         2.55       0.0427
Wall time: 2278.8958339560777
! Best model       39    0.035

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40   100       0.0243       0.0242     5.88e-05        0.223        0.499       0.0118
     40   200       0.0361        0.036     0.000131        0.268         1.14       0.0165
     40   300       0.0357       0.0356     0.000165        0.271         1.17        0.019
     40   400       0.0341       0.0333     0.000774        0.264         3.28       0.0481
     40   401       0.0389       0.0372      0.00169        0.287         3.78       0.0787

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40    51       0.0351       0.0345     0.000677        0.275          4.4       0.0443


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              40 2336.535   0.0015       0.0352      0.00053       0.0357        0.267         2.05       0.0337
! Validation         40 2336.535   0.0015       0.0331     0.000984       0.0341        0.259          3.3       0.0541
Wall time: 2336.5352894039825
! Best model       40    0.034

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41   100       0.0366       0.0358     0.000793        0.278         3.23       0.0431
     41   200       0.0355       0.0348     0.000716        0.272         3.73       0.0484
     41   300       0.0323       0.0318      0.00051        0.249          1.9       0.0382
     41   400       0.0254       0.0251     0.000262         0.22        0.993       0.0275
     41   401       0.0265       0.0257     0.000821        0.236         4.11       0.0551

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41    51       0.0351       0.0348     0.000323        0.274         2.68       0.0269


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              41 2393.659   0.0015       0.0347     0.000515       0.0353        0.266         2.07       0.0338
! Validation         41 2393.659   0.0015       0.0336     0.000261       0.0339        0.261         1.62       0.0257
Wall time: 2393.6589189539663
! Best model       41    0.034

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42   100        0.035       0.0348     0.000247        0.266         1.71       0.0273
     42   200       0.0293       0.0291     0.000226        0.246         1.21       0.0232
     42   300       0.0291       0.0285     0.000563        0.238         1.89        0.041
     42   400        0.033       0.0322     0.000771        0.256         2.56       0.0496
     42   401       0.0324       0.0317      0.00073        0.253         3.57       0.0522

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42    51       0.0343       0.0335     0.000745         0.27         4.71       0.0486


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              42 2451.002   0.0015       0.0338     0.000466       0.0342        0.262         1.96        0.032
! Validation         42 2451.002   0.0015       0.0336     0.000675       0.0342         0.26         2.52       0.0452
Wall time: 2451.00254576304

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43   100       0.0354       0.0353     9.06e-05        0.271        0.968       0.0141
     43   200       0.0497       0.0488     0.000914        0.311         3.19       0.0333
     43   300       0.0306       0.0301     0.000454        0.257         3.35       0.0384
     43   400       0.0281       0.0279     0.000171        0.242        0.931       0.0188
     43   401       0.0438       0.0438     1.75e-05         0.31        0.387      0.00807

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43    51       0.0331        0.033     0.000162        0.266         1.93       0.0198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              43 2508.059   0.0015       0.0335     0.000431        0.034        0.261         1.89       0.0306
! Validation         43 2508.059   0.0015       0.0324      0.00037       0.0327        0.256         1.72       0.0285
Wall time: 2508.0598760270514
! Best model       43    0.033

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44   100       0.0411        0.041     0.000134        0.285         1.35        0.019
     44   200       0.0313       0.0307     0.000515         0.25         1.63       0.0214
     44   300       0.0298       0.0297     0.000115        0.249         1.56       0.0179
     44   400       0.0264        0.026     0.000403        0.225         1.74       0.0367
     44   401       0.0385       0.0384      8.5e-05        0.296         1.44       0.0157

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44    51       0.0326       0.0325     9.73e-05        0.266         1.18       0.0148


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              44 2564.905   0.0015       0.0329     0.000335       0.0333        0.258         1.66        0.027
! Validation         44 2564.905   0.0015       0.0316     0.000136       0.0318        0.253            1       0.0142
Wall time: 2564.905528072035
! Best model       44    0.032

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45   100       0.0292        0.029     0.000135        0.242        0.856       0.0185
     45   200       0.0378       0.0362      0.00159        0.267         3.79        0.073
     45   300       0.0332        0.033     0.000275        0.262         2.93       0.0256
     45   400       0.0238       0.0238     6.01e-05        0.229        0.707       0.0115
     45   401       0.0222       0.0221     7.39e-05         0.19        0.611       0.0135

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45    51       0.0332       0.0331     9.84e-05        0.267         1.26       0.0148


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              45 2622.543   0.0015       0.0335     0.000559        0.034        0.261         2.09       0.0344
! Validation         45 2622.543   0.0015       0.0325     0.000165       0.0326        0.257         1.16       0.0166
Wall time: 2622.543318167096

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46   100       0.0351       0.0344     0.000706         0.26         2.05       0.0443
     46   200        0.028       0.0278      0.00019        0.243         1.43       0.0209
     46   300       0.0273        0.027     0.000272        0.225         1.24       0.0209
     46   400       0.0348       0.0346     0.000251        0.267         1.69       0.0271
     46   401       0.0148       0.0139     0.000947        0.165         1.71       0.0523

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46    51       0.0327       0.0325     0.000178        0.266          2.1        0.023


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              46 2679.260   0.0015        0.033     0.000442       0.0335        0.259         1.89       0.0308
! Validation         46 2679.260   0.0015       0.0316     0.000205       0.0318        0.253         1.38       0.0206
Wall time: 2679.260216824012

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47   100       0.0326       0.0325     0.000106        0.262         1.13       0.0172
     47   200       0.0401       0.0399     0.000122        0.289         1.34       0.0191
     47   300       0.0349       0.0346     0.000296        0.265         1.63       0.0296
     47   400       0.0413       0.0408     0.000488        0.285         3.19       0.0252
     47   401       0.0246       0.0245     5.06e-05        0.227        0.752       0.0135

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47    51       0.0317       0.0314     0.000248        0.262         2.51       0.0257


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              47 2736.026   0.0015       0.0324     0.000341       0.0327        0.256         1.69       0.0273
! Validation         47 2736.026   0.0015       0.0314     0.000325       0.0318        0.254         1.81       0.0261
Wall time: 2736.0264731359202

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48   100       0.0295       0.0292     0.000299        0.244         2.28       0.0303
     48   200       0.0351       0.0349     0.000155        0.269          1.1         0.02
     48   300       0.0351       0.0328      0.00232        0.263         4.59       0.0909
     48   400       0.0309       0.0306     0.000337        0.247         1.47       0.0295
     48   401       0.0747       0.0744     0.000333        0.386         2.17        0.033

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48    51       0.0338       0.0337     9.79e-05        0.272         1.54       0.0167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              48 2792.942   0.0015       0.0334     0.000495       0.0339        0.259         1.94       0.0319
! Validation         48 2792.942   0.0015       0.0333     0.000185       0.0335        0.261         1.21       0.0192
Wall time: 2792.941886167042

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49   100       0.0294       0.0293     7.07e-05        0.248        0.792       0.0145
     49   200       0.0244       0.0243     6.91e-05         0.22         1.23        0.013
     49   300       0.0367       0.0364     0.000271         0.27         1.41       0.0288
     49   400       0.0304       0.0303     9.32e-05        0.253         2.16       0.0159
     49   401        0.053       0.0514       0.0016        0.312         3.71       0.0774

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49    51        0.034       0.0338     0.000127        0.271         1.48        0.015


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              49 2850.985   0.0015       0.0325     0.000369       0.0329        0.257         1.72       0.0281
! Validation         49 2850.985   0.0015        0.034     0.000233       0.0342        0.264         1.34       0.0213
Wall time: 2850.9856684289407

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50   100       0.0227       0.0216      0.00109        0.213         3.66       0.0606
     50   200       0.0308       0.0304     0.000419        0.246         1.99       0.0329
     50   300       0.0337       0.0332     0.000484         0.26          2.3       0.0383
     50   400       0.0321        0.032     0.000121        0.257         1.25       0.0185
     50   401       0.0367       0.0365     0.000268        0.263         1.09       0.0308

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50    51       0.0354       0.0348      0.00055        0.276         2.85       0.0318


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              50 2908.694   0.0015       0.0326     0.000413        0.033        0.257         1.83       0.0299
! Validation         50 2908.694   0.0015       0.0338     0.000665       0.0345        0.264         1.98       0.0342
Wall time: 2908.6939755780622

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     51   100       0.0383       0.0374     0.000939        0.274         3.05       0.0559
     51   200       0.0316       0.0299      0.00169         0.25         4.89       0.0765
     51   300       0.0349       0.0346     0.000306        0.266         1.32       0.0248
     51   400       0.0489       0.0487     0.000181        0.297         1.37       0.0231
     51   401       0.0444       0.0444     4.03e-05        0.301         1.11       0.0107

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     51    51       0.0383       0.0382     6.49e-05        0.291        0.998       0.0121


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              51 2965.582   0.0015       0.0329     0.000465       0.0334        0.259         1.91       0.0315
! Validation         51 2965.582   0.0015       0.0354      0.00014       0.0355        0.269        0.975       0.0149
Wall time: 2965.5823417610954

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     52   100       0.0377       0.0374     0.000304        0.283         2.66       0.0255
     52   200       0.0297       0.0292     0.000536        0.255         2.22       0.0378
     52   300       0.0358       0.0351      0.00064        0.272          3.8       0.0421
     52   400       0.0387       0.0384     0.000273        0.283         1.54        0.022
     52   401       0.0451       0.0444     0.000713        0.315         4.16       0.0506

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     52    51        0.032       0.0318     0.000217        0.262         2.41       0.0242


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              52 3023.166   0.0015       0.0326     0.000647       0.0333        0.257         2.28       0.0377
! Validation         52 3023.166   0.0015       0.0314     0.000256       0.0316        0.253          1.6       0.0228
Wall time: 3023.1661931599956
! Best model       52    0.032

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     53   100       0.0253        0.025     0.000326        0.217         2.27       0.0317
     53   200       0.0311       0.0311     8.78e-05        0.251        0.783       0.0142
     53   300       0.0345       0.0342     0.000344        0.263         2.37       0.0261
     53   400       0.0373       0.0367     0.000552        0.276         2.45       0.0273
     53   401       0.0268       0.0268     8.07e-05        0.239        0.577       0.0166

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     53    51       0.0311       0.0309      0.00015         0.26         2.08       0.0209


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              53 3080.933   0.0015       0.0313     0.000343       0.0317        0.252          1.7       0.0273
! Validation         53 3080.933   0.0015         0.03      0.00041       0.0305        0.247         1.86       0.0308
Wall time: 3080.933763650013
! Best model       53    0.030

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     54   100       0.0305       0.0301     0.000389        0.252         2.21       0.0355
     54   200       0.0416       0.0392      0.00235        0.279         4.43       0.0538
     54   300       0.0286       0.0285     9.55e-05        0.243        0.954       0.0174
     54   400       0.0272       0.0271     0.000102         0.24         1.03       0.0171
     54   401       0.0311       0.0308      0.00028        0.259         1.37       0.0273

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     54    51       0.0312       0.0307     0.000457        0.259         3.64       0.0351


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              54 3138.503   0.0015       0.0313     0.000402       0.0317        0.252         1.79       0.0294
! Validation         54 3138.503   0.0015       0.0304     0.000968       0.0314         0.25         3.08       0.0511
Wall time: 3138.50303459703

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     55   100       0.0211       0.0209     0.000206        0.202         1.25       0.0257
     55   200       0.0276       0.0275     8.19e-05        0.241        0.806       0.0146
     55   300       0.0355       0.0351     0.000443        0.251         2.66       0.0342
     55   400       0.0375       0.0374     0.000159        0.267         1.11       0.0184
     55   401       0.0195       0.0191     0.000427        0.204          2.9         0.04

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     55    51       0.0328       0.0326     0.000206        0.266          2.5       0.0254


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              55 3196.052   0.0015       0.0317     0.000396       0.0321        0.253          1.8       0.0294
! Validation         55 3196.052   0.0015       0.0307     0.000433       0.0312        0.249         1.94       0.0321
Wall time: 3196.0527693310287

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     56   100       0.0407       0.0395      0.00125        0.285         4.56       0.0619
     56   200       0.0321       0.0308      0.00136        0.245         2.86       0.0591
     56   300       0.0416       0.0414     0.000182         0.29         1.24        0.022
     56   400       0.0333       0.0332     0.000119        0.266        0.994       0.0181
     56   401       0.0148       0.0147     0.000123        0.165        0.565        0.018

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     56    51       0.0304       0.0303     0.000129        0.258         2.01       0.0197


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              56 3253.639   0.0015       0.0312     0.000625       0.0318        0.252         2.24       0.0371
! Validation         56 3253.639   0.0015       0.0299     0.000233       0.0301        0.246          1.4        0.021
Wall time: 3253.638891328126
! Best model       56    0.030

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     57   100       0.0357       0.0354      0.00033        0.265         1.52       0.0306
     57   200       0.0247       0.0245     0.000178        0.224         1.02       0.0212
     57   300       0.0314       0.0305     0.000841         0.24         2.41       0.0533
     57   400       0.0367       0.0355      0.00123        0.266         4.39       0.0657
     57   401       0.0283        0.028      0.00027        0.242         1.21       0.0318

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     57    51       0.0314       0.0313     0.000144        0.262         1.72       0.0195


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              57 3311.123   0.0015       0.0313     0.000431       0.0317        0.252         1.78        0.029
! Validation         57 3311.123   0.0015       0.0318     0.000235       0.0321        0.256         1.42       0.0216
Wall time: 3311.1233416090254

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     58   100       0.0365       0.0362     0.000241        0.261          1.7       0.0267
     58   200       0.0292       0.0289     0.000262        0.243         1.61       0.0255
     58   300       0.0252       0.0251     0.000138        0.237         1.04       0.0187
     58   400       0.0248       0.0246     0.000193        0.226         1.38       0.0229
     58   401        0.025       0.0249     0.000123        0.194         0.48       0.0163

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     58    51       0.0306       0.0299     0.000712        0.256         5.03       0.0485


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              58 3369.228   0.0015       0.0311     0.000514       0.0316        0.251         1.96       0.0324
! Validation         58 3369.228   0.0015       0.0294      0.00102       0.0304        0.244         3.45       0.0578
Wall time: 3369.2282812050544

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     59   100       0.0286       0.0283     0.000266        0.248         1.36       0.0268
     59   200       0.0321        0.032     0.000174        0.244        0.918       0.0154
     59   300       0.0324       0.0323     0.000134        0.261         1.48       0.0176
     59   400       0.0272        0.027     0.000173        0.238        0.883       0.0184
     59   401       0.0306       0.0302     0.000408        0.259         1.83        0.038

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     59    51         0.03       0.0298      0.00022        0.255         2.43        0.025


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              59 3427.199   0.0015       0.0305     0.000425       0.0309        0.249         1.75       0.0284
! Validation         59 3427.199   0.0015       0.0295     0.000289       0.0298        0.245         1.51       0.0273
Wall time: 3427.1996899829246
! Best model       59    0.030

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     60   100       0.0303       0.0288      0.00148        0.234         3.95       0.0734
     60   200       0.0298       0.0296     0.000216        0.242         1.54        0.021
     60   300       0.0243       0.0241     0.000119        0.224        0.783        0.016
     60   400       0.0298       0.0298     8.44e-05         0.24        0.833       0.0163
     60   401       0.0351       0.0351     1.02e-05        0.277        0.295      0.00614

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     60    51        0.031       0.0308     0.000158         0.26         1.93         0.02


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              60 3484.953   0.0015       0.0298     0.000266       0.0301        0.246         1.47       0.0237
! Validation         60 3484.953   0.0015       0.0292     0.000184       0.0294        0.244         1.27       0.0212
Wall time: 3484.953776247101
! Best model       60    0.029

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     61   100        0.025        0.025     6.43e-05        0.214        0.562       0.0133
     61   200       0.0283       0.0283     8.27e-05        0.233        0.721       0.0126
     61   300       0.0295       0.0291     0.000319        0.231         1.86       0.0271
     61   400       0.0251       0.0244     0.000721        0.222         2.01       0.0332
     61   401       0.0522       0.0519     0.000351        0.315         5.98       0.0362

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     61    51       0.0305       0.0304      0.00012        0.258         1.34       0.0151


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              61 3542.849   0.0015       0.0298     0.000341       0.0302        0.245         1.66       0.0269
! Validation         61 3542.849   0.0015       0.0296     0.000162       0.0298        0.246         1.16       0.0177
Wall time: 3542.8492385789286

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     62   100       0.0305       0.0299     0.000655        0.245         2.15       0.0311
     62   200       0.0365       0.0347      0.00184        0.271         4.05       0.0813
     62   300         0.03       0.0299     0.000118        0.256        0.815       0.0166
     62   400       0.0411       0.0409      0.00019        0.289         1.42        0.016
     62   401        0.036       0.0347      0.00128        0.277         5.29       0.0524

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     62    51       0.0332       0.0313      0.00198        0.261          8.7       0.0843


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              62 3600.926   0.0015       0.0312     0.000508       0.0317        0.251         1.99       0.0326
! Validation         62 3600.926   0.0015       0.0311      0.00187        0.033        0.252         4.76       0.0805
Wall time: 3600.92610952002

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     63   100       0.0245        0.024     0.000562        0.205         1.23        0.024
     63   200       0.0291       0.0283     0.000765        0.243          5.1       0.0432
     63   300       0.0256       0.0254     0.000167        0.228         1.24       0.0208
     63   400       0.0257       0.0255     0.000226        0.224         1.18       0.0263
     63   401       0.0254       0.0253     3.18e-05        0.233        0.563      0.00957

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     63    51       0.0306       0.0304     0.000183        0.258         2.51       0.0246


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              63 3658.210   0.0015       0.0297     0.000288         0.03        0.246         1.54       0.0248
! Validation         63 3658.210   0.0015       0.0295       0.0003       0.0298        0.245         1.73       0.0267
Wall time: 3658.210602150997

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     64   100       0.0242       0.0239     0.000344        0.225         1.81       0.0326
     64   200       0.0317       0.0316     0.000163         0.25         1.27       0.0214
     64   300       0.0427       0.0371      0.00562        0.272         8.98        0.141
     64   400       0.0322       0.0309      0.00132        0.252         4.22       0.0639
     64   401        0.043       0.0412      0.00181          0.3           20       0.0822

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     64    51       0.0298       0.0296     0.000258        0.255         2.78       0.0269


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              64 3715.285   0.0015       0.0296       0.0004         0.03        0.245         1.77       0.0288
! Validation         64 3715.285   0.0015       0.0292     0.000255       0.0295        0.244          1.5       0.0252
Wall time: 3715.285343854921

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     65   100       0.0363       0.0361     0.000188        0.266         1.23       0.0232
     65   200       0.0236       0.0235     0.000116        0.218         1.06       0.0177
     65   300       0.0279       0.0277     0.000147        0.238         1.16       0.0199
     65   400       0.0267       0.0263      0.00035        0.221         1.45       0.0308
     65   401       0.0222        0.022     0.000215        0.218          2.1       0.0242

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     65    51       0.0332       0.0323     0.000815        0.266         5.41       0.0525


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              65 3772.265   0.0015       0.0298     0.000448       0.0302        0.246         1.84       0.0303
! Validation         65 3772.265   0.0015       0.0307      0.00117       0.0318        0.248         3.83       0.0621
Wall time: 3772.26533446298

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     66   100       0.0314       0.0305     0.000895        0.247          2.6       0.0448
     66   200       0.0241       0.0236     0.000535         0.22          3.1       0.0403
     66   300       0.0273       0.0272     6.68e-05        0.234        0.973       0.0137
     66   400       0.0305       0.0304     0.000114        0.248         1.18       0.0155
     66   401       0.0618       0.0614     0.000454        0.354         2.37       0.0374

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     66    51       0.0333       0.0332     6.13e-05         0.27         1.04       0.0121


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              66 3829.536   0.0015       0.0319     0.000805       0.0327        0.252         2.02       0.0325
! Validation         66 3829.536   0.0015       0.0314     0.000241       0.0317        0.253         1.27       0.0208
Wall time: 3829.535891611129

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     67   100       0.0308       0.0307     9.78e-05        0.252        0.922       0.0158
     67   200       0.0281       0.0274     0.000684        0.238         3.17       0.0453
     67   300       0.0226       0.0223      0.00028        0.208         1.57       0.0193
     67   400       0.0247       0.0246     0.000117        0.225        0.863       0.0172
     67   401       0.0253       0.0251      0.00015        0.229         1.41       0.0234

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     67    51       0.0294       0.0288     0.000637         0.25         4.74       0.0469


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              67 3887.067   0.0015       0.0298     0.000346       0.0301        0.245         1.68       0.0275
! Validation         67 3887.067   0.0015       0.0285     0.000657       0.0291        0.241         2.63       0.0453
Wall time: 3887.067383886082
! Best model       67    0.029

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     68   100       0.0327       0.0318     0.000916        0.254          3.4       0.0557
     68   200       0.0328       0.0322     0.000618        0.258         2.62       0.0407
     68   300       0.0336       0.0336     6.58e-05        0.265         1.34       0.0119
     68   400       0.0253       0.0251     0.000268        0.224         1.51       0.0281
     68   401       0.0305       0.0304     0.000119        0.239         0.77        0.021

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     68    51       0.0301       0.0299     0.000115        0.257         1.77       0.0176


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              68 3944.050   0.0015       0.0307     0.000536       0.0313        0.248         2.05       0.0338
! Validation         68 3944.050   0.0015       0.0292     0.000146       0.0294        0.244         1.16       0.0176
Wall time: 3944.0500164369587

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     69   100       0.0292       0.0291     0.000154        0.242        0.989       0.0208
     69   200       0.0266       0.0262     0.000423        0.228         2.69       0.0374
     69   300       0.0267       0.0267     6.98e-05         0.23        0.587       0.0129
     69   400       0.0287       0.0286      0.00017        0.243         1.53       0.0222
     69   401       0.0215       0.0214     6.12e-05        0.207        0.593       0.0149

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     69    51       0.0294       0.0293     9.17e-05        0.253         1.42       0.0142


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              69 3999.821   0.0015       0.0289     0.000289       0.0291        0.242         1.53       0.0249
! Validation         69 3999.821   0.0015       0.0284     0.000103       0.0285         0.24        0.904       0.0138
Wall time: 3999.8213325340766
! Best model       69    0.028

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     70   100       0.0269       0.0267     0.000194        0.229         1.48        0.023
     70   200       0.0277       0.0275     0.000168        0.239         2.06        0.022
     70   300        0.029       0.0285      0.00046        0.241         2.16       0.0354
     70   400       0.0255       0.0253     0.000155         0.23         1.05         0.02
     70   401       0.0421       0.0417     0.000415        0.316         1.73       0.0361

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     70    51        0.029       0.0289     0.000148        0.251         1.75       0.0198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              70 4055.024   0.0015       0.0291     0.000363       0.0295        0.243          1.7        0.028
! Validation         70 4055.024   0.0015        0.028     0.000222       0.0283        0.239          1.3       0.0227
Wall time: 4055.0246446470264
! Best model       70    0.028

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     71   100       0.0282       0.0281     0.000143        0.244         1.19       0.0182
     71   200       0.0343       0.0337     0.000572        0.266         2.01       0.0355
     71   300       0.0252       0.0251     9.33e-05        0.223        0.866       0.0174
     71   400       0.0204       0.0202     0.000151        0.196        0.843       0.0199
     71   401       0.0418       0.0416     0.000196        0.298         2.18       0.0266

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     71    51       0.0294       0.0289     0.000433        0.253            4       0.0372


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              71 4109.318   0.0015       0.0293     0.000408       0.0298        0.244         1.81       0.0291
! Validation         71 4109.318   0.0015        0.028     0.000622       0.0286        0.238         2.74        0.044
Wall time: 4109.31791025796

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     72   100       0.0239       0.0234     0.000466        0.218         1.82       0.0401
     72   200       0.0351       0.0347     0.000413        0.266         1.12       0.0229
     72   300       0.0263       0.0261     0.000181        0.236         1.95       0.0222
     72   400       0.0172       0.0167     0.000515        0.179         1.41       0.0392
     72   401       0.0514       0.0513      9.9e-05        0.305         1.47       0.0174

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     72    51       0.0297       0.0295     0.000104        0.253         1.48       0.0156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              72 4164.263   0.0015       0.0289     0.000312       0.0292        0.241          1.6       0.0258
! Validation         72 4164.263   0.0015       0.0294     0.000199       0.0296        0.245         1.33       0.0214
Wall time: 4164.263106642058

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     73   100       0.0235       0.0234     0.000157        0.218         1.01       0.0181
     73   200       0.0289       0.0288     8.03e-05        0.249        0.807       0.0143
     73   300       0.0268       0.0267     6.56e-05        0.228        0.588        0.012
     73   400       0.0288       0.0285     0.000287        0.244         1.53       0.0296
     73   401       0.0125       0.0124     0.000145        0.157        0.471       0.0167

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     73    51       0.0281        0.028     6.11e-05        0.248        0.873       0.0115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              73 4219.903   0.0015       0.0287     0.000293        0.029        0.241         1.53       0.0252
! Validation         73 4219.903   0.0015       0.0274     0.000133       0.0276        0.236        0.961       0.0156
Wall time: 4219.903291491093
! Best model       73    0.028

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     74   100       0.0269       0.0267     0.000136        0.231        0.963       0.0192
     74   200       0.0293        0.029     0.000311        0.228         1.24       0.0309
     74   300       0.0272       0.0269     0.000297        0.239          1.3       0.0257
     74   400       0.0391       0.0387     0.000378         0.27         1.91       0.0316
     74   401       0.0221       0.0215     0.000643        0.225         2.35       0.0489

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     74    51       0.0289       0.0284     0.000515         0.25         4.31       0.0414


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              74 4275.444   0.0015       0.0289     0.000328       0.0292        0.241         1.66       0.0271
! Validation         74 4275.444   0.0015        0.028     0.000688       0.0287        0.239         2.81       0.0446
Wall time: 4275.44441032107

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     75   100       0.0259       0.0258     8.48e-05        0.233        0.801       0.0129
     75   200       0.0316       0.0314     0.000195        0.258         1.58       0.0195
     75   300       0.0308       0.0307     7.12e-05        0.257          1.7        0.012
     75   400       0.0332       0.0327     0.000564        0.255         2.48       0.0412
     75   401       0.0269       0.0268     0.000137         0.25         1.03       0.0215

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     75    51       0.0293       0.0289     0.000393        0.252         3.61       0.0345


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              75 4330.663   0.0015       0.0288     0.000406       0.0292        0.242          1.8       0.0296
! Validation         75 4330.663   0.0015       0.0281     0.000655       0.0288        0.239         2.74       0.0443
Wall time: 4330.6631693099625

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     76   100       0.0193       0.0191     0.000164        0.189         1.01       0.0237
     76   200       0.0304       0.0293      0.00106        0.247         3.69       0.0453
     76   300       0.0318       0.0306      0.00118        0.254         5.79       0.0633
     76   400       0.0268       0.0266     0.000198        0.238         1.33       0.0231
     76   401       0.0298       0.0295     0.000261        0.258         1.49        0.031

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     76    51       0.0289       0.0288      8.2e-05        0.252         1.49       0.0145


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              76 4386.358   0.0015       0.0286     0.000336       0.0289         0.24         1.66       0.0272
! Validation         76 4386.358   0.0015       0.0276     0.000139       0.0277        0.236          1.1       0.0162
Wall time: 4386.358162926044

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     77   100       0.0221       0.0218     0.000298        0.214         1.76       0.0315
     77   200       0.0233       0.0232     8.42e-05        0.213         0.79       0.0156
     77   300       0.0288       0.0285     0.000263        0.239         1.21       0.0247
     77   400       0.0245       0.0244     0.000156        0.221        0.989       0.0207
     77   401       0.0363       0.0361     0.000159        0.258         2.22       0.0216

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     77    51       0.0284       0.0283      0.00012        0.248          1.8       0.0191


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              77 4440.893   0.0015       0.0289      0.00031       0.0292        0.241         1.57       0.0259
! Validation         77 4440.893   0.0015       0.0278     0.000113       0.0279        0.238         1.01       0.0151
Wall time: 4440.893366419943

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     78   100       0.0305       0.0303     0.000289        0.243         1.17       0.0244
     78   200       0.0226       0.0225     0.000101        0.216        0.757       0.0148
     78   300       0.0375        0.037     0.000564        0.261         2.12       0.0236
     78   400       0.0301       0.0298     0.000223        0.247         1.02       0.0242
     78   401       0.0357       0.0357     4.48e-06        0.242         0.11        0.003

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     78    51        0.028       0.0279     9.92e-05        0.248         1.43       0.0156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              78 4495.753   0.0015       0.0281     0.000271       0.0284        0.239         1.48        0.024
! Validation         78 4495.753   0.0015       0.0274     0.000118       0.0275        0.236        0.961       0.0156
Wall time: 4495.753610301064
! Best model       78    0.027

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     79   100       0.0314       0.0313     0.000113        0.243        0.854       0.0173
     79   200       0.0287       0.0285     0.000199        0.238         2.11       0.0257
     79   300       0.0246       0.0244     0.000258        0.225        0.916       0.0241
     79   400       0.0271       0.0267     0.000347        0.237         1.79       0.0312
     79   401      0.00416      0.00391     0.000245       0.0953        0.847       0.0303

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     79    51       0.0291       0.0286     0.000518        0.249         4.16       0.0415


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              79 4550.949   0.0015       0.0277     0.000329        0.028        0.237         1.65       0.0271
! Validation         79 4550.949   0.0015       0.0273     0.000471       0.0277        0.234         2.18       0.0377
Wall time: 4550.949047025992

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     80   100       0.0219       0.0217     0.000219        0.204         1.23        0.026
     80   200       0.0208       0.0203     0.000529          0.2         2.43       0.0409
     80   300       0.0188       0.0187     7.79e-05        0.192        0.597       0.0136
     80   400       0.0283       0.0276     0.000776        0.243         2.62       0.0472
     80   401       0.0613       0.0612     4.18e-05        0.261         1.31       0.0113

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     80    51       0.0293       0.0292     0.000152        0.254         2.35        0.021


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              80 4606.358   0.0015       0.0281     0.000388       0.0284        0.238         1.74       0.0287
! Validation         80 4606.358   0.0015       0.0277     0.000299        0.028        0.237         1.82       0.0292
Wall time: 4606.358668191126

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     81   100       0.0374       0.0365     0.000835        0.277         2.51       0.0355
     81   200       0.0273       0.0271     0.000191         0.24        0.994        0.021
     81   300       0.0316       0.0313     0.000296        0.261         1.36       0.0297
     81   400       0.0297       0.0294     0.000344         0.24          1.6       0.0334
     81   401       0.0267       0.0267     2.04e-05        0.242         2.28      0.00816

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     81    51        0.032       0.0312     0.000831        0.261         5.56       0.0538


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              81 4661.613   0.0015       0.0314     0.000415       0.0318         0.25         1.81       0.0299
! Validation         81 4661.613   0.0015       0.0298     0.000862       0.0306        0.247         3.12       0.0529
Wall time: 4661.613328323001

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     82   100       0.0265       0.0262     0.000302        0.234         1.58       0.0298
     82   200       0.0217       0.0214     0.000352        0.211         1.35       0.0323
     82   300       0.0368       0.0366       0.0002        0.261         1.13       0.0241
     82   400       0.0285       0.0283     0.000238        0.241         1.53       0.0279
     82   401       0.0234       0.0232     0.000167         0.21         1.59        0.025

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     82    51       0.0305       0.0301      0.00032        0.257         2.85       0.0298


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              82 4717.103   0.0015       0.0287     0.000383       0.0291        0.241         1.74        0.029
! Validation         82 4717.103   0.0015       0.0282     0.000231       0.0285        0.238         1.42       0.0241
Wall time: 4717.103353010956

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     83   100        0.027       0.0265     0.000464         0.23         3.14       0.0311
     83   200       0.0252       0.0252     3.24e-05        0.227        0.538      0.00937
     83   300       0.0212       0.0211     0.000111        0.212        0.786       0.0164
     83   400       0.0259       0.0256     0.000305        0.226         1.59       0.0288
     83   401       0.0526       0.0525     0.000106        0.325         1.52        0.015

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     83    51       0.0277       0.0277      4.7e-05        0.247         0.99       0.0102


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              83 4772.840   0.0015       0.0279     0.000315       0.0282        0.237          1.6       0.0258
! Validation         83 4772.840   0.0015       0.0271     0.000107       0.0272        0.234        0.925       0.0145
Wall time: 4772.840633834014
! Best model       83    0.027

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     84   100       0.0244        0.024     0.000365        0.222         1.76       0.0289
     84   200       0.0264       0.0264     3.69e-05        0.222        0.372      0.00923
     84   300       0.0385       0.0368      0.00176        0.274         6.27       0.0751
     84   400       0.0329       0.0327     0.000218        0.258         1.12       0.0239
     84   401       0.0315       0.0314     3.95e-05        0.258        0.559       0.0117

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     84    51        0.029       0.0289     8.98e-05        0.251          1.1       0.0128


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              84 4827.847   0.0015        0.028      0.00046       0.0285        0.238         1.86       0.0309
! Validation         84 4827.847   0.0015       0.0277     0.000178       0.0279        0.237         1.12       0.0183
Wall time: 4827.847602754133

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     85   100       0.0254       0.0252     0.000203        0.227         1.27       0.0252
     85   200       0.0323       0.0319     0.000356        0.251         1.08         0.02
     85   300       0.0251       0.0249     0.000151        0.222         1.29       0.0219
     85   400       0.0299       0.0296     0.000291        0.243         1.72        0.022
     85   401       0.0169       0.0169     3.46e-05        0.185        0.447       0.0109

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     85    51       0.0282       0.0281     8.02e-05         0.25         1.12       0.0128


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              85 4882.872   0.0015       0.0276     0.000344       0.0279        0.236         1.63       0.0268
! Validation         85 4882.872   0.0015       0.0272     0.000109       0.0273        0.236        0.942       0.0147
Wall time: 4882.872110412922

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     86   100       0.0252       0.0246     0.000583        0.214          1.5       0.0365
     86   200       0.0283        0.028     0.000275        0.243         1.45       0.0271
     86   300       0.0307       0.0305     0.000246        0.257         2.19       0.0272
     86   400       0.0217       0.0213     0.000406        0.203         1.71       0.0349
     86   401      0.00276      0.00275     3.77e-06       0.0796        0.103      0.00367

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     86    51       0.0279       0.0277     0.000191        0.247         2.19       0.0225


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              86 4937.981   0.0015       0.0273     0.000276       0.0275        0.235         1.47       0.0242
! Validation         86 4937.981   0.0015       0.0266     0.000206       0.0268        0.232         1.29        0.023
Wall time: 4937.981463544071
! Best model       86    0.027

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     87   100        0.026       0.0251     0.000963        0.231         3.04       0.0554
     87   200       0.0277       0.0275     0.000211        0.232         1.28       0.0256
     87   300       0.0254        0.025     0.000454        0.226         1.63       0.0376
     87   400       0.0255       0.0254      0.00011        0.225        0.765       0.0169
     87   401        0.014       0.0121      0.00189         0.16         2.47        0.075

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     87    51       0.0281       0.0279     0.000213        0.247         2.39       0.0243


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              87 4993.693   0.0015       0.0278     0.000309       0.0281        0.237         1.56       0.0256
! Validation         87 4993.693   0.0015       0.0274      0.00016       0.0276        0.237         1.14       0.0183
Wall time: 4993.692891899031

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     88   100       0.0315       0.0314     0.000119        0.255         1.25       0.0185
     88   200       0.0281       0.0274     0.000746        0.234         2.18       0.0508
     88   300       0.0287       0.0286     8.89e-05        0.244         1.04        0.017
     88   400       0.0326       0.0324     0.000222         0.26         1.75        0.023
     88   401       0.0546        0.054     0.000604        0.302         3.85       0.0421

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     88    51       0.0272       0.0266     0.000549        0.242         4.24        0.043


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              88 5049.161   0.0015       0.0279     0.000441       0.0284        0.238         1.88        0.031
! Validation         88 5049.161   0.0015       0.0262     0.000562       0.0268         0.23         2.36       0.0409
Wall time: 5049.161736930022
! Best model       88    0.027

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     89   100       0.0217       0.0217     2.42e-05        0.204        0.413      0.00832
     89   200       0.0306       0.0305     6.76e-05         0.25         1.07       0.0129
     89   300       0.0308       0.0303     0.000441        0.243         2.57       0.0366
     89   400       0.0266       0.0265     7.45e-05        0.227        0.621       0.0133
     89   401       0.0243       0.0242     0.000118        0.207        0.825       0.0201

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     89    51       0.0274       0.0273     6.89e-05        0.245         1.09       0.0125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              89 5103.920   0.0015       0.0266     0.000264       0.0268        0.232         1.47       0.0243
! Validation         89 5103.920   0.0015        0.026     7.83e-05       0.0261        0.229        0.752       0.0111
Wall time: 5103.920321177924
! Best model       89    0.026

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     90   100       0.0294       0.0293     7.52e-05        0.246        0.756       0.0126
     90   200        0.029       0.0288     0.000164        0.246         2.07       0.0175
     90   300       0.0263       0.0258     0.000499        0.233          2.2       0.0377
     90   400       0.0253       0.0252     0.000129        0.219         1.53       0.0182
     90   401       0.0404       0.0404     2.41e-05        0.275         0.45      0.00881

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     90    51       0.0273       0.0272     7.54e-05        0.245          1.7       0.0154


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              90 5157.972   0.0015       0.0267     0.000237       0.0269        0.232         1.37       0.0225
! Validation         90 5157.972   0.0015       0.0262     0.000166       0.0264         0.23         1.21       0.0187
Wall time: 5157.972852193052

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     91   100       0.0206       0.0205     0.000114        0.201        0.809       0.0173
     91   200       0.0265       0.0264     7.22e-05        0.226        0.735       0.0136
     91   300       0.0255        0.025      0.00045         0.23         1.63       0.0361
     91   400       0.0238       0.0236     0.000172        0.219         1.16       0.0221
     91   401       0.0244       0.0243      0.00012        0.231        0.962         0.02

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     91    51       0.0266       0.0266     7.46e-05        0.242         1.16       0.0128


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              91 5213.505   0.0015        0.027     0.000256       0.0272        0.234         1.45       0.0238
! Validation         91 5213.505   0.0015       0.0259     0.000108        0.026        0.228        0.915       0.0147
Wall time: 5213.505303580081
! Best model       91    0.026

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     92   100       0.0251       0.0248      0.00037        0.211         1.22       0.0317
     92   200       0.0296       0.0278      0.00181        0.225         3.51       0.0762
     92   300       0.0302         0.03     0.000258         0.25         1.69       0.0278
     92   400       0.0301       0.0297     0.000349        0.244         2.31        0.033
     92   401        0.054       0.0539     0.000146        0.348         1.89       0.0228

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     92    51        0.026       0.0259     6.12e-05        0.239        0.972       0.0114


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              92 5268.761   0.0015       0.0268     0.000461       0.0273        0.233         1.89       0.0316
! Validation         92 5268.761   0.0015       0.0257     0.000117       0.0258        0.228        0.951       0.0153
Wall time: 5268.761316498043
! Best model       92    0.026

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     93   100       0.0305       0.0304     6.95e-05        0.257        0.829       0.0131
     93   200       0.0372       0.0366     0.000593        0.274         1.94       0.0213
     93   300       0.0378        0.037     0.000861        0.279         3.31       0.0542
     93   400       0.0252       0.0251     7.66e-05        0.225        0.776       0.0122
     93   401       0.0286       0.0285     7.79e-05        0.234        0.693       0.0151

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     93    51       0.0263       0.0262      0.00011        0.239         1.49       0.0164


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              93 5323.518   0.0015       0.0274     0.000235       0.0277        0.236         1.38       0.0226
! Validation         93 5323.518   0.0015        0.026     0.000153       0.0261        0.228         1.06       0.0183
Wall time: 5323.5186387391295

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     94   100       0.0201       0.0199     0.000275          0.2         1.52       0.0292
     94   200       0.0309       0.0309     3.59e-05        0.241        0.696      0.00947
     94   300       0.0258       0.0255      0.00026        0.225         1.71       0.0288
     94   400       0.0178       0.0178     5.91e-05         0.18        0.628       0.0117
     94   401       0.0245       0.0243     0.000106        0.211        0.745       0.0168

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     94    51       0.0261        0.026        5e-05        0.239         1.28       0.0122


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              94 5378.046   0.0015       0.0265     0.000235       0.0268        0.232         1.39       0.0225
! Validation         94 5378.046   0.0015       0.0257     0.000138       0.0258        0.227         1.13       0.0167
Wall time: 5378.04635154712
! Best model       94    0.026

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     95   100       0.0273       0.0272     0.000125         0.23         1.48       0.0181
     95   200       0.0296       0.0295     9.25e-05        0.241          1.1       0.0132
     95   300       0.0313       0.0312     0.000129        0.251          1.3       0.0162
     95   400        0.033       0.0328     0.000279        0.256         1.51        0.029
     95   401       0.0152       0.0151     0.000168        0.168        0.926       0.0207

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     95    51       0.0257       0.0257     5.65e-05        0.236         1.01       0.0113


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              95 5433.506   0.0015       0.0264     0.000357       0.0268        0.231         1.68       0.0279
! Validation         95 5433.506   0.0015       0.0254     0.000125       0.0255        0.227        0.996       0.0153
Wall time: 5433.505996917142
! Best model       95    0.026

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     96   100       0.0278       0.0276     0.000211         0.24         1.34       0.0261
     96   200       0.0212       0.0202      0.00104        0.192         2.45        0.058
     96   300       0.0265       0.0262     0.000276        0.229         1.42       0.0292
     96   400       0.0279       0.0276     0.000296        0.246         2.25        0.029
     96   401        0.018       0.0179     5.36e-05        0.201         1.15       0.0127

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     96    51       0.0268       0.0268     4.97e-05         0.24        0.853       0.0105


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              96 5488.227   0.0015       0.0269     0.000297       0.0272        0.233         1.56       0.0254
! Validation         96 5488.227   0.0015       0.0257     0.000154       0.0259        0.228         1.08       0.0182
Wall time: 5488.22758048214

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     97   100       0.0296       0.0295     0.000105        0.249         1.03        0.016
     97   200       0.0293       0.0292     0.000171        0.248          1.1       0.0205
     97   300       0.0321        0.032     8.37e-05         0.25          0.9       0.0148
     97   400       0.0233       0.0232     6.96e-05        0.218        0.643       0.0133
     97   401       0.0264       0.0262     0.000224        0.214          1.1       0.0289

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     97    51       0.0261        0.026     0.000139        0.238         1.89       0.0196


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              97 5543.528   0.0015       0.0264       0.0002       0.0266        0.231         1.25       0.0204
! Validation         97 5543.528   0.0015       0.0255     0.000138       0.0257        0.226         1.05       0.0181
Wall time: 5543.528249138035

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     98   100       0.0296       0.0294     0.000255        0.242         1.44        0.025
     98   200       0.0351       0.0344     0.000684        0.251         3.04       0.0488
     98   300       0.0236       0.0235     2.88e-05        0.223        0.547      0.00865
     98   400       0.0289       0.0286     0.000305        0.246         1.52        0.029
     98   401      0.00504      0.00324       0.0018       0.0837         2.29       0.0819

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     98    51       0.0275       0.0274      9.9e-05        0.245         1.58       0.0157


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              98 5598.636   0.0015       0.0264     0.000324       0.0268        0.231         1.61       0.0268
! Validation         98 5598.636   0.0015       0.0264     0.000212       0.0266        0.232         1.39       0.0219
Wall time: 5598.636303234147

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     99   100       0.0275       0.0273     0.000176        0.237          1.4       0.0216
     99   200       0.0248       0.0245     0.000288        0.222         1.43        0.029
     99   300        0.022       0.0218     0.000213        0.217         1.85       0.0221
     99   400       0.0468       0.0373      0.00947        0.274         11.5        0.179
     99   401       0.0565       0.0478      0.00861        0.334         5.07        0.157

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     99    51       0.0273       0.0272     0.000141        0.244          1.8       0.0196


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              99 5653.561   0.0015       0.0289       0.0007       0.0296        0.239         1.77       0.0298
! Validation         99 5653.561   0.0015       0.0272     0.000215       0.0274        0.237         1.44       0.0214
Wall time: 5653.561793894973

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
    100   100       0.0313       0.0312      0.00014        0.253          1.2       0.0198
    100   200       0.0271       0.0269     0.000158        0.237         1.19       0.0212
    100   300       0.0337       0.0337     3.94e-05        0.263         1.06       0.0107
    100   400       0.0267       0.0265     0.000238        0.233         1.72       0.0222
    100   401       0.0279       0.0278     0.000112        0.247         1.64       0.0175

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
    100    51       0.0281       0.0271      0.00101        0.243         6.04        0.058


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train             100 5708.350   0.0015       0.0281     0.000349       0.0284        0.239         1.61       0.0262
! Validation        100 5708.350   0.0015       0.0265       0.0011       0.0276        0.232         3.74       0.0603
Wall time: 5708.350628478918
! Stop training: max epochs
Wall time: 5708.377570941113
Cumulative wall time: 5708.377570941113
Testset is used.
Using all frames from the specified test dataset, yielding a test set size of 811 frames.
Starting...

--- Evaluation Time consumption: 2.996274s ---

--- Evaluation Final result: ---
               f_mae =  0.250301           
              f_rmse =  0.341963           
             N_f_mae =  0.220813           
            Si_f_mae =  0.283336           
         psavg_f_mae =  0.252074           
            N_f_rmse =  0.309298           
           Si_f_rmse =  0.375194           
        psavg_f_rmse =  0.342246           
               e_mae =  2.764592           
             e/N_mae =  0.042631           
Training QAT Model...
After QAT training...
loaded model from training session
               f_mae =  0.250301           
              f_rmse =  0.341963           
             N_f_mae =  0.220813           
            Si_f_mae =  0.283336           
         psavg_f_mae =  0.252074           
            N_f_rmse =  0.309298           
           Si_f_rmse =  0.375194           
        psavg_f_rmse =  0.342246           
               e_mae =  2.764592           
             e/N_mae =  0.042631           
