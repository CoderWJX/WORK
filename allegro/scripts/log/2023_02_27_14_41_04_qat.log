Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs16', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 8, 'max_epochs': 50, 'learning_rate': 0.004, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_e/N_mae', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs16', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 8, 'max_epochs': 50, 'learning_rate': 0.004, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_e/N_mae', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False, 'dataset_extra_fixed_fields': {'r_max': 6.0}, 'validation_dataset_extra_fixed_fields': {'r_max': 6.0}, 'dataset_config': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml', 'metrics_config': PosixPath('/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml'), 'base_model_file': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/best_model.pth', 'output_fields': []}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
RescaleOutput(
  (model): GradientOutput(
    (func): SequentialGraphNetwork(
      (one_hot): OneHotAtomEncoding()
      (radial_basis): RadialBasisEdgeEncoding(
        (basis): NormalizedBasis(
          (basis): BesselBasis()
        )
        (cutoff): PolynomialCutoff()
      )
      (spharm): SphericalHarmonicEdgeAttrs(
        (sh): SphericalHarmonics()
      )
      (allegro): Allegro_Module(
        (latents): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (env_embed_mlps): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (tps): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (linears): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (env_linears): ModuleList(
          (0): Identity()
          (1): Identity()
          (2): Identity()
        )
        (_env_weighter): MakeWeightedChannels()
        (final_latent): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng): ScalarMLP(
        (_module): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng_sum): EdgewiseEnergySum()
      (per_species_rescale): PerSpeciesScaleShift()
      (total_energy_sum): AtomwiseReduce()
    )
  )
)
Number of weights: 43096
! Starting training ...

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      0   100         1.72         1.12        0.593         1.54         88.5          1.4
      0   102         1.97         1.38        0.589         1.74         71.1         1.48


  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Initial Validation          0   20.525    0.004         1.18        0.804         1.98         1.51         90.7         1.64
Wall time: 20.52495572785847
! Best model        0    1.644

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1   100        0.497         0.49       0.0067        0.908         11.8        0.134
      1   200          0.2        0.195      0.00492        0.655         4.64        0.117
      1   300        0.243        0.242      0.00119        0.703         4.24       0.0582
      1   400        0.208        0.188       0.0201        0.625         14.1        0.218
      1   500        0.186        0.186     0.000444        0.598         2.53       0.0345
      1   600        0.134        0.127      0.00682        0.534         8.18        0.113
      1   700       0.0817       0.0814     0.000354        0.388         1.93       0.0281
      1   800       0.0702       0.0699     0.000357        0.387         1.61       0.0328
      1   801       0.0911       0.0894      0.00168        0.468         3.51       0.0732

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1   100        0.151        0.133       0.0181        0.538         19.8        0.253
      1   102       0.0926       0.0818       0.0108        0.433         9.56        0.199


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               1  174.848    0.004        0.225       0.0117        0.237         0.64         8.41        0.138
! Validation          1  174.848    0.004        0.108       0.0191        0.127        0.479           15        0.253
Wall time: 174.84854503092356
! Best model        1    0.253

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2   100        0.144        0.141      0.00321        0.547         5.69        0.101
      2   200       0.0769       0.0755      0.00135        0.399         2.49       0.0609
      2   300       0.0703       0.0686      0.00168         0.39          2.7       0.0577
      2   400       0.0746       0.0722      0.00235        0.394         4.04       0.0847
      2   500       0.0904       0.0862      0.00419         0.43         8.06        0.109
      2   600       0.0735       0.0722      0.00124        0.382         2.86       0.0483
      2   700       0.0678       0.0661      0.00169        0.391          3.5       0.0729
      2   800       0.0801       0.0764      0.00366        0.414         6.27        0.113
      2   801       0.0701       0.0692      0.00094        0.384         4.49       0.0551

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2   100       0.0882       0.0865       0.0017         0.43         5.75       0.0631
      2   102       0.0657        0.065     0.000654        0.381         2.06       0.0429


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               2  308.231    0.004        0.086      0.00221       0.0882        0.419         4.15       0.0674
! Validation          2  308.231    0.004       0.0665      0.00123       0.0678        0.376         3.08       0.0546
Wall time: 308.2328499748837
! Best model        2    0.055

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3   100       0.0931       0.0895      0.00363        0.437           13        0.108
      3   200       0.0963       0.0946       0.0017        0.447         2.57       0.0657
      3   300       0.0512       0.0489      0.00237        0.303         4.23       0.0922
      3   400       0.0553       0.0544     0.000889        0.323         2.31       0.0512
      3   500       0.0559       0.0551     0.000856        0.345         2.52       0.0525
      3   600       0.0886       0.0877     0.000939        0.427         1.83       0.0428
      3   700       0.0859       0.0856       0.0003        0.404         2.16       0.0261
      3   800       0.0596       0.0582      0.00141         0.35         2.97       0.0596
      3   801       0.0574       0.0563      0.00107        0.364         2.97        0.062

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3   100       0.0831       0.0821      0.00105        0.416         4.55       0.0569
      3   102         0.07       0.0691     0.000933        0.389         2.56       0.0534


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               3  442.506    0.004       0.0669      0.00248       0.0694        0.371          4.3       0.0701
! Validation          3  442.506    0.004       0.0646      0.00117       0.0658        0.371         3.36       0.0557
Wall time: 442.5086831860244

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4   100       0.0676       0.0672     0.000365        0.382         2.28        0.033
      4   200       0.0863       0.0849      0.00137        0.402         4.24       0.0686
      4   300       0.0685       0.0675      0.00102        0.373         2.85       0.0536
      4   400       0.0641       0.0629      0.00119        0.367         5.18       0.0526
      4   500       0.0332       0.0332     5.58e-05        0.266         0.48       0.0119
      4   600       0.0568       0.0564     0.000307        0.352         1.27       0.0259
      4   700       0.0625       0.0604      0.00216        0.355         3.51       0.0777
      4   800       0.0575       0.0573     0.000219        0.343         1.45       0.0255
      4   801       0.0451        0.045     4.76e-05        0.328        0.597       0.0124

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4   100       0.0826       0.0811      0.00157        0.426         6.09       0.0617
      4   102       0.0645       0.0642     0.000332        0.358         1.46       0.0305


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               4  575.439    0.004       0.0631      0.00197       0.0651        0.362         3.71       0.0606
! Validation          4  575.439    0.004       0.0683     0.000963       0.0692        0.385          2.7        0.047
Wall time: 575.4391155259218
! Best model        4    0.047

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5   100       0.0563        0.056     0.000243        0.312         1.52       0.0263
      5   200       0.0515        0.051     0.000485        0.332         1.46       0.0339
      5   300       0.0852       0.0811      0.00413        0.391         7.31        0.104
      5   400       0.0375       0.0358      0.00172         0.27         2.82       0.0707
      5   500       0.0432       0.0428     0.000425        0.299            3       0.0295
      5   600       0.0409       0.0403     0.000587        0.294         2.56       0.0381
      5   700       0.0395       0.0391     0.000374        0.293         1.28       0.0344
      5   800       0.0574       0.0567     0.000774        0.358         3.33       0.0479
      5   801       0.0365       0.0348      0.00176        0.285         3.86       0.0803

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5   100        0.119        0.101       0.0171        0.475         13.6        0.237
      5   102       0.0985       0.0779       0.0206        0.414         13.2        0.275


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               5  709.076    0.004       0.0547      0.00136       0.0561        0.336         3.25       0.0527
! Validation          5  709.076    0.004       0.0903       0.0213        0.112         0.44         15.6        0.275
Wall time: 709.0762174860574

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6   100       0.0499       0.0496     0.000231        0.328         2.75       0.0256
      6   200       0.0453       0.0449     0.000321        0.303         1.21       0.0243
      6   300       0.0379        0.037      0.00082        0.267         1.97       0.0537
      6   400       0.0517       0.0514     0.000291        0.314          1.2       0.0266
      6   500       0.0606       0.0598     0.000775        0.347         2.75        0.044
      6   600       0.0471       0.0451      0.00202        0.311         2.79       0.0714
      6   700       0.0402       0.0392      0.00107        0.293         3.21       0.0594
      6   800       0.0398       0.0385      0.00123        0.285         3.65       0.0643
      6   801       0.0872       0.0865     0.000716        0.416         5.43       0.0517

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6   100       0.0799       0.0604       0.0194        0.359         20.6        0.267
      6   102       0.0724       0.0564       0.0161        0.354         11.7        0.245


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               6  842.716    0.004       0.0512       0.0012       0.0524        0.324         3.06       0.0497
! Validation          6  842.716    0.004       0.0499       0.0202       0.0701        0.324         16.3        0.268
Wall time: 842.7169436018448

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7   100       0.0414       0.0411     0.000296         0.29        0.978       0.0218
      7   200       0.0419       0.0413     0.000544        0.289         1.63       0.0391
      7   300       0.0478       0.0474     0.000473        0.327         2.59       0.0385
      7   400       0.0411       0.0406     0.000495        0.297         1.94       0.0382
      7   500       0.0538       0.0536     0.000197        0.332         1.26        0.024
      7   600       0.0623       0.0607      0.00155        0.344         4.13       0.0676
      7   700       0.0484       0.0482     0.000158         0.32            2       0.0219
      7   800       0.0505       0.0498     0.000788        0.335         3.07       0.0497
      7   801       0.0455       0.0439      0.00165        0.292         3.04       0.0784

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7   100       0.0535       0.0524      0.00114        0.334          4.7       0.0523
      7   102       0.0498       0.0495     0.000362        0.325          1.5       0.0313


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               7  975.601    0.004        0.047      0.00122       0.0482         0.31          3.1       0.0509
! Validation          7  975.601    0.004       0.0407     0.000685       0.0414        0.292         2.62       0.0379
Wall time: 975.6017211498693
! Best model        7    0.038

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8   100       0.0475       0.0472     0.000284         0.32         1.83       0.0254
      8   200       0.0483       0.0482     0.000147        0.317        0.853        0.019
      8   300       0.0402       0.0396     0.000579         0.28         2.66       0.0414
      8   400       0.0571       0.0565     0.000679        0.341         2.31       0.0408
      8   500       0.0381       0.0376     0.000514        0.282         2.38       0.0397
      8   600       0.0447       0.0424       0.0023        0.293         4.92       0.0871
      8   700       0.0425       0.0419     0.000598        0.292         1.88        0.043
      8   800       0.0289       0.0288     8.43e-05         0.25        0.731       0.0156
      8   801         0.03         0.03     1.42e-05        0.258         0.35      0.00728

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8   100       0.0558        0.055     0.000864        0.355         4.39       0.0448
      8   102       0.0459       0.0459      7.2e-05        0.318        0.635       0.0132


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               8 1108.714    0.004       0.0486      0.00166       0.0502        0.312            3       0.0502
! Validation          8 1108.714    0.004       0.0486     0.000459       0.0491        0.322         1.95       0.0288
Wall time: 1108.7147527909838
! Best model        8    0.029

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9   100       0.0409         0.04     0.000905        0.293         2.56       0.0483
      9   200       0.0561       0.0558      0.00036        0.343         3.58       0.0324
      9   300       0.0413       0.0411     0.000202        0.299         1.91       0.0242
      9   400       0.0174       0.0173     0.000126        0.183         1.74       0.0193
      9   500       0.0346       0.0335      0.00103        0.266         3.87       0.0541
      9   600       0.0324       0.0311      0.00127         0.25         1.83       0.0456
      9   700       0.0451       0.0445     0.000678        0.282         1.77       0.0456
      9   800       0.0406       0.0398     0.000729        0.287         2.85       0.0406
      9   801       0.0374       0.0371     0.000269        0.287         1.31       0.0273

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9   100       0.0544       0.0534     0.000983        0.344         3.29       0.0557
      9   102        0.044       0.0425      0.00154        0.301         3.48       0.0725


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               9 1241.786    0.004       0.0444     0.000887       0.0452          0.3          2.7        0.044
! Validation          9 1241.786    0.004       0.0424      0.00149       0.0439        0.299         3.81       0.0688
Wall time: 1241.7883500149474

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10   100        0.032        0.032     5.71e-05        0.245        0.559       0.0113
     10   200       0.0436       0.0435      0.00011          0.3         1.88       0.0179
     10   300       0.0536       0.0527     0.000958        0.315         4.64       0.0493
     10   400        0.022       0.0217     0.000219        0.212         2.35       0.0257
     10   500       0.0424        0.042     0.000388        0.292          1.9       0.0338
     10   600       0.0466       0.0457     0.000825        0.306         3.34       0.0442
     10   700       0.0436       0.0431     0.000478        0.296         2.03       0.0397
     10   800       0.0333       0.0332     0.000187        0.257         0.78         0.02
     10   801       0.0364       0.0363      8.2e-05        0.283         1.32        0.016

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10   100       0.0433        0.043     0.000276        0.307         2.03       0.0206
     10   102       0.0386       0.0386     3.87e-05        0.284        0.501       0.0104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              10 1375.431    0.004       0.0393      0.00086       0.0402        0.284         2.56        0.042
! Validation         10 1375.431    0.004       0.0355     0.000211       0.0357        0.271         1.21       0.0179
Wall time: 1375.4317451459356
! Best model       10    0.018

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11   100       0.0404        0.037      0.00341        0.272          6.3        0.107
     11   200       0.0312       0.0286      0.00254        0.245         3.52       0.0927
     11   300       0.0464        0.046      0.00046        0.304         1.73       0.0363
     11   400       0.0332       0.0326     0.000621        0.268         1.73       0.0411
     11   500       0.0394       0.0389     0.000446        0.284         2.11       0.0376
     11   600       0.0467       0.0465     0.000223        0.318         1.37       0.0208
     11   700       0.0427       0.0418     0.000857        0.295         2.09       0.0434
     11   800        0.038       0.0379     0.000124        0.273         1.13       0.0196
     11   801        0.018        0.018     4.05e-06        0.206        0.184      0.00383

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11   100       0.0497       0.0492     0.000554        0.327         2.97       0.0318
     11   102       0.0454       0.0453     0.000114        0.316        0.924       0.0193


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              11 1507.962    0.004       0.0406      0.00101       0.0416        0.289         2.72        0.045
! Validation         11 1507.962    0.004       0.0403     0.000357       0.0406        0.292         1.61       0.0268
Wall time: 1507.9629266289994

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12   100       0.0462       0.0461     0.000126        0.286        0.902       0.0196
     12   200       0.0358       0.0356     0.000238        0.282         1.53       0.0286
     12   300       0.0248       0.0248     8.33e-05         0.22        0.804       0.0156
     12   400       0.0238       0.0234      0.00043        0.213         1.22       0.0308
     12   500       0.0323       0.0322     7.02e-05        0.263         1.29       0.0146
     12   600       0.0505       0.0472      0.00325        0.293         5.88         0.11
     12   700       0.0295       0.0268       0.0027        0.232         4.05       0.0986
     12   800       0.0478       0.0472     0.000598        0.322         3.07       0.0381
     12   801       0.0269       0.0238      0.00301        0.228         4.09        0.106

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12   100       0.0453       0.0448     0.000445        0.312          2.9       0.0309
     12   102       0.0369       0.0367     0.000176        0.273        0.961         0.02


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              12 1641.071    0.004       0.0368     0.000887       0.0377        0.274         2.65       0.0433
! Validation         12 1641.071    0.004       0.0351     0.000323       0.0354         0.27         1.51       0.0254
Wall time: 1641.071329229977

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13   100       0.0272       0.0233      0.00387        0.222         5.31        0.117
     13   200       0.0458       0.0455     0.000268        0.305         1.11       0.0256
     13   300       0.0299       0.0297     0.000226        0.248         1.13        0.025
     13   400       0.0264       0.0261     0.000354        0.232         1.76       0.0344
     13   500       0.0371       0.0361      0.00101        0.275         3.94       0.0567
     13   600       0.0414        0.038      0.00341        0.279         7.03         0.11
     13   700       0.0336       0.0323      0.00121        0.255         4.12       0.0652
     13   800       0.0299       0.0296     0.000283        0.251         2.65       0.0248
     13   801       0.0486       0.0486     3.23e-07        0.331       0.0896      0.00105

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13   100       0.0486       0.0461      0.00253        0.318         4.94       0.0876
     13   102       0.0417       0.0386      0.00316        0.294         5.14        0.107


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              13 1773.085    0.004       0.0358     0.000803       0.0366         0.27         2.47       0.0406
! Validation         13 1773.085    0.004       0.0365      0.00346         0.04        0.278         6.09        0.108
Wall time: 1773.0859763468616

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14   100       0.0447       0.0446     0.000141        0.284         1.27       0.0201
     14   200       0.0332        0.031       0.0022        0.254         4.45       0.0861
     14   300       0.0365       0.0356     0.000881        0.263         1.68       0.0435
     14   400       0.0434       0.0427     0.000706        0.291         2.16       0.0417
     14   500        0.029       0.0285     0.000445        0.249         1.86       0.0387
     14   600       0.0477       0.0471     0.000566        0.316         2.13       0.0359
     14   700       0.0287       0.0285     0.000177        0.236         1.03       0.0225
     14   800       0.0316       0.0309     0.000756         0.26         3.02       0.0448
     14   801        0.024       0.0227      0.00128        0.231          6.6       0.0688

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14   100       0.0415       0.0411     0.000403        0.302         2.53       0.0365
     14   102       0.0349       0.0346     0.000337        0.278         1.69       0.0352


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              14 1905.717    0.004       0.0357     0.000853       0.0366         0.27         2.55       0.0421
! Validation         14 1905.717    0.004       0.0358     0.000306       0.0361        0.274         1.73       0.0278
Wall time: 1905.7179222039413

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15   100       0.0319       0.0318     0.000104        0.241        0.665       0.0161
     15   200       0.0422       0.0416     0.000581        0.301         3.13       0.0452
     15   300       0.0358       0.0343      0.00148        0.266         4.93       0.0712
     15   400        0.027       0.0266     0.000443        0.238         2.24       0.0402
     15   500        0.044       0.0428      0.00119        0.294         3.65        0.059
     15   600       0.0611       0.0573      0.00374        0.319         5.51       0.0627
     15   700        0.049       0.0486       0.0004        0.308         1.84       0.0252
     15   800       0.0587        0.053      0.00569        0.318         8.41        0.139
     15   801       0.0237       0.0228     0.000919        0.211         2.22       0.0586

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15   100       0.0522       0.0457      0.00654         0.32           12        0.152
     15   102       0.0482       0.0432      0.00503        0.309         6.53        0.136


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              15 2037.483    0.004       0.0412       0.0024       0.0436         0.29         3.33       0.0539
! Validation         15 2037.483    0.004       0.0375      0.00447       0.0419        0.281         7.88        0.123
Wall time: 2037.48333730991

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16   100       0.0378       0.0372     0.000664         0.28         2.61        0.037
     16   200       0.0379       0.0375     0.000359        0.278         1.61       0.0319
     16   300       0.0334       0.0331     0.000325        0.264         1.51       0.0296
     16   400       0.0325       0.0309       0.0016        0.257         4.94       0.0589
     16   500       0.0303       0.0301     0.000232        0.257         1.34       0.0229
     16   600       0.0303         0.03     0.000358        0.232         1.32       0.0318
     16   700        0.032       0.0318     0.000213        0.254         1.77       0.0231
     16   800       0.0344       0.0343     0.000133        0.261        0.833       0.0164
     16   801      0.00459      0.00432     0.000273       0.0953        0.884       0.0316

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16   100       0.0427       0.0417      0.00095          0.3         3.49       0.0553
     16   102       0.0336       0.0322      0.00142         0.27          3.4       0.0708


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              16 2169.834    0.004       0.0364     0.000811       0.0372        0.272         2.55       0.0421
! Validation         16 2169.834    0.004       0.0339      0.00154       0.0354        0.266         3.95       0.0703
Wall time: 2169.834569983883

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17   100       0.0559        0.055     0.000888        0.327         3.32       0.0506
     17   200       0.0214       0.0212     0.000256        0.212         1.36       0.0263
     17   300       0.0278       0.0274     0.000471         0.24          1.7       0.0402
     17   400       0.0209       0.0207     0.000207        0.209         1.41       0.0255
     17   500       0.0438       0.0428     0.000971        0.293         4.99       0.0546
     17   600         0.03       0.0299     0.000123         0.25         0.64        0.017
     17   700       0.0266       0.0262      0.00044        0.232         2.36       0.0299
     17   800       0.0193       0.0192     0.000111        0.201        0.775       0.0144
     17   801        0.026       0.0255      0.00051        0.221         1.53       0.0327

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17   100       0.0396       0.0391     0.000504        0.292         3.05       0.0324
     17   102       0.0316       0.0316      4.8e-05        0.262        0.643       0.0134


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              17 2302.559    0.004       0.0346     0.000703       0.0353        0.263         2.34        0.038
! Validation         17 2302.559    0.004       0.0304     0.000333       0.0307        0.251         1.59       0.0265
Wall time: 2302.5619560908526

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18   100         0.03       0.0299     0.000159        0.252        0.973       0.0194
     18   200       0.0317       0.0316     8.05e-05        0.265        0.792       0.0143
     18   300        0.036       0.0359     0.000108        0.275         1.04       0.0157
     18   400       0.0269       0.0258      0.00101        0.227         3.49       0.0607
     18   500       0.0209       0.0206     0.000292        0.209         2.45       0.0316
     18   600       0.0346       0.0344     0.000268        0.275         1.51       0.0273
     18   700       0.0293       0.0278      0.00146        0.252         4.82       0.0724
     18   800       0.0281       0.0269      0.00118        0.229         2.59       0.0654
     18   801       0.0227       0.0222     0.000551        0.205         1.78       0.0432

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18   100       0.0417       0.0413     0.000448        0.301          2.9       0.0333
     18   102       0.0371        0.037     0.000145        0.277        0.934       0.0195


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              18 2435.030    0.004       0.0346     0.000665       0.0353        0.265         2.22       0.0368
! Validation         18 2435.030    0.004       0.0329       0.0003       0.0332        0.263         1.58       0.0246
Wall time: 2435.0304146970157

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19   100       0.0469       0.0462     0.000737        0.307         2.65       0.0395
     19   200       0.0342       0.0313      0.00295         0.25         4.01       0.0978
     19   300       0.0327       0.0326     8.22e-05         0.26        0.633        0.014
     19   400       0.0162        0.016     0.000228        0.177        0.922       0.0256
     19   500       0.0479       0.0476     0.000362        0.317         1.79       0.0287
     19   600       0.0409       0.0386      0.00227        0.286         9.07       0.0896
     19   700       0.0316       0.0305      0.00113        0.251         2.78       0.0584
     19   800       0.0339       0.0336     0.000356        0.265         2.17       0.0227
     19   801       0.0336       0.0329     0.000771        0.266         3.22       0.0497

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19   100       0.0638       0.0535       0.0103        0.342         14.1        0.192
     19   102       0.0463       0.0364      0.00995        0.287         9.25        0.193


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              19 2566.524    0.004       0.0351     0.000861        0.036        0.269         2.48       0.0411
! Validation         19 2566.524    0.004       0.0461       0.0119        0.058        0.306         12.1        0.206
Wall time: 2566.5250905209687

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20   100       0.0328       0.0324     0.000383         0.26         1.18       0.0244
     20   200       0.0247       0.0237        0.001         0.22         2.68        0.059
     20   300       0.0213       0.0203     0.000957        0.209         3.18       0.0554
     20   400       0.0208       0.0207     0.000121        0.203        0.821       0.0186
     20   500       0.0307       0.0303     0.000401        0.241         2.27        0.035
     20   600       0.0343       0.0337     0.000646        0.268         3.66       0.0417
     20   700       0.0394        0.038      0.00139        0.282         2.97       0.0661
     20   800       0.0338       0.0332     0.000686        0.262         3.64       0.0494
     20   801        0.046       0.0433      0.00264        0.294         16.9       0.0993

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20   100       0.0397       0.0395     0.000172        0.297         2.04       0.0204
     20   102       0.0334       0.0332      0.00019        0.273         1.22       0.0255


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              20 2699.019    0.004       0.0332     0.000777        0.034         0.26         2.45       0.0408
! Validation         20 2699.019    0.004       0.0317     0.000244        0.032        0.258          1.7       0.0237
Wall time: 2699.019263506867

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21   100       0.0396       0.0395     8.75e-05        0.269        0.677       0.0121
     21   200       0.0228       0.0228     6.61e-05        0.223        0.601       0.0124
     21   300       0.0339       0.0335     0.000447        0.249         1.67       0.0381
     21   400        0.036       0.0352      0.00081        0.279         3.21       0.0533
     21   500       0.0302       0.0298     0.000452        0.247         2.56       0.0389
     21   600       0.0208       0.0208     7.89e-05        0.208        0.687       0.0141
     21   700       0.0241       0.0236      0.00043        0.226          2.9       0.0379
     21   800       0.0398       0.0397     0.000114        0.296         1.14        0.019
     21   801       0.0151       0.0144     0.000728        0.161         1.18       0.0422

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21   100       0.0376        0.037     0.000616        0.288         2.53       0.0415
     21   102       0.0307         0.03     0.000706        0.261         2.39       0.0497


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              21 2831.161    0.004       0.0315     0.000621       0.0321        0.253         2.24       0.0367
! Validation         21 2831.161    0.004       0.0303     0.000935       0.0312        0.251         2.97       0.0533
Wall time: 2831.1620988720097

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22   100       0.0305       0.0301     0.000464        0.252         1.78        0.038
     22   200       0.0372       0.0367      0.00051        0.275          2.6       0.0341
     22   300       0.0268       0.0267      0.00017         0.23         1.66       0.0236
     22   400       0.0321       0.0315     0.000666        0.259         3.27       0.0446
     22   500       0.0296       0.0294     0.000157         0.26         1.82         0.02
     22   600       0.0234       0.0234     3.41e-05        0.221        0.448       0.0101
     22   700       0.0371       0.0348      0.00233        0.254         4.32       0.0872
     22   800       0.0313       0.0302      0.00109        0.237         4.97        0.051
     22   801       0.0341       0.0339     0.000182        0.275        0.914        0.019

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22   100       0.0365       0.0359     0.000562        0.282         3.44       0.0375
     22   102       0.0338       0.0337     0.000132        0.271        0.892       0.0186


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              22 2963.323    0.004       0.0311     0.000623       0.0318        0.252         2.22       0.0366
! Validation         22 2963.323    0.004       0.0279     0.000267       0.0282         0.24         1.57       0.0229
Wall time: 2963.3233252449427

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23   100       0.0429       0.0414      0.00144        0.292         4.97        0.072
     23   200       0.0239       0.0237     0.000228         0.22         1.15       0.0241
     23   300       0.0344       0.0341     0.000242        0.272         1.72       0.0293
     23   400       0.0371       0.0368     0.000294        0.278         1.95       0.0309
     23   500       0.0309       0.0302     0.000756        0.243         1.75       0.0418
     23   600       0.0341       0.0339     0.000201        0.266         2.37       0.0242
     23   700       0.0358       0.0346      0.00117        0.277          3.7       0.0643
     23   800       0.0537       0.0516      0.00216        0.332         5.55       0.0849
     23   801       0.0223       0.0181      0.00423        0.185         4.68        0.125

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23   100       0.0365       0.0363     0.000213        0.283          1.6       0.0199
     23   102       0.0279       0.0279      3.7e-05        0.249        0.414      0.00862


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              23 3096.366    0.004        0.031      0.00065       0.0316        0.252         2.17       0.0361
! Validation         23 3096.366    0.004       0.0297      0.00026       0.0299        0.249         1.29       0.0232
Wall time: 3096.3680419619195

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24   100       0.0327       0.0317     0.000991        0.252         2.99       0.0504
     24   200       0.0317       0.0315     0.000166        0.246         1.21       0.0225
     24   300       0.0552       0.0536      0.00166        0.287         3.52       0.0355
     24   400       0.0244        0.021       0.0034        0.208          5.9        0.111
     24   500       0.0361       0.0356     0.000461        0.269         1.79       0.0353
     24   600       0.0396       0.0395     5.68e-05        0.287        0.664       0.0126
     24   700       0.0269       0.0262     0.000694         0.24          2.3        0.048
     24   800       0.0363       0.0358     0.000569        0.277         2.58       0.0427
     24   801       0.0242       0.0222      0.00197        0.207         3.35       0.0797

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24   100       0.0424       0.0419      0.00045        0.305         2.72       0.0328
     24   102        0.038       0.0379     9.87e-05        0.288        0.847       0.0177


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              24 3229.251    0.004       0.0317     0.000752       0.0325        0.254         2.34       0.0387
! Validation         24 3229.251    0.004       0.0336     0.000374        0.034        0.265          1.9       0.0287
Wall time: 3229.2537076158915

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25   100       0.0449       0.0447     0.000221         0.26         1.74       0.0244
     25   200       0.0346       0.0342     0.000394        0.269         2.06       0.0242
     25   300       0.0273       0.0246      0.00269        0.216         5.23       0.0995
     25   400        0.024       0.0236     0.000422        0.226         1.93        0.035
     25   500        0.026       0.0252     0.000835        0.219         2.69       0.0552
     25   600        0.031       0.0304     0.000529        0.255         2.87       0.0302
     25   700       0.0303       0.0302     6.24e-05        0.244        0.705       0.0138
     25   800       0.0311       0.0304     0.000721        0.244         2.45       0.0461
     25   801       0.0378       0.0377     9.61e-05        0.282         1.02       0.0166

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25   100       0.0334        0.033     0.000402         0.27         2.68       0.0344
     25   102        0.027       0.0269     0.000145        0.241        0.956       0.0199


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              25 3360.342    0.004       0.0302     0.000551       0.0308        0.248         2.12        0.035
! Validation         25 3360.342    0.004       0.0262     0.000299       0.0265        0.232         1.74       0.0276
Wall time: 3360.342067434918

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26   100       0.0384       0.0383     4.39e-05        0.278        0.545      0.00987
     26   200       0.0224       0.0204      0.00196        0.206         3.89       0.0835
     26   300       0.0336       0.0331     0.000439        0.258         3.07       0.0285
     26   400       0.0173       0.0162      0.00111        0.174         2.72       0.0587
     26   500       0.0339       0.0339     5.51e-05        0.264        0.683       0.0125
     26   600       0.0381       0.0372     0.000878        0.281         3.72       0.0517
     26   700       0.0306       0.0305     9.64e-05         0.25         1.22       0.0173
     26   800       0.0373       0.0362      0.00118        0.272         2.52       0.0553
     26   801       0.0211       0.0184      0.00266        0.196          7.1       0.0988

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26   100       0.0352        0.035     0.000191        0.277         1.67       0.0199
     26   102       0.0272       0.0272     5.05e-05        0.246        0.617       0.0129


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              26 3494.764    0.004         0.03     0.000534       0.0306        0.248         2.04       0.0334
! Validation         26 3494.764    0.004        0.027     0.000178       0.0271        0.235         1.13       0.0183
Wall time: 3494.7648019359913

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27   100       0.0241        0.024     0.000121        0.222          1.1       0.0197
     27   200       0.0304       0.0296     0.000838         0.25         2.25       0.0456
     27   300        0.038       0.0377     0.000317        0.288         2.02         0.03
     27   400       0.0351        0.035      8.8e-05        0.263        0.499       0.0123
     27   500       0.0246       0.0245     0.000105        0.222        0.655       0.0168
     27   600       0.0418       0.0412     0.000597        0.306         3.69       0.0391
     27   700       0.0269       0.0249        0.002        0.228         2.99       0.0734
     27   800       0.0233        0.023     0.000329        0.216         1.35        0.031
     27   801       0.0805       0.0782      0.00236        0.409         7.66       0.0894

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27   100        0.064       0.0569      0.00702        0.357         8.76         0.15
     27   102       0.0514       0.0425      0.00897        0.302         8.77        0.183


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              27 3628.515    0.004       0.0351      0.00115       0.0362        0.267         2.47       0.0421
! Validation         27 3628.515    0.004       0.0455       0.0107       0.0563         0.31         10.1        0.186
Wall time: 3628.5154706758913

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28   100       0.0365       0.0361     0.000336        0.278         1.58       0.0316
     28   200       0.0339       0.0337     0.000136        0.267         1.18       0.0198
     28   300       0.0386       0.0371      0.00148        0.263         2.89       0.0689
     28   400       0.0254       0.0243      0.00108        0.232          3.8       0.0634
     28   500       0.0285       0.0282      0.00031        0.245         1.12       0.0287
     28   600       0.0325       0.0321     0.000397        0.259          2.8       0.0359
     28   700       0.0267       0.0262     0.000514        0.232         1.74       0.0418
     28   800       0.0412       0.0407      0.00047        0.259         2.05       0.0264
     28   801       0.0195       0.0194     0.000126         0.21         1.48       0.0212

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28   100        0.034       0.0336     0.000441        0.273         2.64       0.0374
     28   102       0.0275       0.0268     0.000673        0.249          2.4       0.0501


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              28 3760.828    0.004       0.0318     0.000851       0.0326        0.255         2.62       0.0439
! Validation         28 3760.828    0.004       0.0277      0.00079       0.0285        0.239         3.18        0.051
Wall time: 3760.828349869

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29   100       0.0317       0.0316     0.000126        0.264        0.746       0.0152
     29   200       0.0218       0.0212     0.000601        0.202          1.9       0.0449
     29   300       0.0475       0.0469     0.000646        0.229         2.46       0.0478
     29   400       0.0234       0.0231     0.000254        0.219          1.5       0.0277
     29   500       0.0158       0.0156     0.000189        0.175         1.06       0.0245
     29   600       0.0276       0.0274     0.000179        0.244         1.33        0.021
     29   700       0.0292        0.029     0.000234        0.249         1.16       0.0228
     29   800       0.0285       0.0285     1.53e-05        0.236        0.339      0.00595
     29   801       0.0419       0.0418      7.4e-05        0.289        0.989       0.0164

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29   100       0.0326       0.0323      0.00026        0.268         1.66       0.0253
     29   102       0.0266       0.0263     0.000242         0.24         1.37       0.0285


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              29 3893.361    0.004       0.0295     0.000622       0.0301        0.245         2.17       0.0362
! Validation         29 3893.361    0.004       0.0258     0.000323       0.0261        0.231          1.6       0.0288
Wall time: 3893.3615484850015

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30   100       0.0332       0.0324     0.000785        0.243         3.02       0.0534
     30   200       0.0372        0.037     0.000163        0.273        0.971       0.0182
     30   300       0.0278       0.0275     0.000259        0.234         1.49       0.0277
     30   400       0.0387       0.0373      0.00139        0.281         2.59       0.0594
     30   500       0.0361       0.0358     0.000304        0.267         1.83       0.0321
     30   600       0.0354       0.0351     0.000334        0.263         1.53       0.0307
     30   700       0.0506       0.0491      0.00154        0.296         4.99       0.0601
     30   800       0.0295       0.0292     0.000276         0.25         1.45       0.0253
     30   801       0.0515        0.049      0.00253        0.319         4.97       0.0924

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30   100       0.0369       0.0359      0.00103        0.284         4.34       0.0602
     30   102       0.0307         0.03     0.000631        0.257         2.06       0.0429


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              30 4028.304    0.004       0.0342     0.000752        0.035        0.254         2.34       0.0383
! Validation         30 4028.304    0.004       0.0287      0.00104       0.0297        0.245         3.47       0.0559
Wall time: 4028.3041643090546

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31   100       0.0232        0.023     0.000136        0.224         1.19        0.019
     31   200       0.0256       0.0255     0.000185        0.233         1.51         0.02
     31   300        0.026       0.0255     0.000504        0.237         1.96       0.0363
     31   400       0.0138       0.0137     7.01e-05        0.171         0.56       0.0145
     31   500       0.0227       0.0226     0.000154        0.211        0.862        0.021
     31   600       0.0276       0.0275     9.61e-05        0.213         0.79       0.0168
     31   700       0.0283       0.0281     0.000222        0.243         1.33       0.0243
     31   800       0.0193       0.0191     0.000151        0.182        0.799       0.0198
     31   801       0.0273       0.0273     2.85e-06        0.245        0.156      0.00324

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31   100       0.0324       0.0321     0.000214        0.268         1.67       0.0242
     31   102       0.0224       0.0219     0.000444        0.218         1.87        0.039


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              31 4162.429    0.004       0.0287     0.000553       0.0293        0.241         2.13       0.0354
! Validation         31 4162.429    0.004       0.0262     0.000292       0.0265        0.234         1.73       0.0276
Wall time: 4162.429637894966

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32   100       0.0303       0.0297     0.000592        0.247         2.86       0.0449
     32   200       0.0247       0.0244     0.000214        0.215         1.48       0.0256
     32   300       0.0266       0.0251      0.00154        0.227         3.82       0.0741
     32   400       0.0261       0.0261     7.97e-05        0.234        0.816       0.0149
     32   500       0.0155       0.0155     7.64e-05        0.176        0.568       0.0126
     32   600       0.0249       0.0246     0.000268        0.219         1.56       0.0303
     32   700       0.0253       0.0248     0.000496         0.22         2.12       0.0397
     32   800       0.0371       0.0368     0.000325        0.274         1.86       0.0272
     32   801       0.0267       0.0265     0.000258        0.239         1.07       0.0223

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32   100       0.0338       0.0336     0.000157         0.27         1.71       0.0181
     32   102       0.0265       0.0265     5.14e-05        0.242        0.617       0.0128


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              32 4294.105    0.004       0.0284     0.000538       0.0289         0.24         1.94       0.0318
! Validation         32 4294.105    0.004       0.0268     0.000148        0.027        0.235         1.09        0.017
Wall time: 4294.10517629399
! Best model       32    0.017

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33   100       0.0332       0.0327     0.000524        0.257         1.98       0.0401
     33   200       0.0257        0.025     0.000709         0.23         2.93       0.0463
     33   300       0.0196       0.0195     0.000128         0.19         1.02       0.0174
     33   400       0.0304       0.0303     9.59e-05        0.252         2.11       0.0147
     33   500        0.026       0.0253     0.000686         0.23         2.35       0.0456
     33   600       0.0322       0.0319     0.000261        0.257         1.91        0.029
     33   700       0.0223       0.0216     0.000669        0.212         2.32        0.032
     33   800       0.0352       0.0349     0.000237        0.265         1.21       0.0256
     33   801       0.0452       0.0445     0.000687        0.313         3.89       0.0507

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33   100       0.0321        0.032     5.57e-05        0.264         1.08       0.0124
     33   102       0.0227       0.0227     3.13e-05        0.228        0.446       0.0093


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              33 4428.064    0.004       0.0269     0.000369       0.0273        0.235         1.72       0.0282
! Validation         33 4428.064    0.004       0.0265     9.17e-05       0.0266        0.231        0.869       0.0129
Wall time: 4428.064008632908
! Best model       33    0.013

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34   100       0.0312       0.0311     0.000149        0.246         1.14       0.0187
     34   200       0.0265       0.0258     0.000644        0.239         2.09       0.0459
     34   300        0.024       0.0234     0.000662        0.223         1.91       0.0393
     34   400       0.0481       0.0478     0.000284        0.307         1.97       0.0296
     34   500       0.0385       0.0382     0.000318        0.279         1.86       0.0263
     34   600       0.0286       0.0284     0.000278         0.23         1.23       0.0257
     34   700       0.0224        0.022     0.000475        0.203         1.81       0.0393
     34   800       0.0315       0.0312     0.000269        0.253         1.93       0.0234
     34   801       0.0308       0.0305     0.000298        0.253         3.29       0.0313

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34   100       0.0358       0.0354     0.000388         0.28         2.12       0.0341
     34   102       0.0297        0.029     0.000726        0.251         2.29       0.0476


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              34 4559.896    0.004       0.0297     0.000537       0.0302        0.247         2.08       0.0338
! Validation         34 4559.896    0.004       0.0268     0.000604       0.0274        0.235         2.35       0.0421
Wall time: 4559.896483159857

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35   100       0.0397       0.0395     0.000216        0.272         1.68       0.0243
     35   200       0.0283       0.0281     0.000118        0.243        0.928       0.0178
     35   300       0.0183       0.0177     0.000594        0.191         1.69       0.0424
     35   400        0.026       0.0257     0.000268        0.228         1.81       0.0289
     35   500       0.0247       0.0246     0.000173         0.23        0.873       0.0176
     35   600       0.0333       0.0328     0.000583        0.244         2.49        0.045
     35   700       0.0296        0.029     0.000597        0.237         3.38       0.0419
     35   800       0.0222       0.0221     7.18e-05        0.214         0.72       0.0144
     35   801       0.0146       0.0146     2.58e-05        0.172        0.374       0.0086

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35   100       0.0325       0.0324     0.000105        0.267         1.29       0.0176
     35   102       0.0284       0.0283     0.000145         0.25        0.844       0.0176


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              35 4692.501    0.004        0.027     0.000393       0.0274        0.235         1.77       0.0289
! Validation         35 4692.501    0.004       0.0259     0.000253       0.0261        0.231         1.35       0.0246
Wall time: 4692.503383300966

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36   100       0.0357       0.0353      0.00037        0.244         1.81       0.0322
     36   200       0.0327       0.0325     0.000237        0.261         2.12       0.0204
     36   300        0.026       0.0259     4.56e-05        0.233         1.04       0.0104
     36   400       0.0465       0.0464     1.78e-05        0.272        0.457      0.00691
     36   500       0.0221       0.0217     0.000393          0.2         1.17       0.0335
     36   600       0.0253       0.0251     0.000234        0.226         1.64       0.0262
     36   700       0.0299       0.0298     8.31e-05        0.247        0.729       0.0142
     36   800       0.0186       0.0183      0.00026        0.191        0.875       0.0241
     36   801       0.0298       0.0298     8.44e-06        0.255        0.262      0.00546

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36   100       0.0334       0.0315      0.00196        0.264         6.26       0.0846
     36   102       0.0257       0.0241      0.00159        0.231         3.68       0.0767


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              36 4824.066    0.004       0.0274     0.000452       0.0279        0.236          1.9       0.0319
! Validation         36 4824.066    0.004       0.0252      0.00188       0.0271        0.227         5.02       0.0817
Wall time: 4824.066752851009

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37   100         0.02       0.0197     0.000278        0.202         1.05       0.0251
     37   200       0.0355       0.0342      0.00125        0.267         3.22       0.0598
     37   300       0.0282       0.0279     0.000285        0.248         1.27       0.0285
     37   400       0.0305       0.0303     0.000188        0.257         1.94       0.0214
     37   500       0.0277       0.0275     0.000263        0.246         1.41       0.0229
     37   600       0.0463        0.046     0.000335        0.288         1.97       0.0306
     37   700       0.0356       0.0354     0.000235        0.274         1.45       0.0258
     37   800       0.0303       0.0302     0.000123        0.248        0.786       0.0175
     37   801       0.0167       0.0166     3.43e-05        0.184        0.403      0.00869

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37   100        0.033       0.0327     0.000349        0.271         2.46        0.035
     37   102       0.0216       0.0209     0.000696        0.218         2.41       0.0502


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              37 4956.468    0.004       0.0292     0.000545       0.0297        0.244            2       0.0334
! Validation         37 4956.468    0.004       0.0264     0.000523       0.0269        0.234         2.57       0.0398
Wall time: 4956.469071771018

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38   100       0.0277       0.0276     0.000101        0.229         0.71        0.016
     38   200       0.0193       0.0183     0.000939        0.192         6.71       0.0584
     38   300       0.0184       0.0178     0.000589        0.187         1.41       0.0395
     38   400       0.0171       0.0168     0.000327        0.182         2.11       0.0306
     38   500       0.0249       0.0248     0.000157        0.233        0.967       0.0206
     38   600       0.0513       0.0493      0.00206         0.27         4.61       0.0801
     38   700       0.0241       0.0231     0.000992        0.216         2.87       0.0565
     38   800       0.0508       0.0467      0.00415        0.289         5.36       0.0576
     38   801       0.0301         0.03     0.000105        0.269         1.48       0.0196

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38   100       0.0349       0.0326      0.00233        0.268         5.76       0.0896
     38   102       0.0298       0.0267       0.0031        0.244         5.09        0.106


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              38 5090.919    0.004       0.0286     0.000684       0.0293        0.242         2.33       0.0387
! Validation         38 5090.919    0.004       0.0257      0.00295       0.0286        0.229         6.04        0.103
Wall time: 5090.91998779797

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39   100       0.0205       0.0203      0.00021        0.208         1.68       0.0217
     39   200       0.0184       0.0183     0.000146        0.199         1.51       0.0216
     39   300       0.0321       0.0305      0.00161         0.24         3.58       0.0502
     39   400       0.0262       0.0255     0.000693        0.225         2.64       0.0445
     39   500       0.0264        0.026     0.000405         0.23         1.37       0.0325
     39   600       0.0342       0.0338     0.000406        0.255          1.8       0.0365
     39   700       0.0205       0.0202     0.000304        0.206         1.75       0.0306
     39   800       0.0252       0.0239      0.00127        0.217         3.74       0.0661
     39   801       0.0289       0.0289     8.65e-06        0.243        0.183      0.00533

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39   100       0.0328       0.0326     0.000197        0.267         1.91       0.0226
     39   102       0.0244       0.0244     3.49e-05        0.229        0.388      0.00809


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              39 5225.079    0.004       0.0265     0.000489        0.027        0.233            2       0.0331
! Validation         39 5225.079    0.004       0.0248     0.000144        0.025        0.226         1.09       0.0168
Wall time: 5225.079076108057

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40   100       0.0201       0.0189      0.00116        0.194         3.58       0.0649
     40   200       0.0148       0.0147     8.18e-05        0.177        0.504       0.0145
     40   300       0.0352       0.0346     0.000543        0.272         2.13       0.0395
     40   400       0.0223       0.0222     0.000105        0.203        0.893       0.0164
     40   500       0.0324       0.0319     0.000519        0.259         2.26       0.0411
     40   600        0.031       0.0302     0.000812        0.252         2.73       0.0519
     40   700        0.029        0.029     2.05e-05        0.231        0.429      0.00807
     40   800       0.0266       0.0265     3.29e-05        0.236        0.643      0.00971
     40   801       0.0319       0.0319     2.12e-05        0.271        0.377      0.00786

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40   100       0.0313       0.0311      0.00014        0.263         1.46       0.0182
     40   102       0.0262       0.0262     2.33e-05        0.245        0.421      0.00878


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              40 5358.717    0.004       0.0265     0.000378       0.0269        0.231         1.73       0.0289
! Validation         40 5358.717    0.004       0.0244     0.000123       0.0245        0.223        0.929        0.015
Wall time: 5358.717798335943

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41   100       0.0245       0.0241     0.000432        0.221         1.49       0.0351
     41   200       0.0255       0.0251     0.000398        0.231         2.18       0.0369
     41   300        0.032       0.0318     0.000187        0.261         1.36       0.0232
     41   400       0.0301       0.0299     0.000217         0.25          1.2        0.025
     41   500       0.0248        0.024     0.000787        0.222         2.09       0.0458
     41   600       0.0264       0.0262     0.000211        0.233         1.13       0.0215
     41   700       0.0401       0.0399     0.000172        0.287          1.2       0.0198
     41   800        0.019       0.0189     0.000139        0.187        0.778       0.0191
     41   801       0.0201       0.0199     0.000183         0.21         1.86       0.0261

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41   100       0.0318       0.0317     8.04e-05        0.266        0.979        0.013
     41   102       0.0313       0.0312     4.27e-05        0.264        0.593       0.0123


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              41 5491.826    0.004       0.0277     0.000582       0.0283        0.238         2.11       0.0351
! Validation         41 5491.826    0.004        0.027     0.000127       0.0271        0.235         1.01       0.0158
Wall time: 5491.827025462873

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42   100       0.0304       0.0303     6.39e-05        0.253        0.841       0.0119
     42   200       0.0259       0.0258     6.62e-05        0.233        0.816       0.0136
     42   300       0.0245       0.0244     7.66e-05        0.221        0.547        0.014
     42   400       0.0222       0.0219     0.000269        0.215         1.24       0.0276
     42   500        0.032       0.0319     8.62e-05        0.262        0.838       0.0152
     42   600       0.0218       0.0211     0.000741        0.196         2.55       0.0514
     42   700        0.023       0.0229     0.000104        0.217        0.919       0.0172
     42   800       0.0343       0.0339     0.000393        0.268          2.4       0.0337
     42   801       0.0226       0.0226     1.93e-05        0.215        0.629      0.00821

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42   100       0.0331       0.0329     0.000172        0.275         1.59       0.0173
     42   102       0.0239       0.0239     7.16e-06        0.231          0.2      0.00416


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              42 5625.734    0.004       0.0315     0.000759       0.0322        0.249         2.21       0.0366
! Validation         42 5625.734    0.004       0.0278       0.0004       0.0282        0.242         1.58       0.0278
Wall time: 5625.7348349639215

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43   100       0.0388       0.0356      0.00315        0.269          5.6        0.105
     43   200       0.0266       0.0264       0.0002        0.239         1.64       0.0224
     43   300       0.0223       0.0222     8.99e-05        0.219        0.683       0.0124
     43   400       0.0512       0.0495       0.0017        0.284          4.4       0.0638
     43   500       0.0187       0.0186     8.31e-05          0.2        0.882       0.0172
     43   600       0.0245       0.0244     7.06e-05        0.228         1.06       0.0133
     43   700       0.0351       0.0337      0.00144        0.253         7.88       0.0721
     43   800       0.0256       0.0255     0.000153        0.227         1.27       0.0226
     43   801       0.0398       0.0389      0.00088        0.298         2.75       0.0573

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43   100       0.0318       0.0316     0.000287        0.265         2.02       0.0289
     43   102       0.0239       0.0233     0.000549        0.228         2.07        0.043


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              43 5758.245    0.004       0.0285      0.00056       0.0291        0.242         1.99       0.0334
! Validation         43 5758.245    0.004       0.0267     0.000413       0.0271        0.235         2.22       0.0352
Wall time: 5758.245339164045

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44   100       0.0319       0.0317      0.00026        0.242          1.8       0.0274
     44   200       0.0278       0.0268     0.000979        0.236         3.84       0.0557
     44   300       0.0251       0.0247     0.000403        0.224         2.03       0.0363
     44   400       0.0257       0.0249     0.000714        0.232         2.71       0.0388
     44   500       0.0238       0.0237     0.000136        0.227         1.13       0.0172
     44   600       0.0137       0.0134     0.000278        0.167         1.07       0.0286
     44   700       0.0241        0.024     8.39e-05        0.219        0.858        0.015
     44   800        0.023       0.0226     0.000419        0.213         2.02       0.0368
     44   801       0.0361       0.0361     3.19e-05        0.282        0.882      0.00955

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44   100       0.0317       0.0311     0.000592        0.262         2.98       0.0439
     44   102       0.0238       0.0229     0.000873        0.225         2.69       0.0561


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              44 5892.875    0.004       0.0268     0.000389       0.0271        0.233         1.78       0.0293
! Validation         44 5892.875    0.004       0.0243     0.000816       0.0251        0.223         3.22       0.0532
Wall time: 5892.875665901927

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45   100       0.0215       0.0214     0.000118        0.212        0.808       0.0186
     45   200       0.0249       0.0246     0.000344        0.225          1.5       0.0343
     45   300       0.0238       0.0231     0.000763        0.222          3.7       0.0512
     45   400       0.0253       0.0247     0.000524        0.213         1.96       0.0414
     45   500       0.0216       0.0214     0.000117        0.216        0.851       0.0156
     45   600       0.0287       0.0278     0.000897         0.24         5.26       0.0501
     45   700       0.0303       0.0293     0.000975        0.251         3.12        0.058
     45   800       0.0202       0.0201     0.000106        0.211        0.815       0.0162
     45   801       0.0162       0.0161     0.000124        0.164        0.836       0.0213

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45   100        0.032       0.0318     0.000244        0.264         1.66       0.0256
     45   102       0.0252       0.0248     0.000384        0.238          1.7       0.0353


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              45 6025.930    0.004       0.0269     0.000455       0.0274        0.233         1.91       0.0316
! Validation         45 6025.930    0.004       0.0254     0.000314       0.0257        0.229         1.67       0.0277
Wall time: 6025.931935803965

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46   100       0.0268       0.0266     0.000149        0.235        0.921       0.0175
     46   200       0.0245       0.0245     5.11e-05        0.225        0.546       0.0114
     46   300       0.0367        0.036     0.000626        0.273         2.33       0.0448
     46   400       0.0161        0.016     0.000116        0.189         1.07       0.0142
     46   500       0.0192        0.019     0.000197        0.195         1.22       0.0254
     46   600       0.0239       0.0234     0.000451        0.209         1.52       0.0383
     46   700       0.0264       0.0257     0.000701        0.234         2.56        0.048
     46   800       0.0277       0.0276     8.47e-05        0.246        0.796        0.016
     46   801       0.0084      0.00822     0.000174         0.13        0.925       0.0252

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46   100       0.0298       0.0297     0.000125        0.256          1.4       0.0166
     46   102        0.022        0.022     3.69e-05        0.223        0.547       0.0114


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              46 6158.487    0.004       0.0249     0.000348       0.0252        0.225         1.68       0.0275
! Validation         46 6158.487    0.004       0.0235     0.000139       0.0237        0.219        0.974       0.0166
Wall time: 6158.487532119965

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47   100       0.0374       0.0371     0.000285        0.256          2.5       0.0292
     47   200       0.0321       0.0318     0.000381        0.243         1.72       0.0344
     47   300        0.029       0.0285      0.00055         0.24         2.38       0.0438
     47   400       0.0333       0.0332      0.00018        0.262         1.43        0.022
     47   500       0.0252       0.0249     0.000261        0.222         1.92       0.0225
     47   600       0.0277       0.0275     0.000235        0.233         1.31       0.0275
     47   700       0.0157       0.0142      0.00143        0.162          2.7       0.0708
     47   800       0.0286       0.0285     2.98e-05        0.242        0.427      0.00845
     47   801       0.0209       0.0208     6.12e-05        0.213         1.06       0.0141

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47   100       0.0328       0.0327     7.27e-05         0.27          1.1        0.013
     47   102       0.0264       0.0263     5.57e-05        0.246        0.575        0.012


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              47 6290.565    0.004       0.0257     0.000419       0.0261         0.23         1.71       0.0283
! Validation         47 6290.565    0.004       0.0259     0.000113        0.026        0.232        0.988       0.0158
Wall time: 6290.565181449056

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48   100       0.0303       0.0301      0.00019        0.258         1.61       0.0223
     48   200        0.022       0.0207      0.00125        0.207         2.99       0.0625
     48   300       0.0174       0.0171     0.000311        0.184          1.1       0.0295
     48   400       0.0335       0.0335     6.35e-05        0.264        0.438      0.00951
     48   500       0.0238       0.0237     0.000125        0.229        0.998       0.0195
     48   600       0.0182        0.018     0.000204        0.198         1.32       0.0259
     48   700        0.036       0.0355     0.000494        0.262         2.12       0.0235
     48   800       0.0335       0.0332     0.000215        0.246         1.36       0.0214
     48   801       0.0725       0.0719     0.000578        0.366         3.71       0.0393

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48   100       0.0291        0.029     6.41e-05        0.253         1.03       0.0136
     48   102       0.0198       0.0198     1.31e-05         0.21        0.322       0.0067


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              48 6423.290    0.004       0.0253     0.000365       0.0256        0.228         1.69       0.0277
! Validation         48 6423.290    0.004       0.0235     0.000116       0.0236         0.22        0.861       0.0154
Wall time: 6423.290525737917

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49   100        0.026       0.0259     7.33e-05        0.234        0.804       0.0143
     49   200       0.0287       0.0285     0.000139        0.249         1.16       0.0205
     49   300       0.0242       0.0241     0.000176        0.223         1.53       0.0228
     49   400       0.0167       0.0165     0.000156        0.184        0.854       0.0212
     49   500       0.0253       0.0252     0.000121        0.223          1.2       0.0172
     49   600       0.0524       0.0511      0.00125        0.325         4.57       0.0635
     49   700       0.0215       0.0214     9.36e-05        0.211        0.611        0.016
     49   800       0.0319       0.0319     3.38e-05         0.26         1.32         0.01
     49   801       0.0372       0.0372     3.22e-05        0.295        0.521       0.0109

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49   100       0.0491       0.0447      0.00437        0.309         8.38        0.125
     49   102       0.0389       0.0339      0.00504        0.272         6.55        0.137


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              49 6555.622    0.004       0.0273     0.000526       0.0278        0.235         1.91       0.0316
! Validation         49 6555.622    0.004       0.0362      0.00505       0.0412        0.274         7.69        0.134
Wall time: 6555.624374551931

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50   100        0.024       0.0239     7.33e-05        0.227        0.746       0.0141
     50   200       0.0217       0.0213     0.000438        0.204          2.2       0.0374
     50   300        0.032       0.0312     0.000763         0.25         2.93       0.0486
     50   400       0.0189       0.0187     0.000207        0.191         1.21       0.0208
     50   500       0.0257       0.0247      0.00105        0.232         3.69       0.0619
     50   600       0.0269       0.0265     0.000434        0.232          2.1       0.0375
     50   700       0.0234       0.0232     0.000228        0.217         1.36       0.0264
     50   800       0.0333       0.0328     0.000544        0.255         2.11       0.0326
     50   801       0.0465       0.0465     5.53e-05        0.295         0.43        0.013

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50   100       0.0346       0.0344     0.000232        0.278         1.98       0.0229
     50   102        0.031       0.0309     3.58e-05        0.259        0.541       0.0113


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              50 6688.511    0.004       0.0287     0.000925       0.0296        0.237         2.35       0.0397
! Validation         50 6688.511    0.004         0.03     0.000222       0.0302        0.242         1.25       0.0215
Wall time: 6688.513293416938
! Stop training: max epochs
Wall time: 6688.561986366054
Cumulative wall time: 6688.561986366054
Training QAT Model...
After QAT training...
Traceback (most recent call last):
  File "/mnt/yujie.zeng/project_2023/qat_allegro/allegro/allegro/scripts/train_qat.py", line 620, in <module>
    main(running_as_script=True)
  File "/mnt/yujie.zeng/project_2023/qat_allegro/allegro/allegro/scripts/train_qat.py", line 355, in main
    qat_train(trainer, config)
  File "/mnt/yujie.zeng/project_2023/qat_allegro/allegro/allegro/scripts/train_qat.py", line 134, in qat_train
    evaluate(trainer, config)
  File "/mnt/yujie.zeng/project_2023/qat_allegro/allegro/allegro/scripts/train_qat.py", line 140, in evaluate
    global_config = Config.from_file(str(global_config), defaults=default_config)
  File "/mnt/hwl/anaconda3/envs/zyj/lib/python3.9/site-packages/nequip/utils/config.py", line 260, in from_file
    dictionary = load_file(
  File "/mnt/hwl/anaconda3/envs/zyj/lib/python3.9/site-packages/nequip/utils/savenload.py", line 259, in load_file
    raise OSError(f"file {filename} at {abs_path} is not found")
OSError: file /mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs16/config.yaml at /mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs16/config.yaml is not found
