Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat_bs4', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs4', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 4, 'max_epochs': 100, 'learning_rate': 0.005, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_e/N_mae', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat_bs4', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs4', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 4, 'max_epochs': 100, 'learning_rate': 0.005, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_e/N_mae', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False, 'dataset_extra_fixed_fields': {'r_max': 6.0}, 'validation_dataset_extra_fixed_fields': {'r_max': 6.0}, 'dataset_config': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml', 'metrics_config': PosixPath('/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml'), 'base_model_file': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/best_model.pth', 'output_fields': []}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
RescaleOutput(
  (model): GradientOutput(
    (func): SequentialGraphNetwork(
      (one_hot): OneHotAtomEncoding()
      (radial_basis): RadialBasisEdgeEncoding(
        (basis): NormalizedBasis(
          (basis): BesselBasis()
        )
        (cutoff): PolynomialCutoff()
      )
      (spharm): SphericalHarmonicEdgeAttrs(
        (sh): SphericalHarmonics()
      )
      (allegro): Allegro_Module(
        (latents): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (env_embed_mlps): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (tps): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (linears): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (env_linears): ModuleList(
          (0): Identity()
          (1): Identity()
          (2): Identity()
        )
        (_env_weighter): MakeWeightedChannels()
        (final_latent): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng): ScalarMLP(
        (_module): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng_sum): EdgewiseEnergySum()
      (per_species_rescale): PerSpeciesScaleShift()
      (total_energy_sum): AtomwiseReduce()
    )
  )
)
Number of weights: 43096
! Starting training ...

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      0   100         1.76         1.06        0.698          1.4         60.1         1.51
      0   200         1.83         1.01        0.816         1.51          103         1.67
      0   203         1.97         1.38        0.589         1.74         71.1         1.48


  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Initial Validation          0   16.643    0.005         1.16        0.805         1.97         1.51         90.7         1.64
Wall time: 16.64338459307328
! Best model        0    1.644

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1   100        0.357        0.353      0.00437        0.799         8.82        0.119
      1   200        0.278        0.252       0.0262        0.756         28.5        0.308
      1   300         0.16        0.156      0.00376        0.566         2.51        0.077
      1   400        0.139        0.135      0.00348        0.553         4.76        0.106
      1   500        0.211        0.209      0.00175        0.641          2.2       0.0603
      1   600          0.1       0.0996     0.000829        0.462         2.12       0.0501
      1   700        0.133        0.131      0.00162        0.523         5.14       0.0599
      1   800        0.183        0.172       0.0103        0.612         8.55        0.182
      1   900       0.0565       0.0523       0.0042         0.35         4.68        0.117
      1  1000         0.14        0.138      0.00252        0.525         7.45       0.0967
      1  1100        0.107        0.101      0.00593        0.436            8        0.147
      1  1200        0.112        0.104      0.00851         0.47         10.5        0.135
      1  1300       0.0579       0.0572     0.000624        0.339         1.86       0.0479
      1  1400       0.0402       0.0382      0.00196        0.281         4.48       0.0843
      1  1500       0.0846       0.0824       0.0021        0.435         4.16       0.0866
      1  1600        0.127        0.127     0.000337        0.444         1.15       0.0272
      1  1601       0.0987       0.0974      0.00136        0.463         3.11       0.0647

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1   100       0.0615       0.0591       0.0024        0.353         3.76       0.0785
      1   200        0.108        0.106      0.00178        0.466         7.48       0.0665
      1   203       0.0789       0.0776      0.00125        0.414         3.14       0.0654


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               1  141.254    0.005        0.161      0.00752        0.168        0.552         6.84        0.113
! Validation          1  141.254    0.005       0.0797      0.00324       0.0829        0.416         5.92       0.0883
Wall time: 141.2542532889638
! Best model        1    0.088

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2   100       0.0474       0.0458       0.0016        0.307         2.87       0.0658
      2   200       0.0612       0.0606     0.000534        0.364         1.81        0.041
      2   300       0.0865       0.0862     0.000258        0.439         1.23       0.0228
      2   400       0.0716       0.0713     0.000339        0.383         1.54       0.0354
      2   500       0.0742       0.0702      0.00407        0.364         5.45        0.105
      2   600        0.075       0.0742     0.000826        0.399          2.3       0.0478
      2   700       0.0621       0.0618     0.000385        0.357         1.56       0.0369
      2   800       0.0745       0.0742     0.000313        0.393         1.43       0.0267
      2   900       0.0602       0.0597     0.000457        0.358         1.74       0.0362
      2  1000       0.0717       0.0714     0.000301        0.387         1.77        0.033
      2  1100       0.0794       0.0785     0.000821        0.402         3.15       0.0489
      2  1200       0.0824       0.0819     0.000519        0.417         2.69       0.0374
      2  1300       0.0632       0.0629     0.000366        0.361         2.18       0.0318
      2  1400       0.0527        0.052     0.000637        0.346          2.1       0.0438
      2  1500       0.0528       0.0525     0.000334        0.348         1.38       0.0287
      2  1600        0.074       0.0737     0.000269        0.399         1.74       0.0268
      2  1601       0.0544       0.0541     0.000301        0.341         2.42       0.0268

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2   100       0.0381       0.0376     0.000455        0.287         1.42       0.0335
      2   200         0.06         0.06     6.84e-05        0.348        0.783       0.0149
      2   203       0.0503       0.0502     7.37e-05        0.326        0.783       0.0163


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               2  245.701    0.005       0.0749      0.00228       0.0771        0.388         4.03        0.066
! Validation          2  245.701    0.005       0.0505     0.000482       0.0509        0.328         1.94        0.029
Wall time: 245.7015869130846
! Best model        2    0.029

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3   100        0.049       0.0407      0.00828        0.303         10.4        0.175
      3   200       0.0651       0.0644     0.000733        0.378         4.08       0.0451
      3   300       0.0938       0.0715       0.0223          0.4           15        0.286
      3   400        0.086       0.0835      0.00256        0.415          6.5       0.0866
      3   500       0.0392       0.0361      0.00305        0.284         16.1        0.106
      3   600       0.0496       0.0471       0.0025        0.298         3.23       0.0961
      3   700       0.0367       0.0366     3.58e-05        0.269        0.413      0.00962
      3   800       0.0473       0.0467     0.000623        0.312         2.35       0.0453
      3   900        0.053       0.0522     0.000767         0.34         2.51       0.0522
      3  1000       0.0449       0.0423      0.00261        0.296         2.35       0.0811
      3  1100       0.0782       0.0768      0.00143        0.412          2.8        0.057
      3  1200       0.0613       0.0541      0.00712        0.333         6.87        0.161
      3  1300        0.051       0.0488       0.0022        0.332         4.24       0.0883
      3  1400       0.0592        0.059     0.000232        0.337         3.58       0.0263
      3  1500       0.0476       0.0456      0.00198        0.315         1.53       0.0498
      3  1600       0.0711       0.0704     0.000745        0.388         2.54       0.0449
      3  1601       0.0513       0.0496      0.00169        0.339         3.75       0.0782

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3   100       0.0427       0.0415      0.00122        0.299         2.73       0.0608
      3   200       0.0606       0.0604     0.000231        0.352         2.16       0.0272
      3   203       0.0645       0.0643     0.000188        0.372         1.18       0.0246


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               3  351.933    0.005       0.0596      0.00258       0.0622        0.349         4.35       0.0716
! Validation          3  351.933    0.005       0.0548     0.000826       0.0556        0.344         2.63       0.0387
Wall time: 351.93366123898886

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4   100       0.0414         0.04      0.00141        0.297         3.58       0.0661
      4   200       0.0654       0.0636      0.00182        0.373         5.37       0.0699
      4   300       0.0549       0.0547     0.000151        0.314         1.49        0.018
      4   400       0.0738       0.0734     0.000388         0.36         2.83       0.0378
      4   500       0.0657       0.0636      0.00208        0.353         7.71       0.0765
      4   600        0.041       0.0401     0.000932        0.293         3.32       0.0555
      4   700       0.0573        0.056      0.00135        0.318         3.43       0.0692
      4   800       0.0169       0.0166     0.000299        0.163        0.733       0.0246
      4   900       0.0252        0.025     0.000151        0.228         3.97       0.0186
      4  1000       0.0266       0.0247       0.0019        0.213         3.13       0.0836
      4  1100        0.053       0.0524     0.000626        0.342         2.02        0.042
      4  1200        0.041       0.0408     0.000156        0.303         1.01       0.0211
      4  1300        0.047       0.0458      0.00114        0.321         5.14       0.0533
      4  1400       0.0297       0.0273      0.00247        0.225         4.74       0.0959
      4  1500       0.0316       0.0309     0.000695        0.231         1.85       0.0502
      4  1600       0.0432       0.0427     0.000495        0.286         2.41       0.0404
      4  1601       0.0403       0.0401     0.000204        0.298         1.19       0.0247

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4   100        0.032       0.0316     0.000462        0.262         1.72       0.0368
      4   200       0.0434       0.0434     1.87e-05        0.304        0.678       0.0076
      4   203       0.0555       0.0555     7.45e-05        0.348        0.573       0.0119


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               4  456.759    0.005       0.0494      0.00125       0.0506        0.319         3.16        0.051
! Validation          4  456.759    0.005       0.0434     0.000274       0.0436        0.305         1.39       0.0205
Wall time: 456.75925219315104
! Best model        4    0.021

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5   100       0.0534       0.0533     0.000123        0.335         1.35       0.0192
      5   200        0.036       0.0353     0.000712        0.277         2.26       0.0479
      5   300       0.0656       0.0651     0.000496        0.369         2.15       0.0325
      5   400        0.049       0.0489     9.79e-05        0.323        0.555       0.0117
      5   500       0.0359       0.0358     0.000108         0.25        0.799       0.0185
      5   600       0.0427       0.0423     0.000368        0.306         1.43       0.0297
      5   700        0.014        0.013     0.000993        0.159         1.82        0.059
      5   800       0.0199       0.0197     0.000202        0.202        0.719       0.0207
      5   900       0.0517       0.0514     0.000266        0.326         1.47       0.0281
      5  1000       0.0554        0.055     0.000419         0.35         3.69       0.0345
      5  1100       0.0481       0.0476     0.000487        0.306          4.6       0.0323
      5  1200       0.0319       0.0316     0.000345        0.259         1.33       0.0274
      5  1300       0.0284       0.0283     0.000145        0.238        0.841       0.0197
      5  1400       0.0299       0.0299     2.33e-06        0.253        0.087      0.00223
      5  1500       0.0922       0.0803       0.0118         0.41           12        0.204
      5  1600       0.0388       0.0379     0.000853        0.295         2.43       0.0506
      5  1601       0.0363       0.0358     0.000436        0.284         1.73        0.036

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5   100       0.0605       0.0566      0.00392        0.346          5.3        0.119
      5   200       0.0769       0.0749      0.00204        0.402         3.79       0.0769
      5   203       0.0888       0.0854      0.00335        0.432         5.37        0.112


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               5  562.173    0.005        0.044      0.00125       0.0453          0.3         2.97       0.0489
! Validation          5  562.173    0.005       0.0737      0.00438       0.0781        0.394         6.73        0.115
Wall time: 562.1734003811143

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6   100       0.0787       0.0787     4.85e-05        0.367        0.904       0.0115
      6   200       0.0632        0.062      0.00124         0.37         8.63       0.0675
      6   300       0.0417       0.0376      0.00414         0.27         4.17        0.114
      6   400       0.0672        0.067      0.00023        0.329         1.69       0.0263
      6   500       0.0486       0.0482     0.000367        0.312         2.06       0.0302
      6   600       0.0508       0.0501     0.000761        0.322         2.03       0.0475
      6   700       0.0378       0.0371     0.000723         0.27         4.27       0.0411
      6   800        0.055        0.053      0.00197        0.312         5.03       0.0829
      6   900       0.0552       0.0506      0.00458        0.326         9.54        0.128
      6  1000       0.0558       0.0554     0.000356        0.331         1.62       0.0294
      6  1100       0.0403       0.0359      0.00431         0.27         6.32        0.123
      6  1200       0.0311       0.0299       0.0012         0.25         2.85       0.0669
      6  1300        0.046       0.0457     0.000344        0.301         1.51        0.028
      6  1400        0.033       0.0326     0.000418        0.267         1.97        0.035
      6  1500       0.0535       0.0506      0.00288         0.32         8.17       0.0984
      6  1600         0.07       0.0694     0.000606        0.371         3.88       0.0467
      6  1601       0.0839       0.0836     0.000243        0.384         2.87       0.0274

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6   100       0.0333       0.0331     0.000278        0.265          1.3       0.0301
      6   200       0.0546       0.0541     0.000476        0.334         2.05       0.0346
      6   203       0.0383       0.0371      0.00114        0.284         3.05       0.0634


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               6  666.942    0.005       0.0472      0.00166       0.0488        0.309         3.48       0.0587
! Validation          6  666.942    0.005       0.0446     0.000865       0.0454        0.304         2.88       0.0495
Wall time: 666.9423150559887

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7   100       0.0508         0.05     0.000839        0.332         3.04       0.0515
      7   200       0.0345       0.0341     0.000381        0.277         1.53       0.0343
      7   300       0.0299        0.028      0.00191        0.231          2.6       0.0769
      7   400       0.0492       0.0484     0.000812        0.313         1.86       0.0482
      7   500       0.0308         0.03     0.000801        0.252         3.19       0.0476
      7   600       0.0234       0.0232     0.000204        0.229         1.68       0.0274
      7   700       0.0508       0.0493       0.0015        0.324         10.4       0.0666
      7   800        0.036       0.0355     0.000579        0.286         3.33       0.0456
      7   900       0.0303       0.0251      0.00514        0.228         3.68        0.112
      7  1000       0.0456        0.045     0.000556        0.303         3.12       0.0389
      7  1100       0.0395       0.0374       0.0021        0.264         4.13       0.0852
      7  1200       0.0575       0.0565      0.00109        0.332         4.43       0.0511
      7  1300       0.0441       0.0432     0.000853        0.292         2.96       0.0542
      7  1400       0.0351        0.035     0.000124        0.259         1.09       0.0187
      7  1500       0.0282       0.0282     1.94e-06        0.238        0.103      0.00256
      7  1600       0.0316       0.0313     0.000321        0.253         1.44       0.0307
      7  1601       0.0348       0.0345      0.00029        0.252         1.04       0.0306

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7   100       0.0235       0.0234     0.000162        0.225        0.891        0.022
      7   200       0.0359       0.0357     0.000172        0.276         1.23       0.0211
      7   203       0.0283       0.0282     4.64e-05        0.249        0.459      0.00956


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               7  772.207    0.005       0.0388      0.00097       0.0398        0.283         2.77       0.0458
! Validation          7  772.207    0.005       0.0328     0.000354       0.0331        0.263         1.44        0.026
Wall time: 772.2074076039717

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8   100       0.0398       0.0386      0.00114        0.288         1.92       0.0435
      8   200       0.0619       0.0617     0.000242        0.364          1.3       0.0271
      8   300       0.0399       0.0396     0.000261        0.282         1.86        0.029
      8   400       0.0436       0.0432     0.000346        0.301         2.65       0.0324
      8   500       0.0269       0.0244      0.00247         0.23         4.32       0.0948
      8   600       0.0297       0.0288     0.000908         0.24         3.36       0.0564
      8   700       0.0323       0.0317     0.000564        0.266         2.14       0.0445
      8   800       0.0641        0.061      0.00311        0.358         6.64        0.107
      8   900       0.0231       0.0223      0.00079        0.211          2.2       0.0451
      8  1000       0.0385       0.0378     0.000638        0.282          1.6       0.0375
      8  1100       0.0596       0.0561      0.00351        0.353         6.19       0.0971
      8  1200       0.0483       0.0474     0.000819        0.307         2.74       0.0508
      8  1300       0.0351       0.0347     0.000463        0.266         3.27       0.0323
      8  1400       0.0389       0.0387     0.000233        0.293         1.67       0.0262
      8  1500       0.0657       0.0655     0.000292        0.349         2.55       0.0319
      8  1600       0.0265       0.0261     0.000398         0.24         1.67       0.0381
      8  1601       0.0214       0.0193      0.00211        0.205         4.26       0.0888

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8   100       0.0233       0.0222      0.00115        0.219         2.85        0.063
      8   200       0.0358       0.0353     0.000512        0.273         3.44       0.0431
      8   203       0.0322       0.0319     0.000357        0.264         1.71       0.0357


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               8  879.201    0.005       0.0406      0.00105       0.0417        0.284         2.81        0.047
! Validation          8  879.201    0.005       0.0312     0.000781        0.032        0.255            3       0.0475
Wall time: 879.2012841750402

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9   100       0.0347       0.0345     0.000127        0.277         1.42         0.02
      9   200        0.031       0.0307     0.000307        0.254         1.24       0.0255
      9   300       0.0415       0.0411     0.000391        0.292         2.36       0.0354
      9   400       0.0367       0.0358     0.000951        0.253         2.56       0.0581
      9   500       0.0484       0.0458      0.00266        0.303          2.7       0.0832
      9   600       0.0395       0.0368      0.00271        0.267          8.3       0.0985
      9   700       0.0676       0.0672     0.000434        0.386         1.65       0.0325
      9   800       0.0123        0.012     0.000277         0.16         3.42       0.0279
      9   900       0.0356       0.0335       0.0021        0.269         5.21       0.0878
      9  1000       0.0318       0.0305      0.00129         0.26         4.23       0.0603
      9  1100       0.0418       0.0417     8.13e-05        0.282         1.06       0.0169
      9  1200       0.0344       0.0329      0.00151        0.256         5.02       0.0732
      9  1300       0.0345       0.0344     9.17e-05        0.275         0.61       0.0149
      9  1400       0.0502       0.0493     0.000898         0.32         2.22       0.0452
      9  1500       0.0549       0.0502      0.00467         0.33         6.17        0.129
      9  1600       0.0442        0.043      0.00118         0.29         5.21       0.0641
      9  1601       0.0319       0.0318     0.000117         0.26        0.873       0.0182

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9   100       0.0299       0.0287      0.00122        0.253         2.83       0.0628
      9   200       0.0431       0.0426     0.000475        0.305         2.87       0.0395
      9   203       0.0425       0.0422     0.000351        0.307         1.73        0.036


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               9  982.526    0.005         0.04      0.00116       0.0412        0.284         2.81       0.0468
! Validation          9  982.526    0.005       0.0381     0.000927        0.039         0.29         3.01       0.0478
Wall time: 982.5267518919427

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10   100       0.0279       0.0275     0.000457        0.242         1.21       0.0357
     10   200       0.0275       0.0252      0.00235        0.211         9.27       0.0905
     10   300       0.0241        0.024     7.35e-05        0.218        0.575       0.0142
     10   400        0.048       0.0474     0.000552        0.321         5.48       0.0388
     10   500       0.0241       0.0228      0.00134        0.221         2.16       0.0637
     10   600       0.0315       0.0296      0.00195        0.255         3.32       0.0809
     10   700       0.0222        0.022     0.000176        0.208        0.989       0.0246
     10   800       0.0169       0.0166     0.000257        0.183         3.08       0.0271
     10   900       0.0443       0.0439     0.000429        0.262         2.74       0.0383
     10  1000       0.0413       0.0411     0.000173        0.295         1.42       0.0215
     10  1100       0.0176       0.0171     0.000494        0.194         2.41       0.0422
     10  1200       0.0444       0.0433      0.00105        0.297         5.64       0.0602
     10  1300       0.0707       0.0707      2.1e-05        0.335        0.525      0.00655
     10  1400       0.0415       0.0411     0.000362         0.29         1.78       0.0353
     10  1500       0.0496       0.0493     0.000261        0.322         1.75       0.0303
     10  1600       0.0254       0.0246     0.000863        0.216         2.78        0.055
     10  1601       0.0259       0.0256     0.000331        0.238         2.53       0.0352

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10   100       0.0219       0.0218      0.00013        0.218          0.7       0.0179
     10   200       0.0341       0.0339     0.000138        0.265         1.17       0.0191
     10   203        0.029       0.0289     8.16e-05        0.255        0.639       0.0133


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              10 1088.112    0.005       0.0372     0.000824        0.038        0.274         2.58        0.042
! Validation         10 1088.112    0.005       0.0301     0.000264       0.0303        0.251         1.46       0.0244
Wall time: 1088.1127707830165

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11   100       0.0279       0.0276     0.000253        0.251          1.1        0.023
     11   200       0.0297       0.0293     0.000318         0.25         1.95       0.0284
     11   300       0.0225       0.0224     0.000134         0.21        0.748       0.0193
     11   400        0.028       0.0279     0.000181        0.246         1.08       0.0247
     11   500       0.0157       0.0152     0.000476        0.173         1.19       0.0365
     11   600       0.0382       0.0381     5.25e-05        0.284        0.674        0.012
     11   700       0.0291       0.0289     0.000214        0.253         1.33       0.0247
     11   800         0.03       0.0299     0.000191         0.25         1.14       0.0264
     11   900       0.0316       0.0313     0.000216        0.247         1.14       0.0234
     11  1000       0.0667        0.066       0.0007        0.366         3.04       0.0502
     11  1100       0.0414        0.041     0.000441        0.277         1.29       0.0324
     11  1200       0.0257       0.0254     0.000363        0.242         1.52       0.0334
     11  1300       0.0467       0.0462     0.000534        0.299         3.88       0.0343
     11  1400       0.0658       0.0656      0.00027        0.285         1.98       0.0289
     11  1500       0.0333       0.0316      0.00168        0.268         6.89       0.0788
     11  1600       0.0448       0.0439     0.000861        0.293         2.99       0.0491
     11  1601       0.0173       0.0172     0.000113          0.2        0.981       0.0204

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11   100       0.0328        0.032     0.000822        0.262          2.3        0.054
     11   200        0.043       0.0429      0.00012        0.302        0.879       0.0175
     11   203       0.0339       0.0338     7.33e-05        0.276        0.581       0.0121


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              11 1194.053    0.005        0.039      0.00108         0.04        0.281         2.83       0.0469
! Validation         11 1194.053    0.005        0.038     0.000413       0.0384        0.284         1.78       0.0303
Wall time: 1194.0537090301514

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12   100       0.0331       0.0327      0.00039        0.266          2.2       0.0372
     12   200       0.0641       0.0639      0.00028        0.341         1.16       0.0295
     12   300       0.0161       0.0157     0.000435        0.184         1.44       0.0391
     12   400       0.0322        0.032     0.000205         0.27         1.55        0.027
     12   500       0.0396       0.0394     0.000179        0.288          1.5       0.0236
     12   600       0.0107       0.0105     0.000176        0.143         1.29       0.0154
     12   700       0.0692       0.0669      0.00234        0.355         6.76       0.0933
     12   800       0.0292       0.0291     0.000123        0.248        0.743       0.0173
     12   900       0.0411       0.0401     0.000994        0.296         4.43       0.0558
     12  1000       0.0275       0.0274     5.89e-05        0.234         1.62       0.0105
     12  1100       0.0354       0.0353     0.000163        0.273         1.88       0.0185
     12  1200       0.0552       0.0542     0.000941        0.331         4.09       0.0583
     12  1300       0.0407       0.0406     6.15e-05         0.28        0.764       0.0143
     12  1400       0.0157       0.0152     0.000503        0.179         1.45       0.0392
     12  1500       0.0241        0.024     7.85e-05        0.221         0.79       0.0165
     12  1600       0.0463       0.0463     7.62e-06         0.31         0.27      0.00393
     12  1601       0.0247       0.0244     0.000286        0.228        0.724       0.0247

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12   100         0.02       0.0198     0.000142        0.212        0.862       0.0215
     12   200       0.0298       0.0298     8.18e-05         0.25         1.37       0.0166
     12   203       0.0247       0.0246     0.000133        0.237         1.01       0.0211


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              12 1298.638    0.005       0.0325     0.000578       0.0331        0.259         2.12       0.0352
! Validation         12 1298.638    0.005       0.0268     0.000236        0.027        0.237         1.51        0.025
Wall time: 1298.638638193952

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13   100       0.0651       0.0651     6.21e-05         0.31        0.849       0.0138
     13   200       0.0216        0.021     0.000607        0.202          1.8       0.0444
     13   300       0.0317        0.031     0.000743        0.253         4.02       0.0517
     13   400        0.035       0.0349     0.000105        0.265        0.779       0.0152
     13   500       0.0509       0.0505     0.000386        0.341         2.23        0.034
     13   600       0.0477       0.0444      0.00333        0.305         5.19        0.108
     13   700       0.0358       0.0355      0.00023        0.282         1.37       0.0286
     13   800       0.0375       0.0373     0.000191        0.278         1.07       0.0214
     13   900       0.0368       0.0364     0.000434         0.27         1.58       0.0382
     13  1000       0.0463       0.0457     0.000572        0.307         4.09       0.0409
     13  1100        0.119        0.113      0.00516        0.384         17.1        0.122
     13  1200       0.0372        0.037     0.000198        0.282         1.14       0.0218
     13  1300       0.0241        0.023       0.0011        0.213         2.14       0.0607
     13  1400       0.0472       0.0462     0.000916        0.299         2.53        0.051
     13  1500       0.0489       0.0483     0.000582        0.322         3.14        0.038
     13  1600       0.0189       0.0185     0.000362         0.19         1.68       0.0354
     13  1601       0.0635       0.0619      0.00165        0.364         6.18       0.0635

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13   100       0.0257       0.0256     0.000117        0.237        0.707        0.015
     13   200       0.0351       0.0346     0.000492        0.277         2.23       0.0375
     13   203        0.032       0.0314     0.000582        0.266         1.91       0.0397


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              13 1401.277    0.005       0.0392      0.00203       0.0413        0.278         2.95       0.0489
! Validation         13 1401.277    0.005       0.0333     0.000455       0.0338        0.269         2.06       0.0335
Wall time: 1401.2772408700548

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14   100       0.0253       0.0249     0.000404        0.224          1.3       0.0371
     14   200       0.0356       0.0346     0.000976        0.251         3.45       0.0555
     14   300       0.0301         0.03     0.000144        0.249        0.957       0.0178
     14   400       0.0173       0.0165     0.000818        0.177         2.13       0.0546
     14   500       0.0445       0.0396      0.00491        0.261         4.69        0.107
     14   600       0.0293       0.0289     0.000329        0.254         1.61       0.0304
     14   700       0.0138       0.0135     0.000313        0.171         1.48        0.028
     14   800       0.0331       0.0296      0.00358        0.244         8.43         0.11
     14   900        0.064       0.0623      0.00166        0.348          4.7       0.0767
     14  1000       0.0233       0.0232     9.95e-05        0.231        0.854       0.0178
     14  1100       0.0455       0.0449     0.000603        0.293         2.89       0.0436
     14  1200       0.0545       0.0544     0.000119        0.309        0.565       0.0146
     14  1300       0.0429       0.0426     0.000268        0.297         1.32       0.0286
     14  1400       0.0158       0.0157     0.000126        0.162        0.659       0.0188
     14  1500       0.0521       0.0521     3.24e-06        0.313        0.183      0.00299
     14  1600       0.0439       0.0406      0.00325        0.287         8.17         0.11
     14  1601       0.0342        0.034     0.000183        0.281         2.48       0.0258

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14   100       0.0248       0.0246     0.000213        0.221        0.967       0.0248
     14   200       0.0334       0.0333     0.000167        0.266        0.959       0.0219
     14   203       0.0269       0.0267     0.000153        0.247         1.05       0.0218


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              14 1506.945    0.005       0.0341     0.000819        0.035        0.264         2.48       0.0409
! Validation         14 1506.945    0.005       0.0306      0.00025       0.0308        0.253         1.48       0.0242
Wall time: 1506.9453880379442

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15   100       0.0342       0.0337     0.000532        0.278            2       0.0416
     15   200       0.0306       0.0301      0.00046        0.229        0.751       0.0262
     15   300       0.0396       0.0393     0.000344         0.27         1.14       0.0321
     15   400        0.035       0.0341     0.000869        0.268         4.17       0.0427
     15   500       0.0173       0.0172     2.51e-05        0.186        0.285      0.00689
     15   600       0.0437       0.0436     6.88e-05        0.286        0.689       0.0107
     15   700       0.0451       0.0442     0.000827        0.309         4.31       0.0544
     15   800        0.032       0.0317     0.000235        0.263         1.53       0.0279
     15   900       0.0448       0.0443     0.000487        0.315          2.4       0.0388
     15  1000       0.0352       0.0343     0.000837        0.254         3.23       0.0506
     15  1100       0.0291       0.0279      0.00118        0.248         3.06       0.0626
     15  1200       0.0284       0.0265      0.00189        0.238         3.41       0.0811
     15  1300       0.0318       0.0316     0.000177        0.269          1.6        0.023
     15  1400       0.0334       0.0331     0.000335        0.264         2.16       0.0341
     15  1500       0.0272       0.0271     9.33e-05        0.246        0.761       0.0151
     15  1600       0.0379       0.0373     0.000668        0.273          2.6       0.0451
     15  1601       0.0138       0.0137     0.000107        0.171        0.785       0.0193

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15   100       0.0241       0.0236     0.000475        0.226         1.84       0.0407
     15   200       0.0355       0.0354     6.81e-05        0.275          1.3       0.0153
     15   203       0.0329       0.0328     7.48e-05        0.264        0.732       0.0152


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              15 1621.911    0.005        0.036     0.000955        0.037        0.273         2.65       0.0441
! Validation         15 1621.911    0.005       0.0315     0.000231       0.0317         0.26         1.36         0.02
Wall time: 1621.9117079819553
! Best model       15    0.020

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16   100       0.0371       0.0369      0.00018         0.27         1.66       0.0206
     16   200       0.0335       0.0332     0.000246        0.265         2.33       0.0294
     16   300       0.0209       0.0209        2e-05        0.202        0.764      0.00714
     16   400       0.0279       0.0272     0.000713        0.229         2.21       0.0464
     16   500       0.0413       0.0409     0.000365        0.288         1.72       0.0316
     16   600       0.0218       0.0215     0.000262         0.22        0.907       0.0193
     16   700       0.0264       0.0248      0.00159        0.219         2.57       0.0664
     16   800       0.0371        0.037     0.000106        0.273         0.89       0.0173
     16   900       0.0268       0.0262     0.000539         0.24          2.1       0.0438
     16  1000       0.0271       0.0267     0.000373        0.235         1.39        0.032
     16  1100       0.0447       0.0445     0.000159        0.304         1.86       0.0215
     16  1200       0.0388       0.0371      0.00173        0.267         5.16       0.0725
     16  1300       0.0294       0.0274      0.00194        0.231         1.94       0.0654
     16  1400       0.0299       0.0294     0.000565        0.246         1.73       0.0348
     16  1500       0.0331       0.0329     0.000142        0.267         1.56       0.0226
     16  1600       0.0201       0.0198     0.000254        0.199         1.19       0.0251
     16  1601      0.00378      0.00371     6.58e-05       0.0919         0.42        0.015

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16   100       0.0219        0.021     0.000929        0.215         2.48       0.0538
     16   200       0.0338       0.0334     0.000423        0.265         3.13       0.0387
     16   203       0.0283       0.0281     0.000207        0.249         1.31       0.0273


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              16 1738.961    0.005       0.0342     0.000827        0.035        0.261         2.54       0.0417
! Validation         16 1738.961    0.005       0.0276     0.000669       0.0283        0.241         2.89       0.0444
Wall time: 1738.961014189059

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17   100       0.0241       0.0238     0.000313        0.218         1.94       0.0303
     17   200       0.0456       0.0432      0.00236        0.302         5.23       0.0923
     17   300        0.032       0.0316     0.000394         0.23         1.45       0.0353
     17   400       0.0305       0.0291      0.00135         0.23         2.65       0.0707
     17   500        0.021       0.0205     0.000528        0.191         2.78       0.0409
     17   600       0.0336       0.0331     0.000473        0.266         1.62       0.0386
     17   700       0.0179       0.0172     0.000707        0.189         1.98       0.0443
     17   800       0.0189       0.0188      0.00014        0.204        0.829       0.0209
     17   900       0.0266       0.0261     0.000488        0.242         2.29         0.04
     17  1000       0.0376       0.0374     0.000171        0.285         4.19        0.022
     17  1100       0.0233        0.022      0.00128        0.222         2.45       0.0678
     17  1200       0.0296       0.0296     8.68e-05        0.264        0.815        0.017
     17  1300       0.0261       0.0259     0.000163        0.247          1.6       0.0224
     17  1400       0.0289       0.0282     0.000745        0.231         1.81       0.0503
     17  1500       0.0227        0.022     0.000708        0.208         1.72       0.0492
     17  1600       0.0133        0.013      0.00025        0.167          1.7       0.0267
     17  1601       0.0245       0.0238     0.000633        0.209         1.68       0.0356

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17   100       0.0231       0.0227     0.000378        0.223         1.01       0.0282
     17   200       0.0315       0.0312     0.000385        0.258          2.3       0.0372
     17   203       0.0286       0.0281     0.000488        0.246         1.91       0.0398


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              17 1852.494    0.005       0.0318     0.000773       0.0326        0.255         2.44       0.0401
! Validation         17 1852.494    0.005       0.0286      0.00072       0.0293        0.245          2.5       0.0444
Wall time: 1852.4941234919243

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18   100       0.0391       0.0389     0.000199        0.292         1.05       0.0219
     18   200       0.0206       0.0206      3.5e-05        0.208        0.395      0.00922
     18   300       0.0261        0.026      7.3e-05        0.245        0.815       0.0143
     18   400        0.031       0.0289      0.00217        0.252         4.24       0.0884
     18   500       0.0179       0.0175     0.000362        0.186         1.16       0.0337
     18   600       0.0355       0.0336       0.0019        0.254         2.99       0.0742
     18   700       0.0196       0.0194     0.000235         0.21         1.36       0.0257
     18   800       0.0257       0.0252     0.000496        0.221         3.09       0.0393
     18   900       0.0416       0.0406     0.000939        0.284         3.98       0.0564
     18  1000       0.0208       0.0208     2.06e-05        0.212        0.799      0.00707
     18  1100       0.0411       0.0406       0.0005        0.284         5.48       0.0372
     18  1200        0.069       0.0685     0.000498        0.376         2.62        0.037
     18  1300        0.029       0.0289     7.51e-05        0.249        0.595       0.0135
     18  1400       0.0219       0.0218     7.86e-05        0.221         1.65       0.0139
     18  1500       0.0484       0.0469      0.00151        0.273         4.74       0.0742
     18  1600        0.019       0.0187     0.000344          0.2         1.11       0.0324
     18  1601       0.0172       0.0169     0.000224        0.185        0.974       0.0278

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18   100       0.0247       0.0243     0.000354        0.226         1.46       0.0351
     18   200        0.032       0.0319     0.000158        0.262         1.17       0.0179
     18   203       0.0238       0.0237     4.32e-05        0.232        0.609       0.0127


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              18 1963.376    0.005       0.0311     0.000701       0.0318        0.252         2.34       0.0387
! Validation         18 1963.376    0.005       0.0297     0.000332         0.03        0.251         1.58       0.0268
Wall time: 1963.3763280590065

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19   100        0.104        0.104     0.000424        0.307         2.38       0.0319
     19   200       0.0416       0.0412     0.000392        0.291         2.36        0.034
     19   300       0.0305       0.0305     4.34e-05        0.262        0.538       0.0106
     19   400       0.0258       0.0252     0.000621         0.23         3.44       0.0477
     19   500       0.0223       0.0222     0.000102        0.222        0.738       0.0176
     19   600       0.0278       0.0277     0.000115        0.248         0.87       0.0181
     19   700       0.0505       0.0505     1.63e-05        0.296        0.479      0.00737
     19   800       0.0242       0.0237     0.000522        0.214          1.4       0.0404
     19   900       0.0183        0.018     0.000337        0.201         1.76       0.0292
     19  1000       0.0348       0.0345     0.000274        0.285         1.38       0.0288
     19  1100       0.0193       0.0193     3.43e-05        0.201         0.64      0.00912
     19  1200       0.0418       0.0417     0.000119        0.298         3.53       0.0196
     19  1300       0.0221        0.022     0.000172        0.212         1.17       0.0225
     19  1400       0.0288       0.0287     0.000123        0.245        0.851       0.0177
     19  1500       0.0336       0.0332     0.000393        0.265         3.35        0.037
     19  1600       0.0192       0.0192     2.37e-05        0.205        0.444      0.00746
     19  1601        0.031       0.0308     0.000182        0.259         2.02       0.0261

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19   100       0.0209       0.0199     0.000956        0.204         2.56        0.059
     19   200       0.0299       0.0293     0.000589        0.252         2.61       0.0445
     19   203       0.0229       0.0224     0.000476        0.225            2       0.0416


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              19 2077.688    0.005       0.0297     0.000555       0.0303        0.247         2.05       0.0342
! Validation         19 2077.688    0.005       0.0259     0.000743       0.0267        0.233         2.82       0.0488
Wall time: 2077.6880916161463

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20   100       0.0356       0.0351     0.000467        0.248         2.45       0.0376
     20   200       0.0265       0.0258     0.000766        0.242         3.52       0.0468
     20   300       0.0324       0.0301      0.00236        0.247          3.3       0.0846
     20   400       0.0322       0.0295      0.00275        0.243         4.03       0.0979
     20   500        0.024       0.0224      0.00159        0.214         3.18       0.0759
     20   600       0.0186       0.0175      0.00109        0.191         3.57       0.0611
     20   700       0.0291       0.0284     0.000695        0.247         3.64       0.0397
     20   800         0.03       0.0297     0.000316        0.244         1.09        0.031
     20   900       0.0318       0.0305      0.00135        0.257          3.1       0.0707
     20  1000       0.0995       0.0966      0.00291        0.369          7.6       0.0818
     20  1100       0.0316       0.0315     0.000128        0.249          1.2       0.0169
     20  1200       0.0441       0.0417      0.00236        0.298         12.2       0.0921
     20  1300       0.0207       0.0205     0.000176        0.211        0.843       0.0186
     20  1400       0.0312       0.0297      0.00156        0.237          1.8       0.0567
     20  1500        0.031       0.0307     0.000336        0.254         2.23       0.0324
     20  1600       0.0208       0.0207     0.000145        0.206         1.31         0.02
     20  1601       0.0307       0.0306     9.35e-05        0.249         3.56       0.0179

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20   100       0.0213       0.0209     0.000439        0.207        0.888       0.0267
     20   200       0.0317       0.0312      0.00054        0.259         2.65       0.0424
     20   203       0.0282       0.0276     0.000634        0.247         2.15       0.0448


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              20 2191.817    0.005       0.0328     0.000914       0.0337         0.26          2.6       0.0429
! Validation         20 2191.817    0.005       0.0271     0.000503       0.0276        0.237         2.01       0.0364
Wall time: 2191.8177626740653

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21   100       0.0291       0.0291     4.75e-05        0.254        0.487       0.0101
     21   200       0.0462        0.046     0.000121        0.291         1.12       0.0184
     21   300       0.0152       0.0149     0.000226        0.169        0.714       0.0219
     21   400       0.0222       0.0213     0.000844        0.218         3.79       0.0549
     21   500       0.0243        0.023      0.00124        0.219          2.9       0.0654
     21   600       0.0354       0.0348      0.00059        0.258        0.955       0.0332
     21   700       0.0524       0.0523     0.000146        0.255         1.76       0.0193
     21   800       0.0301       0.0294     0.000719        0.257         4.14       0.0474
     21   900       0.0162       0.0159     0.000328        0.171         1.33       0.0319
     21  1000       0.0213       0.0211     0.000228        0.206         1.46       0.0255
     21  1100       0.0188       0.0179     0.000961         0.18         2.25       0.0589
     21  1200       0.0188       0.0187     3.33e-05        0.203        0.654      0.00955
     21  1300       0.0187       0.0183     0.000374        0.205         2.32       0.0323
     21  1400       0.0263       0.0262     0.000109        0.241        0.985       0.0184
     21  1500        0.031       0.0308     0.000201        0.264         0.89       0.0185
     21  1600       0.0316       0.0308     0.000867        0.258         3.59       0.0553
     21  1601       0.0124       0.0117     0.000682        0.131         1.24       0.0442

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21   100       0.0238       0.0235     0.000312        0.226         1.06       0.0282
     21   200       0.0363       0.0358      0.00051        0.276         3.41       0.0433
     21   203       0.0344       0.0339     0.000478        0.274         2.03       0.0423


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              21 2308.179    0.005       0.0286     0.000622       0.0293        0.243          2.2       0.0366
! Validation         21 2308.179    0.005       0.0295     0.000607       0.0302         0.25         2.37       0.0417
Wall time: 2308.1796501609497

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22   100       0.0254       0.0253     0.000117         0.24         1.27       0.0171
     22   200       0.0299       0.0296     0.000269        0.246          1.2       0.0298
     22   300       0.0262        0.026     0.000222        0.238            2       0.0266
     22   400       0.0458       0.0455      0.00036        0.306         1.31       0.0306
     22   500       0.0417       0.0409     0.000827        0.295         2.94       0.0545
     22   600       0.0211       0.0196      0.00155        0.205         5.31       0.0758
     22   700       0.0285       0.0269      0.00161        0.231         2.11       0.0629
     22   800       0.0511       0.0509     0.000218        0.335        0.941       0.0196
     22   900       0.0454        0.045     0.000444        0.293         1.84       0.0319
     22  1000        0.033       0.0317      0.00125        0.257         3.42        0.063
     22  1100       0.0252       0.0247     0.000522        0.237         1.84       0.0384
     22  1200        0.025       0.0243     0.000676        0.229         1.78       0.0477
     22  1300       0.0156       0.0147     0.000925        0.173         2.76        0.055
     22  1400       0.0492       0.0483     0.000889        0.311         3.46       0.0389
     22  1500       0.0349        0.034     0.000917        0.269         2.49       0.0554
     22  1600       0.0431       0.0412       0.0019        0.277         8.23       0.0712
     22  1601       0.0305       0.0304     7.43e-05         0.27        0.799       0.0166

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22   100       0.0227       0.0226     0.000168        0.221        0.929        0.023
     22   200       0.0303       0.0302     4.78e-05        0.256        0.549       0.0115
     22   203       0.0276       0.0276     8.17e-05        0.248        0.651       0.0136


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              22 2422.875    0.005       0.0335     0.000889       0.0344         0.26         2.39       0.0402
! Validation         22 2422.875    0.005       0.0273     0.000124       0.0274         0.24        0.922       0.0146
Wall time: 2422.8750414189417
! Best model       22    0.015

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23   100        0.032       0.0319     0.000123         0.26          1.2       0.0173
     23   200        0.053       0.0528     0.000277        0.333         2.33       0.0318
     23   300       0.0168       0.0168     3.91e-05        0.186        0.532       0.0101
     23   400       0.0268       0.0262     0.000618        0.232         1.47       0.0393
     23   500       0.0335       0.0334     0.000149        0.259         1.48       0.0177
     23   600       0.0299       0.0292     0.000726        0.252         2.75       0.0515
     23   700       0.0288       0.0284     0.000387        0.232         2.23       0.0341
     23   800       0.0432       0.0431     0.000183         0.28         1.14        0.023
     23   900       0.0154       0.0152     0.000215        0.183         1.75       0.0273
     23  1000       0.0165       0.0165     3.98e-05        0.177        0.324         0.01
     23  1100       0.0161       0.0161     2.94e-05        0.181        0.393      0.00822
     23  1200       0.0202         0.02     0.000158          0.2        0.843       0.0212
     23  1300       0.0294       0.0293     0.000171        0.252          1.4       0.0237
     23  1400       0.0351        0.035     2.66e-05        0.278        0.564      0.00903
     23  1500       0.0481        0.048     7.22e-05        0.324        0.693       0.0118
     23  1600       0.0455       0.0453     0.000193        0.309        0.985       0.0188
     23  1601       0.0121       0.0112     0.000937        0.148         2.27       0.0591

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23   100       0.0205        0.019       0.0015        0.198          3.1       0.0647
     23   200       0.0295       0.0291     0.000414         0.25         3.06        0.036
     23   203       0.0261       0.0256     0.000493        0.241         2.01       0.0418


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              23 2534.268    0.005       0.0293     0.000544       0.0298        0.246          2.1       0.0343
! Validation         23 2534.268    0.005       0.0255     0.000779       0.0263        0.231         2.99       0.0453
Wall time: 2534.2688094810583

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24   100       0.0373       0.0372     0.000103        0.261         1.44       0.0188
     24   200       0.0325        0.032     0.000554        0.261         2.14       0.0377
     24   300       0.0203       0.0199     0.000336        0.203         1.42       0.0296
     24   400       0.0373       0.0357      0.00159         0.26         4.67       0.0717
     24   500       0.0187       0.0181     0.000635        0.195         1.89        0.046
     24   600        0.112        0.107      0.00472         0.37         7.32       0.0736
     24   700       0.0316       0.0307       0.0009         0.25         2.13       0.0509
     24   800       0.0201       0.0187      0.00143        0.198         3.67       0.0727
     24   900       0.0424       0.0399      0.00252         0.29         4.11       0.0873
     24  1000       0.0448       0.0445     0.000297        0.308         1.89       0.0264
     24  1100       0.0452       0.0451     5.87e-05        0.304        0.833       0.0131
     24  1200       0.0475       0.0457      0.00188        0.315         5.82       0.0801
     24  1300       0.0333       0.0329     0.000388        0.265         1.48       0.0343
     24  1400       0.0266       0.0266     4.28e-05        0.243        0.526        0.011
     24  1500       0.0187       0.0174      0.00134        0.198          4.1       0.0697
     24  1600       0.0296       0.0293     0.000297        0.256         1.81       0.0298
     24  1601       0.0244       0.0243     0.000137        0.212        0.458       0.0162

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24   100       0.0227       0.0224     0.000304        0.218         1.19       0.0303
     24   200        0.031       0.0307     0.000351        0.258          2.8       0.0356
     24   203       0.0273       0.0269     0.000371        0.244         1.77       0.0369


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              24 2645.201    0.005       0.0316      0.00074       0.0324        0.255         2.38       0.0391
! Validation         24 2645.201    0.005       0.0273     0.000419       0.0277        0.239         2.15       0.0353
Wall time: 2645.2012118189596

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25   100       0.0253       0.0246      0.00072        0.241          2.9       0.0495
     25   200       0.0398       0.0395     0.000383        0.289         2.78       0.0343
     25   300       0.0283       0.0282     0.000123        0.246        0.919       0.0191
     25   400       0.0257       0.0255     0.000227        0.232         1.41       0.0276
     25   500       0.0302       0.0288      0.00139        0.235         3.34       0.0643
     25   600       0.0223       0.0215       0.0008        0.187         1.81        0.045
     25   700       0.0175       0.0174     0.000126        0.198         0.93       0.0194
     25   800       0.0211       0.0205     0.000614        0.207         2.38        0.045
     25   900       0.0274       0.0271     0.000299        0.232         1.91       0.0293
     25  1000      0.00917      0.00908     8.76e-05        0.121        0.532       0.0172
     25  1100       0.0218       0.0212     0.000618        0.207         1.22        0.039
     25  1200       0.0173       0.0172     0.000103        0.183        0.436       0.0131
     25  1300       0.0233       0.0232     0.000118        0.208        0.696       0.0195
     25  1400       0.0162        0.016     0.000213        0.174         1.02       0.0225
     25  1500       0.0181       0.0179     0.000148        0.177         1.05        0.022
     25  1600       0.0274       0.0264      0.00099        0.219         2.33       0.0572
     25  1601       0.0328       0.0327      4.9e-05        0.266         1.08       0.0113

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25   100       0.0211       0.0209     0.000276        0.214         1.27       0.0266
     25   200       0.0298       0.0298     7.72e-05        0.251          1.1       0.0161
     25   203       0.0272       0.0271     3.57e-05        0.244        0.553       0.0115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              25 2757.373    0.005       0.0296     0.000911       0.0305        0.247         2.44       0.0409
! Validation         25 2757.373    0.005       0.0285     0.000208       0.0287        0.244         1.36       0.0219
Wall time: 2757.37361479993

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26   100       0.0272       0.0257      0.00149        0.228         2.89       0.0715
     26   200       0.0307       0.0279      0.00278        0.242         7.83       0.0981
     26   300       0.0219       0.0212     0.000732         0.21         3.58       0.0493
     26   400       0.0292        0.028      0.00116        0.239         2.46       0.0617
     26   500       0.0227       0.0226     9.82e-05         0.22         2.48       0.0191
     26   600       0.0203       0.0203     3.45e-05        0.209         0.42       0.0096
     26   700       0.0189       0.0182     0.000663        0.197         1.35       0.0415
     26   800      0.00685      0.00628      0.00057        0.109         1.08       0.0375
     26   900         0.19        0.163       0.0272        0.596         13.9        0.308
     26  1000       0.0305       0.0304     0.000128        0.255         1.16       0.0204
     26  1100        0.028       0.0274     0.000582        0.248            3       0.0456
     26  1200       0.0217       0.0214     0.000362        0.219         2.84       0.0349
     26  1300       0.0238       0.0233     0.000571        0.206         1.38       0.0324
     26  1400       0.0362       0.0361      9.9e-05        0.266         1.33        0.019
     26  1500       0.0168       0.0164     0.000482        0.192         2.37        0.042
     26  1600       0.0342       0.0325      0.00167        0.256          3.2       0.0697
     26  1601       0.0189       0.0182     0.000693        0.204         2.58       0.0482

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26   100       0.0237       0.0234     0.000219         0.22         1.12        0.024
     26   200       0.0307       0.0306     7.63e-05        0.256        0.968       0.0157
     26   203       0.0247       0.0247     2.95e-05        0.235        0.501       0.0104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              26 2870.932    0.005       0.0288     0.000628       0.0294        0.241         2.16       0.0359
! Validation         26 2870.932    0.005       0.0279     0.000113        0.028        0.243        0.929       0.0151
Wall time: 2870.9319266630337

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27   100       0.0231        0.023     0.000142        0.204         0.76       0.0192
     27   200       0.0196       0.0192     0.000386        0.203         2.68       0.0326
     27   300       0.0201       0.0187       0.0014          0.2         2.55       0.0694
     27   400       0.0304       0.0288      0.00151        0.249         10.4       0.0743
     27   500       0.0332       0.0308      0.00244        0.254         6.09       0.0666
     27   600       0.0199       0.0198     7.17e-05        0.205         1.01       0.0161
     27   700       0.0305       0.0302     0.000265        0.248         2.01       0.0262
     27   800       0.0412       0.0406     0.000585         0.29          3.4       0.0434
     27   900       0.0336       0.0328     0.000798        0.257         3.04       0.0506
     27  1000       0.0228       0.0227     0.000132        0.216        0.814       0.0185
     27  1100       0.0564       0.0545      0.00187        0.318         6.37       0.0832
     27  1200       0.0447       0.0427      0.00196        0.308         10.6       0.0832
     27  1300       0.0219       0.0203      0.00158        0.209         4.77       0.0726
     27  1400       0.0161       0.0159     0.000126        0.182        0.537       0.0175
     27  1500       0.0796        0.077      0.00253        0.328         5.54       0.0913
     27  1600       0.0177       0.0175     0.000196        0.189         1.01       0.0223
     27  1601       0.0818       0.0807      0.00108        0.392         4.89       0.0636

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27   100       0.0341       0.0309      0.00323        0.254         4.65       0.0999
     27   200       0.0418       0.0408      0.00102        0.298         4.04       0.0529
     27   203       0.0396       0.0378      0.00182        0.289         3.94        0.082


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              27 2983.036    0.005       0.0293     0.000632       0.0299        0.246         2.23        0.037
! Validation         27 2983.036    0.005       0.0345      0.00175       0.0362        0.272         4.39       0.0675
Wall time: 2983.035936834058

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28   100       0.0245       0.0243     0.000148        0.224         2.34       0.0226
     28   200       0.0238       0.0236     0.000198        0.229         1.09       0.0228
     28   300       0.0405       0.0397     0.000818        0.278         2.82       0.0533
     28   400       0.0245        0.024     0.000548        0.225         1.75       0.0379
     28   500       0.0301         0.03     0.000109        0.247         1.27       0.0175
     28   600        0.036       0.0351     0.000811        0.266         3.62       0.0487
     28   700       0.0279       0.0273     0.000567         0.24          2.6       0.0448
     28   800       0.0215       0.0215     4.14e-05        0.214        0.751       0.0115
     28   900       0.0467       0.0464     0.000286        0.313         1.54       0.0304
     28  1000       0.0197       0.0194     0.000208        0.202         1.01        0.024
     28  1100       0.0417       0.0405      0.00119        0.293         4.05       0.0665
     28  1200       0.0248       0.0201      0.00478        0.197         9.46        0.133
     28  1300       0.0203       0.0199     0.000358        0.212         1.71       0.0308
     28  1400       0.0192       0.0188     0.000337        0.197          1.8       0.0344
     28  1500      0.00952      0.00898      0.00054         0.13         1.26       0.0367
     28  1600        0.148         0.14      0.00747        0.439         6.22         0.14
     28  1601       0.0205       0.0205     5.97e-05        0.212         1.16       0.0149

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28   100       0.0205       0.0205     3.58e-05        0.207        0.311       0.0067
     28   200       0.0271        0.027     5.21e-05        0.242        0.829       0.0133
     28   203       0.0236       0.0235     0.000151        0.225         1.02       0.0212


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              28 3093.508    0.005       0.0277     0.000558       0.0283        0.239         2.01       0.0336
! Validation         28 3093.508    0.005       0.0245     0.000152       0.0247        0.226          1.1       0.0181
Wall time: 3093.5081270900555

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29   100        0.066       0.0659     0.000102        0.329        0.757       0.0165
     29   200       0.0269       0.0266     0.000341        0.245         1.43       0.0299
     29   300       0.0415       0.0405      0.00102        0.279         5.71       0.0601
     29   400      0.00957      0.00892     0.000651        0.123         1.68       0.0482
     29   500       0.0264       0.0257     0.000718        0.239         3.17       0.0494
     29   600        0.028       0.0219      0.00607        0.216         7.35        0.147
     29   700       0.0399       0.0396     0.000328        0.275          2.2       0.0313
     29   800       0.0272        0.027     0.000203        0.236         1.32       0.0229
     29   900        0.031       0.0304     0.000543        0.252         1.69       0.0414
     29  1000       0.0179       0.0177     0.000233        0.185         1.11       0.0264
     29  1100       0.0339        0.033     0.000905         0.26         5.17       0.0511
     29  1200       0.0297       0.0295     0.000166        0.255         1.36       0.0224
     29  1300       0.0637       0.0611      0.00262         0.36         5.42       0.0951
     29  1400       0.0374       0.0371     0.000337        0.294         2.24        0.032
     29  1500       0.0244       0.0244     6.04e-05        0.218         0.57        0.013
     29  1600       0.0395       0.0392     0.000275        0.282         1.98       0.0307
     29  1601       0.0383       0.0381     0.000165        0.282         1.72       0.0248

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29   100       0.0218       0.0217     0.000181        0.213        0.774       0.0209
     29   200        0.035       0.0348     0.000136        0.274         1.44       0.0218
     29   203         0.03       0.0297     0.000285        0.258         1.32       0.0276


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              29 3207.285    0.005       0.0301       0.0019        0.032        0.247         2.79       0.0465
! Validation         29 3207.285    0.005       0.0289     0.000262       0.0292        0.246         1.43       0.0245
Wall time: 3207.285260087112

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30   100       0.0281        0.028     0.000118        0.236         0.67       0.0168
     30   200       0.0428       0.0425     0.000294        0.252         1.58       0.0317
     30   300       0.0203       0.0201     0.000192        0.212          1.4       0.0236
     30   400       0.0306       0.0303     0.000269        0.256         1.79       0.0275
     30   500        0.033       0.0328     0.000209        0.267         1.48       0.0261
     30   600       0.0318       0.0313     0.000504        0.247         2.06       0.0379
     30   700       0.0116       0.0107     0.000912        0.144         1.83       0.0538
     30   800       0.0304       0.0301     0.000291        0.238         1.41       0.0299
     30   900       0.0116       0.0109     0.000735        0.147         1.74       0.0499
     30  1000        0.043       0.0415      0.00155        0.272         3.13       0.0714
     30  1100       0.0206       0.0204     0.000228        0.217        0.887       0.0231
     30  1200       0.0317       0.0313     0.000487        0.249         2.28       0.0385
     30  1300       0.0222       0.0219     0.000288         0.22         2.02       0.0247
     30  1400       0.0279       0.0276     0.000235        0.241         1.43       0.0244
     30  1500       0.0214       0.0213     3.64e-05        0.206        0.437      0.00929
     30  1600       0.0366       0.0363     0.000245         0.28         1.93       0.0264
     30  1601       0.0414       0.0412     0.000162        0.287        0.942       0.0213

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30   100       0.0199       0.0197     0.000224        0.201         1.17       0.0246
     30   200       0.0295       0.0295     5.53e-06        0.251        0.375      0.00392
     30   203       0.0201       0.0201     2.71e-05        0.213        0.402      0.00838


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              30 3318.874    0.005       0.0307     0.000647       0.0314        0.246         2.25       0.0368
! Validation         30 3318.874    0.005       0.0241      0.00014       0.0242        0.223         1.03       0.0152
Wall time: 3318.8743090911303

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31   100       0.0262       0.0257     0.000518        0.217         1.43       0.0369
     31   200        0.022       0.0215     0.000516         0.22         4.59       0.0437
     31   300       0.0224       0.0224     7.22e-05        0.218        0.991         0.01
     31   400       0.0272       0.0269     0.000248        0.239         1.49       0.0284
     31   500       0.0249       0.0244     0.000498        0.234         1.88       0.0391
     31   600       0.0271       0.0269     0.000223        0.246         1.49       0.0244
     31   700       0.0372       0.0358      0.00137        0.245         3.94       0.0703
     31   800        0.014       0.0132     0.000814        0.164         1.41       0.0454
     31   900       0.0164       0.0163     6.64e-05         0.19        0.384       0.0111
     31  1000       0.0184       0.0175     0.000877        0.184         2.03         0.05
     31  1100       0.0242       0.0238     0.000474        0.221         2.27       0.0335
     31  1200       0.0244       0.0237     0.000716        0.228         2.46       0.0513
     31  1300       0.0252       0.0248     0.000363        0.229         1.09       0.0242
     31  1400       0.0339       0.0338     4.24e-05        0.271        0.709       0.0111
     31  1500       0.0314        0.031     0.000372        0.267         2.21        0.033
     31  1600       0.0189       0.0189      1.6e-05        0.185         0.25      0.00679
     31  1601       0.0236       0.0236     3.36e-05         0.23        0.438      0.00913

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31   100       0.0236       0.0234     0.000151        0.225        0.849       0.0217
     31   200       0.0311       0.0308     0.000347         0.26         1.93       0.0327
     31   203       0.0228       0.0225     0.000339        0.224         1.63        0.034


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              31 3433.239    0.005       0.0309     0.000565       0.0315        0.247         2.03       0.0337
! Validation         31 3433.239    0.005       0.0277     0.000242       0.0279        0.244         1.29       0.0239
Wall time: 3433.2397535911296

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32   100       0.0217       0.0209     0.000794        0.203         1.89       0.0486
     32   200       0.0206         0.02     0.000622        0.194         2.86       0.0377
     32   300        0.074       0.0603       0.0137        0.354           13        0.138
     32   400       0.0377       0.0372     0.000487        0.243         2.45       0.0402
     32   500       0.0244       0.0235     0.000916        0.224         2.34       0.0526
     32   600       0.0178        0.017     0.000842         0.19         2.57       0.0552
     32   700         0.03       0.0298     0.000183        0.257         4.08       0.0197
     32   800       0.0355       0.0354     8.94e-05        0.274         1.11       0.0164
     32   900       0.0326       0.0324     0.000197        0.251         1.64        0.026
     32  1000       0.0219       0.0216     0.000258        0.221        0.889       0.0244
     32  1100       0.0206       0.0198     0.000834        0.182         2.18       0.0543
     32  1200        0.033       0.0328     0.000234        0.233         1.78       0.0266
     32  1300       0.0194       0.0192     0.000281        0.202         1.28       0.0269
     32  1400       0.0287       0.0282     0.000592        0.247         3.54        0.044
     32  1500       0.0245       0.0244     0.000122        0.223        0.743       0.0157
     32  1600       0.0433       0.0405      0.00275        0.288         7.64        0.101
     32  1601       0.0294       0.0254      0.00402        0.234         5.87        0.122

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32   100       0.0193       0.0191     0.000249        0.196         1.15       0.0272
     32   200       0.0295       0.0295     4.46e-05        0.251        0.752       0.0118
     32   203       0.0234       0.0233     0.000104        0.227        0.688       0.0143


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              32 3545.717    0.005       0.0281     0.000592       0.0287        0.239         1.88       0.0307
! Validation         32 3545.717    0.005       0.0236     0.000188       0.0238        0.221          1.2       0.0201
Wall time: 3545.7170784629416

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33   100      0.00762       0.0074     0.000217        0.128        0.878       0.0268
     33   200        0.015       0.0145     0.000484        0.166         1.61       0.0423
     33   300       0.0261        0.026     3.68e-05        0.241        0.485       0.0111
     33   400       0.0235       0.0234     0.000149        0.226         1.47       0.0194
     33   500       0.0458       0.0457     0.000161        0.297         1.28       0.0212
     33   600        0.022        0.022     3.54e-05        0.185        0.315       0.0101
     33   700       0.0304       0.0303     0.000104        0.256         2.34       0.0189
     33   800       0.0263       0.0261     0.000194        0.231         4.08       0.0243
     33   900       0.0336       0.0334     0.000267        0.268         1.67       0.0298
     33  1000       0.0392        0.039     0.000215         0.24         1.49       0.0259
     33  1100       0.0304       0.0303     4.57e-05        0.245        0.815       0.0112
     33  1200       0.0225       0.0224     0.000149        0.217        0.931       0.0186
     33  1300       0.0425       0.0423      0.00019        0.298          1.2       0.0219
     33  1400       0.0188       0.0186     0.000252        0.197         1.53       0.0254
     33  1500        0.105        0.104     0.000657        0.294         2.85       0.0484
     33  1600       0.0242       0.0235     0.000666        0.221         1.56       0.0411
     33  1601       0.0402         0.04     0.000246        0.297         2.44       0.0297

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33   100       0.0196        0.019     0.000628        0.202         2.07       0.0446
     33   200       0.0269       0.0267       0.0002        0.241         1.84       0.0272
     33   203       0.0225       0.0224     0.000155        0.225         1.12       0.0234


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              33 3660.157    0.005       0.0265      0.00045       0.0269        0.234         1.92       0.0318
! Validation         33 3660.157    0.005       0.0234     0.000318       0.0237        0.221         1.88       0.0288
Wall time: 3660.1578182170633

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34   100        0.018        0.018     5.95e-05        0.197        0.691       0.0144
     34   200       0.0174       0.0171     0.000311        0.191         2.11       0.0338
     34   300       0.0308       0.0307     6.31e-05        0.251         1.19       0.0148
     34   400       0.0181       0.0177     0.000436        0.201         1.75       0.0364
     34   500       0.0475       0.0465     0.000993        0.325         3.52       0.0583
     34   600       0.0212       0.0211     0.000113        0.215        0.888       0.0178
     34   700       0.0253       0.0249     0.000383        0.231         3.33       0.0359
     34   800        0.033       0.0323     0.000705        0.271         1.76        0.045
     34   900       0.0236       0.0236     5.32e-05        0.216        0.608       0.0133
     34  1000       0.0393       0.0392      0.00015        0.276         1.25       0.0219
     34  1100       0.0253       0.0237      0.00152        0.207         2.83       0.0733
     34  1200       0.0929       0.0707       0.0221        0.345         15.2        0.282
     34  1300       0.0323       0.0322      0.00011        0.261         1.45        0.017
     34  1400       0.0319       0.0309      0.00101        0.246         2.07       0.0458
     34  1500       0.0202       0.0202     2.91e-05        0.216        0.455      0.00948
     34  1600       0.0381       0.0374     0.000775        0.274         4.26       0.0432
     34  1601       0.0307       0.0305     0.000277        0.257         3.36        0.032

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34   100       0.0263        0.024      0.00232        0.232         4.02       0.0922
     34   200       0.0334       0.0318      0.00158        0.267         5.83       0.0757
     34   203       0.0361       0.0353     0.000797        0.282         2.56       0.0534


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              34 3775.833    0.005       0.0274     0.000587        0.028        0.239         2.09       0.0352
! Validation         34 3775.833    0.005       0.0297      0.00191       0.0316        0.251         4.93       0.0804
Wall time: 3775.8330424509477

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35   100       0.0186       0.0111      0.00741         0.14         5.14        0.163
     35   200       0.0191       0.0179      0.00117        0.201         2.35       0.0597
     35   300       0.0218       0.0209     0.000948        0.197         2.28       0.0589
     35   400       0.0336       0.0334     0.000244        0.267         1.97       0.0276
     35   500       0.0324       0.0311      0.00136        0.252         4.94       0.0643
     35   600      0.00992      0.00988     3.64e-05        0.139        0.339       0.0103
     35   700       0.0269       0.0266     0.000269        0.242         1.97       0.0306
     35   800       0.0338       0.0331     0.000718        0.259         1.98       0.0454
     35   900       0.0416       0.0365      0.00515        0.278         9.26        0.128
     35  1000       0.0244       0.0243     9.86e-05         0.23         1.02       0.0173
     35  1100       0.0394       0.0394     2.85e-05        0.289        0.725      0.00882
     35  1200       0.0399       0.0396      0.00029        0.277         1.94       0.0285
     35  1300       0.0324       0.0316     0.000737        0.237         1.79        0.047
     35  1400       0.0304       0.0303     0.000156        0.233         2.88       0.0217
     35  1500       0.0333       0.0329     0.000479        0.273         3.57       0.0377
     35  1600       0.0131       0.0129     0.000117        0.161         1.19       0.0186
     35  1601       0.0172       0.0171     0.000116        0.191        0.601       0.0184

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35   100       0.0247       0.0245     0.000265        0.229         1.26       0.0268
     35   200       0.0308       0.0307     0.000119        0.259         1.65       0.0189
     35   203       0.0281        0.028     5.76e-05         0.25        0.704       0.0147


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              35 3893.639    0.005       0.0267     0.000556       0.0272        0.236         2.09       0.0345
! Validation         35 3893.639    0.005       0.0307     0.000141       0.0308        0.257         1.11       0.0178
Wall time: 3893.6398198110983

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36   100       0.0266       0.0262     0.000332        0.228         2.05       0.0316
     36   200        0.027       0.0267     0.000364         0.23         2.52       0.0358
     36   300       0.0176       0.0167     0.000905        0.168         2.19       0.0565
     36   400       0.0288       0.0285     0.000378        0.251          2.4       0.0355
     36   500       0.0284       0.0283     8.91e-05        0.253         1.07        0.013
     36   600       0.0262       0.0253     0.000897        0.228         4.42        0.055
     36   700       0.0433       0.0427     0.000577        0.281         2.31       0.0442
     36   800       0.0275       0.0275     7.55e-05        0.242        0.663       0.0138
     36   900       0.0233        0.023     0.000232        0.227        0.999       0.0205
     36  1000       0.0177        0.016      0.00165         0.18         2.98       0.0778
     36  1100       0.0392       0.0383     0.000905        0.279         3.12       0.0575
     36  1200       0.0257       0.0256     6.29e-05         0.23        0.927       0.0127
     36  1300       0.0289       0.0281     0.000754        0.241         1.71       0.0381
     36  1400       0.0225       0.0208      0.00176        0.217         4.51       0.0775
     36  1500       0.0266       0.0266     5.16e-05        0.243        0.503       0.0105
     36  1600       0.0244       0.0239     0.000467        0.226         1.98       0.0404
     36  1601       0.0271       0.0268     0.000314        0.252         1.63        0.034

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36   100       0.0191       0.0183      0.00081        0.193         2.32       0.0537
     36   200       0.0283       0.0278     0.000523        0.241            3       0.0428
     36   203       0.0211       0.0208     0.000301        0.215         1.59        0.033


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              36 4011.147    0.005       0.0276     0.000519       0.0281        0.238         2.04       0.0335
! Validation         36 4011.147    0.005       0.0223     0.000565       0.0229        0.215         2.63       0.0429
Wall time: 4011.1478936211206

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37   100       0.0229       0.0229      1.6e-05        0.222        0.326      0.00632
     37   200       0.0158       0.0156     0.000166         0.18        0.946       0.0228
     37   300       0.0354       0.0352     0.000173        0.278         1.26       0.0209
     37   400       0.0341       0.0335     0.000569        0.259         1.43       0.0379
     37   500       0.0113       0.0109     0.000335        0.143         1.21       0.0338
     37   600       0.0246       0.0234      0.00114        0.223         2.35       0.0589
     37   700       0.0172       0.0172     3.13e-05        0.196        0.426      0.00888
     37   800       0.0352       0.0349     0.000365        0.275         1.72       0.0264
     37   900       0.0183        0.018     0.000269        0.176         1.45       0.0306
     37  1000       0.0241       0.0238      0.00028        0.229         1.52       0.0317
     37  1100        0.032       0.0318     0.000166        0.244         1.13       0.0232
     37  1200       0.0258       0.0257     0.000127        0.235        0.586       0.0121
     37  1300       0.0229        0.022     0.000846        0.196         2.01       0.0512
     37  1400       0.0285       0.0266      0.00187         0.22         3.65       0.0788
     37  1500       0.0395       0.0392      0.00027        0.289        0.808       0.0246
     37  1600       0.0488       0.0434      0.00541        0.286          9.3        0.141
     37  1601       0.0257       0.0249     0.000731        0.215         2.04       0.0518

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37   100       0.0275       0.0264      0.00105         0.24         1.69       0.0467
     37   200       0.0311       0.0297      0.00137        0.256         2.76        0.052
     37   203       0.0274       0.0274     2.81e-05        0.247        0.442      0.00921


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              37 4126.397    0.005       0.0286     0.000664       0.0292        0.236         2.22       0.0369
! Validation         37 4126.397    0.005       0.0339      0.00102       0.0349        0.265         2.33       0.0447
Wall time: 4126.397219499107

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38   100        0.035       0.0332      0.00183        0.264         5.96        0.082
     38   200       0.0338       0.0337      2.9e-05        0.268        0.696      0.00891
     38   300         0.03       0.0296      0.00036        0.247         1.51       0.0287
     38   400       0.0238       0.0237     7.89e-05        0.214        0.986       0.0152
     38   500       0.0348       0.0345      0.00034        0.267         1.52       0.0299
     38   600       0.0201         0.02     7.31e-05        0.206        0.541       0.0118
     38   700       0.0298       0.0297     6.58e-05        0.242        0.762       0.0135
     38   800       0.0172       0.0171     0.000147         0.19         1.95       0.0205
     38   900       0.0261       0.0246      0.00152        0.225         2.46       0.0638
     38  1000       0.0314       0.0313     0.000115        0.259        0.842       0.0175
     38  1100       0.0329       0.0327      0.00016        0.257         0.89       0.0187
     38  1200      0.00981      0.00937      0.00044        0.133         1.32         0.04
     38  1300        0.014        0.014     4.15e-05        0.166        0.395       0.0108
     38  1400       0.0196       0.0194      0.00016        0.208         0.63       0.0179
     38  1500       0.0239       0.0234     0.000504         0.22         1.77       0.0369
     38  1600        0.068       0.0601      0.00785        0.343         10.5        0.106
     38  1601       0.0361        0.036     8.86e-05         0.29        0.688       0.0136

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38   100       0.0214       0.0209     0.000475        0.212         1.55       0.0388
     38   200       0.0326       0.0322     0.000428        0.262         2.55       0.0355
     38   203       0.0259       0.0258     7.19e-05        0.245        0.603       0.0126


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              38 4240.543    0.005       0.0294     0.000793       0.0302        0.245         2.27       0.0379
! Validation         38 4240.543    0.005        0.027      0.00057       0.0275        0.239         2.24       0.0376
Wall time: 4240.542908603093

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39   100       0.0388        0.037      0.00179        0.278         3.45       0.0729
     39   200       0.0184       0.0183     0.000115        0.201        0.813       0.0169
     39   300       0.0111       0.0108     0.000282        0.156         1.15       0.0313
     39   400       0.0233       0.0231      0.00011         0.22         1.25       0.0169
     39   500       0.0406       0.0404     0.000252        0.266         1.85        0.029
     39   600       0.0416       0.0377      0.00386        0.268         7.31       0.0877
     39   700       0.0297       0.0292     0.000524        0.255         1.93       0.0403
     39   800       0.0305       0.0302     0.000316        0.245          2.2       0.0342
     39   900       0.0439       0.0438     0.000171        0.305            2       0.0249
     39  1000       0.0342       0.0339     0.000271        0.268         1.84       0.0293
     39  1100       0.0253       0.0252     0.000122        0.224        0.631        0.019
     39  1200       0.0202       0.0196     0.000616        0.195         1.77       0.0475
     39  1300       0.0392       0.0384     0.000774        0.262         4.48       0.0536
     39  1400       0.0211         0.02      0.00106        0.193         2.45       0.0611
     39  1500       0.0338       0.0335     0.000274        0.261         2.74       0.0307
     39  1600       0.0229       0.0224     0.000461        0.214         2.48       0.0412
     39  1601       0.0209       0.0209     3.63e-06        0.203        0.131      0.00362

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39   100       0.0254        0.022      0.00343        0.219         4.75        0.112
     39   200       0.0315       0.0288       0.0027        0.252          7.3       0.0986
     39   203       0.0304       0.0283      0.00203        0.251         4.18       0.0871


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              39 4357.049    0.005       0.0274      0.00047       0.0279        0.237         1.87       0.0312
! Validation         39 4357.049    0.005        0.027      0.00291       0.0299        0.239         6.17        0.102
Wall time: 4357.048989312025

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40   100       0.0269       0.0267     0.000158        0.235         1.19       0.0175
     40   200       0.0117       0.0116     8.77e-05        0.155        0.458       0.0147
     40   300       0.0316       0.0314     0.000177        0.267         2.13       0.0227
     40   400       0.0211       0.0206     0.000488        0.217         1.99       0.0414
     40   500       0.0198       0.0196     0.000196        0.205         1.97       0.0241
     40   600       0.0345       0.0344     9.27e-05        0.278         3.45       0.0163
     40   700       0.0203       0.0197     0.000639        0.197         2.35       0.0468
     40   800       0.0175       0.0173     0.000193        0.195        0.661       0.0212
     40   900       0.0127       0.0125     0.000153        0.138        0.662       0.0222
     40  1000       0.0228       0.0227     0.000155        0.217        0.958       0.0234
     40  1100       0.0208       0.0207     4.61e-05        0.211        0.508       0.0106
     40  1200       0.0256       0.0255     5.01e-05        0.236        0.508      0.00887
     40  1300       0.0245       0.0244      0.00014        0.207        0.751       0.0203
     40  1400         0.01      0.00981     0.000241        0.136        0.939       0.0275
     40  1500       0.0233       0.0227     0.000626        0.222         1.88       0.0456
     40  1600       0.0274       0.0273     0.000169        0.236         1.64       0.0213
     40  1601       0.0251        0.025     8.14e-05        0.242        0.762       0.0159

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40   100       0.0185       0.0183     0.000198        0.195        0.817       0.0217
     40   200       0.0286       0.0284     0.000203        0.246         1.22       0.0243
     40   203       0.0233        0.023     0.000222         0.23         1.21       0.0252


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              40 4472.923    0.005       0.0269     0.000423       0.0273        0.232          1.8       0.0297
! Validation         40 4472.923    0.005       0.0225     0.000212       0.0228        0.216          1.3       0.0232
Wall time: 4472.923160481965

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41   100       0.0732       0.0728     0.000431        0.297         3.25       0.0378
     41   200       0.0189       0.0185     0.000368        0.175         1.11       0.0322
     41   300       0.0547       0.0526      0.00213        0.324         3.47       0.0705
     41   400       0.0254        0.025     0.000403        0.233         2.15       0.0342
     41   500        0.034       0.0339     6.26e-05        0.241         0.79       0.0141
     41   600       0.0467       0.0467     8.04e-06        0.279        0.255      0.00446
     41   700      0.00243      0.00185      0.00058       0.0652         1.24       0.0444
     41   800       0.0321       0.0299       0.0022        0.252         3.92        0.089
     41   900       0.0726        0.071      0.00158        0.281          5.7       0.0764
     41  1000       0.0153       0.0152     0.000109        0.168        0.701       0.0197
     41  1100       0.0196        0.019     0.000569          0.2         1.82        0.039
     41  1200       0.0301       0.0293     0.000795        0.252         3.08       0.0533
     41  1300       0.0226       0.0222     0.000369        0.211        0.949       0.0272
     41  1400       0.0388       0.0381     0.000713        0.279         2.64       0.0498
     41  1500       0.0279       0.0279     6.01e-05        0.227        0.726       0.0136
     41  1600       0.0209       0.0207     0.000259        0.198        0.853       0.0256
     41  1601       0.0176       0.0173       0.0003        0.195         2.34       0.0334

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41   100       0.0201       0.0196     0.000406        0.204         1.62       0.0375
     41   200       0.0269       0.0267     0.000135        0.239         1.38       0.0214
     41   203       0.0243       0.0242     7.49e-05        0.228        0.664       0.0138


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              41 4585.876    0.005       0.0268     0.000561       0.0273        0.232         2.07       0.0343
! Validation         41 4585.876    0.005       0.0227      0.00025       0.0229        0.216         1.59       0.0254
Wall time: 4585.876252393937

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42   100       0.0232       0.0222      0.00102         0.22         4.42       0.0614
     42   200       0.0329       0.0321     0.000857        0.262         3.03       0.0538
     42   300      0.00997      0.00982     0.000149        0.134         1.73       0.0215
     42   400       0.0153       0.0152      6.1e-05         0.17        0.611       0.0137
     42   500       0.0344       0.0338     0.000504        0.261         2.72       0.0367
     42   600       0.0158       0.0157     0.000116        0.182        0.751       0.0188
     42   700       0.0202       0.0199     0.000284        0.211         2.05        0.023
     42   800       0.0186       0.0185      8.1e-05        0.179        0.654       0.0168
     42   900       0.0331       0.0326     0.000509        0.245         2.58       0.0421
     42  1000        0.034        0.034     1.22e-05        0.274        0.263      0.00516
     42  1100        0.022       0.0217     0.000226         0.22         1.27       0.0288
     42  1200      0.00878       0.0087     8.21e-05        0.138        0.495       0.0153
     42  1300       0.0359       0.0353     0.000592         0.24         2.58       0.0408
     42  1400        0.018       0.0153      0.00265        0.166            4       0.0943
     42  1500       0.0346       0.0345      7.4e-05        0.263         1.13       0.0114
     42  1600       0.0369       0.0355      0.00138        0.267          5.5       0.0674
     42  1601       0.0232       0.0229     0.000378        0.221         2.43       0.0376

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42   100        0.021       0.0206     0.000377        0.208         1.53       0.0322
     42   200       0.0263       0.0262     0.000105         0.24         1.41       0.0172
     42   203       0.0243       0.0241     0.000105        0.231        0.943       0.0197


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              42 4700.317    0.005       0.0253     0.000561       0.0259        0.229         1.95       0.0322
! Validation         42 4700.317    0.005        0.024     0.000247       0.0242        0.223         1.63       0.0241
Wall time: 4700.317282823147

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43   100       0.0187       0.0185     0.000203        0.202        0.876       0.0201
     43   200       0.0284       0.0274     0.000927         0.24         3.56       0.0569
     43   300       0.0279       0.0277     0.000197        0.242         2.13       0.0192
     43   400        0.028       0.0276     0.000401        0.249         2.42       0.0382
     43   500         0.03       0.0299     4.98e-05        0.259        0.552        0.012
     43   600       0.0267       0.0266     5.54e-05        0.237         2.09       0.0139
     43   700       0.0268       0.0261     0.000635        0.238         3.31       0.0468
     43   800       0.0477       0.0474     0.000289        0.279         1.63       0.0276
     43   900       0.0319       0.0316     0.000324        0.252         2.05       0.0331
     43  1000       0.0159       0.0159     2.79e-05        0.181        0.363      0.00828
     43  1100       0.0161       0.0149      0.00116         0.16         2.05       0.0594
     43  1200       0.0229       0.0228     9.23e-05        0.215         1.46       0.0158
     43  1300       0.0315       0.0314     7.62e-05        0.247        0.492       0.0141
     43  1400        0.036       0.0357     0.000229        0.254         3.48       0.0274
     43  1500       0.0214       0.0213     9.88e-05        0.214        0.633       0.0166
     43  1600       0.0335       0.0327     0.000817        0.258          3.3       0.0503
     43  1601       0.0378        0.036      0.00182        0.286         3.96       0.0824

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43   100       0.0456        0.039       0.0066        0.282         5.85        0.147
     43   200       0.0541       0.0452      0.00891        0.312         11.3        0.176
     43   203       0.0398       0.0321      0.00768        0.274          8.1        0.169


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              43 4813.118    0.005       0.0289     0.000769       0.0297         0.24         2.22       0.0368
! Validation         43 4813.118    0.005       0.0407      0.00749       0.0482        0.295          9.2        0.162
Wall time: 4813.118121059146

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44   100       0.0212       0.0211     0.000122        0.209        0.974       0.0203
     44   200       0.0316       0.0314     0.000191        0.256         1.46       0.0237
     44   300       0.0235       0.0235     5.39e-05        0.206        0.549       0.0117
     44   400       0.0268       0.0266     0.000167        0.243         1.81       0.0191
     44   500       0.0303       0.0298     0.000492        0.241         2.37       0.0401
     44   600       0.0411       0.0406     0.000417        0.291         2.44       0.0369
     44   700       0.0163       0.0151      0.00122        0.183         3.92       0.0671
     44   800       0.0223       0.0222     9.21e-05        0.221        0.597       0.0135
     44   900       0.0189       0.0178      0.00114        0.196          2.7       0.0637
     44  1000       0.0323        0.032     0.000251         0.26         1.52       0.0237
     44  1100       0.0275       0.0255      0.00203        0.234            5       0.0863
     44  1200       0.0105      0.00975      0.00079        0.134         1.36       0.0475
     44  1300       0.0329       0.0326     0.000322        0.254         1.48       0.0321
     44  1400       0.0324       0.0322     0.000228        0.259         1.87       0.0219
     44  1500       0.0191       0.0188     0.000328        0.197         1.27       0.0312
     44  1600       0.0173       0.0172     6.24e-05        0.189        0.487       0.0119
     44  1601       0.0348       0.0347     8.61e-05        0.274         1.45       0.0156

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44   100       0.0251       0.0219      0.00317        0.213         4.62       0.0984
     44   200       0.0329       0.0311      0.00174        0.259         6.61       0.0756
     44   203        0.029       0.0268      0.00227        0.245         4.41        0.092


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              44 4928.039    0.005       0.0277     0.000642       0.0284        0.239         2.19       0.0367
! Validation         44 4928.039    0.005       0.0285      0.00209       0.0306        0.241         5.31       0.0821
Wall time: 4928.039768533083

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45   100       0.0761       0.0698      0.00628        0.384           23        0.152
     45   200       0.0256       0.0254     0.000146         0.23        0.848       0.0229
     45   300       0.0357       0.0352     0.000502        0.274         1.61       0.0351
     45   400       0.0232       0.0231     9.04e-05        0.217        0.625       0.0175
     45   500       0.0596       0.0596     4.63e-05        0.281        0.612       0.0113
     45   600       0.0191       0.0186     0.000466        0.203         2.63       0.0409
     45   700       0.0356       0.0338       0.0018        0.258         3.87       0.0779
     45   800        0.024       0.0239      0.00017         0.22         0.93       0.0199
     45   900       0.0115       0.0115     5.18e-05        0.158        0.382       0.0108
     45  1000       0.0263       0.0261     0.000213        0.247         1.13       0.0236
     45  1100       0.0322        0.032     0.000198        0.248         1.63       0.0257
     45  1200        0.034       0.0338     0.000202        0.275         4.47       0.0208
     45  1300       0.0355       0.0354     3.67e-05        0.275        0.482       0.0112
     45  1400       0.0188       0.0186     0.000232        0.193        0.988        0.027
     45  1500       0.0149       0.0145     0.000409         0.17         1.79        0.036
     45  1600       0.0195       0.0195     1.13e-05        0.206        0.266      0.00554
     45  1601       0.0161       0.0161     1.29e-06        0.166       0.0856      0.00203

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45   100       0.0211       0.0207     0.000454        0.209         1.25       0.0334
     45   200       0.0272       0.0263      0.00089        0.238         3.85        0.057
     45   203       0.0223       0.0214     0.000905        0.218         2.76       0.0574


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              45 5041.025    0.005       0.0327     0.000601       0.0333        0.246         2.04       0.0336
! Validation         45 5041.025    0.005       0.0242     0.000818       0.0251        0.221         2.91       0.0514
Wall time: 5041.025167066138

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46   100        0.026       0.0255     0.000495        0.221         1.25       0.0264
     46   200       0.0259       0.0254     0.000542        0.225         2.28       0.0416
     46   300       0.0175       0.0174     0.000143        0.197        0.962         0.02
     46   400       0.0236       0.0235     0.000135        0.218        0.956       0.0219
     46   500       0.0149       0.0147     0.000201        0.151        0.862       0.0227
     46   600         0.02       0.0194     0.000593        0.205         2.01       0.0449
     46   700       0.0322       0.0319     0.000271        0.263         1.85       0.0314
     46   800       0.0202         0.02      0.00018        0.212         1.58       0.0259
     46   900       0.0175       0.0174     5.65e-05        0.198        0.571       0.0115
     46  1000       0.0197       0.0195     0.000201        0.207          1.8       0.0208
     46  1100       0.0151        0.015     0.000171        0.182        0.959       0.0239
     46  1200       0.0296       0.0288     0.000759        0.241         3.13       0.0411
     46  1300       0.0255       0.0252     0.000356        0.233         1.32       0.0316
     46  1400       0.0296       0.0295     8.36e-05        0.256        0.718        0.015
     46  1500       0.0145       0.0139     0.000688        0.168         3.27         0.05
     46  1600       0.0323       0.0319     0.000343        0.257         2.26       0.0334
     46  1601       0.0125       0.0123     0.000134        0.165        0.627       0.0194

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46   100       0.0199       0.0199     2.27e-05        0.204        0.383      0.00803
     46   200       0.0269       0.0267     0.000186         0.24         1.49       0.0219
     46   203       0.0269       0.0267     0.000205        0.244         1.14       0.0238


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              46 5155.797    0.005       0.0274     0.000629        0.028        0.236         1.93       0.0321
! Validation         46 5155.797    0.005       0.0241     0.000211       0.0244        0.222         1.27       0.0213
Wall time: 5155.797300942009

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47   100       0.0251       0.0247     0.000443        0.209         2.31       0.0386
     47   200        0.034       0.0338     0.000209        0.259         1.56       0.0261
     47   300       0.0231       0.0222     0.000819        0.211         3.66       0.0459
     47   400       0.0292       0.0287     0.000501        0.242          2.2       0.0425
     47   500       0.0122       0.0118     0.000348        0.164         2.08       0.0281
     47   600        0.019        0.019     1.94e-05        0.187        0.157       0.0051
     47   700       0.0243       0.0242     5.24e-05        0.219         0.52       0.0088
     47   800       0.0249       0.0246     0.000227         0.23          2.2       0.0266
     47   900       0.0152        0.015      0.00012        0.183        0.799       0.0159
     47  1000       0.0338       0.0323      0.00154        0.221         5.79       0.0682
     47  1100       0.0287       0.0286     8.35e-05        0.248         4.08       0.0174
     47  1200       0.0242       0.0242     3.03e-05        0.211        0.568         0.01
     47  1300       0.0158       0.0156     0.000188        0.177        0.758       0.0206
     47  1400       0.0154       0.0153     0.000129         0.16        0.697       0.0177
     47  1500       0.0399       0.0397      0.00024        0.295         1.12       0.0233
     47  1600       0.0195       0.0192     0.000266        0.191         0.91       0.0273
     47  1601       0.0197       0.0192     0.000486        0.203         2.13       0.0409

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47   100       0.0199       0.0198      0.00015        0.205         0.71       0.0192
     47   200       0.0291       0.0289      0.00024        0.248         1.77       0.0269
     47   203       0.0205       0.0204     0.000126        0.217         1.03       0.0215


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              47 5268.132    0.005       0.0263     0.000497       0.0268        0.231         1.93       0.0322
! Validation         47 5268.132    0.005       0.0249     0.000274       0.0251        0.226         1.49       0.0262
Wall time: 5268.131930551026

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48   100       0.0172       0.0171     0.000128        0.178        0.842       0.0217
     48   200       0.0327       0.0324     0.000333        0.266         3.12       0.0346
     48   300       0.0219       0.0218     8.12e-05         0.22            1       0.0117
     48   400       0.0234       0.0224     0.000981        0.224          2.9       0.0604
     48   500       0.0303         0.03     0.000243        0.261          4.6       0.0282
     48   600       0.0136       0.0134     0.000223         0.15        0.986       0.0261
     48   700       0.0368       0.0367      0.00014        0.269         1.91       0.0185
     48   800       0.0229       0.0229     4.56e-05        0.213        0.552       0.0117
     48   900       0.0369       0.0367     0.000136        0.278         1.55       0.0189
     48  1000       0.0315       0.0303      0.00118        0.265         3.51       0.0636
     48  1100       0.0277       0.0276     0.000113        0.245         1.37       0.0187
     48  1200       0.0166       0.0165     6.65e-05         0.19         0.56       0.0116
     48  1300       0.0381        0.038     0.000156        0.287         1.45       0.0143
     48  1400       0.0558       0.0557     0.000102        0.319        0.715        0.014
     48  1500       0.0284       0.0278      0.00057        0.241         1.98       0.0386
     48  1600       0.0451       0.0449     0.000193        0.294         2.03       0.0242
     48  1601       0.0609       0.0607     0.000204        0.344         2.25       0.0252

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48   100       0.0225       0.0224     5.14e-05        0.213        0.449      0.00965
     48   200       0.0278       0.0277     0.000139        0.241         1.38       0.0206
     48   203       0.0183       0.0181     0.000224        0.202         1.33       0.0277


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              48 5380.280    0.005       0.0261     0.000396       0.0265        0.229         1.81       0.0299
! Validation         48 5380.280    0.005       0.0246     0.000183       0.0248        0.227         1.41       0.0214
Wall time: 5380.280419900082

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49   100       0.0206         0.02     0.000582        0.193          1.9       0.0415
     49   200       0.0355       0.0353     0.000266        0.272         1.23       0.0252
     49   300       0.0192       0.0191     6.82e-05        0.191         0.68       0.0157
     49   400       0.0403       0.0397     0.000661        0.294         3.24       0.0415
     49   500       0.0205       0.0203     0.000203        0.202         1.17       0.0252
     49   600       0.0322       0.0321     6.37e-05        0.253        0.993       0.0132
     49   700       0.0256       0.0256      4.5e-05        0.231        0.733       0.0118
     49   800       0.0278       0.0274     0.000491        0.245         1.91       0.0398
     49   900       0.0287       0.0281     0.000504        0.248         1.94       0.0404
     49  1000       0.0216       0.0216     3.47e-05        0.216        0.648       0.0101
     49  1100       0.0231        0.022      0.00102        0.215          3.5       0.0606
     49  1200       0.0428       0.0422     0.000638          0.3         3.77       0.0482
     49  1300       0.0088      0.00862     0.000185         0.13        0.998        0.025
     49  1400       0.0182       0.0181     6.82e-05        0.176        0.338       0.0117
     49  1500       0.0201       0.0199     0.000285        0.204         0.95       0.0258
     49  1600       0.0379       0.0379     2.81e-05        0.289         1.03      0.00983
     49  1601       0.0344       0.0337     0.000631        0.274         2.32       0.0484

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49   100       0.0209       0.0203     0.000561        0.213         1.99       0.0445
     49   200       0.0269       0.0266      0.00024        0.245         1.27       0.0259
     49   203       0.0218       0.0217     9.42e-05        0.224        0.898       0.0187


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              49 5493.752    0.005        0.027     0.000585       0.0276        0.236         2.14       0.0353
! Validation         49 5493.752    0.005       0.0248     0.000306       0.0251         0.23         1.71       0.0284
Wall time: 5493.752380745951

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50   100      0.00976      0.00972     4.27e-05        0.142        0.523      0.00951
     50   200       0.0303       0.0301     0.000166        0.257         1.69       0.0227
     50   300       0.0171       0.0168     0.000332        0.185         1.46       0.0318
     50   400       0.0154       0.0142      0.00127        0.167         4.48       0.0687
     50   500        0.025        0.024      0.00098        0.207         2.51       0.0595
     50   600       0.0171       0.0161     0.000951        0.186         2.23       0.0554
     50   700       0.0246       0.0238     0.000755         0.23         3.11        0.053
     50   800       0.0145       0.0144      7.9e-05        0.167        0.434       0.0131
     50   900         0.02         0.02      3.6e-05        0.203        0.432      0.00907
     50  1000       0.0233       0.0232      0.00012        0.219        0.732       0.0149
     50  1100       0.0233        0.023     0.000342         0.21        0.725       0.0205
     50  1200       0.0252        0.025       0.0002        0.226         1.94       0.0267
     50  1300       0.0151       0.0149     0.000204        0.181         1.11       0.0254
     50  1400       0.0399       0.0258       0.0141        0.229         9.42        0.226
     50  1500       0.0218       0.0215     0.000266        0.213         1.23       0.0292
     50  1600        0.013       0.0129      6.5e-05        0.171         0.57       0.0136
     50  1601        0.028       0.0274     0.000618        0.233         1.77       0.0393

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50   100        0.024       0.0239     0.000145        0.226        0.847       0.0209
     50   200       0.0323       0.0321     0.000261        0.263         1.62        0.029
     50   203       0.0227       0.0226     0.000129        0.231        0.829       0.0173


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              50 5606.816    0.005       0.0266     0.000717       0.0274        0.235         2.24       0.0371
! Validation         50 5606.816    0.005       0.0278     0.000305       0.0281        0.244         1.36       0.0249
Wall time: 5606.816610054113

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     51   100       0.0256       0.0255     0.000109        0.224         1.14       0.0177
     51   200       0.0334       0.0332     0.000179        0.268          1.9       0.0244
     51   300       0.0318       0.0314      0.00049        0.251         1.79       0.0386
     51   400       0.0391       0.0385     0.000632        0.274         3.86        0.043
     51   500       0.0241       0.0239      0.00015        0.225        0.876       0.0214
     51   600       0.0301       0.0289      0.00122        0.242         3.84       0.0548
     51   700       0.0138       0.0137     4.35e-05         0.17        0.633       0.0123
     51   800       0.0411       0.0404     0.000686        0.293         4.17       0.0494
     51   900       0.0162       0.0159     0.000356        0.171         1.11        0.033
     51  1000       0.0227       0.0226     6.59e-05        0.216        0.518       0.0108
     51  1100        0.017       0.0163     0.000755        0.188         2.74       0.0432
     51  1200       0.0261       0.0261     5.37e-05        0.231        0.881       0.0134
     51  1300       0.0131        0.013     8.76e-05        0.149        0.677       0.0176
     51  1400       0.0304       0.0296     0.000848         0.25         2.36       0.0487
     51  1500        0.028       0.0279     0.000108        0.251        0.872       0.0182
     51  1600       0.0367       0.0365     0.000207        0.275         1.23       0.0222
     51  1601       0.0349       0.0348      0.00011        0.259         2.03         0.02

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     51   100       0.0184       0.0182     0.000229        0.197         1.19       0.0254
     51   200       0.0273       0.0273     2.94e-05        0.244        0.465      0.00832
     51   203       0.0196       0.0196     5.03e-05        0.211        0.468      0.00975


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              51 5719.603    0.005       0.0264     0.000452       0.0268        0.234         1.86       0.0311
! Validation         51 5719.603    0.005       0.0224     0.000115       0.0225        0.216        0.928       0.0141
Wall time: 5719.603169173002
! Best model       51    0.014

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     52   100       0.0224       0.0223     0.000134        0.218         1.04        0.018
     52   200       0.0239       0.0236     0.000356         0.23         1.26       0.0263
     52   300       0.0229       0.0229     2.82e-05        0.222        0.482         0.01
     52   400       0.0331        0.033     7.14e-05         0.26        0.594       0.0134
     52   500       0.0198       0.0197      5.5e-05        0.211        0.451      0.00974
     52   600       0.0207       0.0192      0.00149        0.198         2.94       0.0718
     52   700      0.00962      0.00945      0.00017        0.135        0.912       0.0222
     52   800       0.0298       0.0291     0.000648        0.257         2.81       0.0475
     52   900       0.0168       0.0165     0.000295        0.178         1.11       0.0317
     52  1000       0.0265       0.0261     0.000338        0.231         1.89       0.0353
     52  1100         0.02       0.0188      0.00124         0.18          3.9       0.0664
     52  1200        0.031       0.0309     7.25e-05         0.24        0.898       0.0148
     52  1300       0.0172       0.0171     0.000136        0.191         0.96       0.0215
     52  1400       0.0177       0.0171     0.000566        0.185         1.87       0.0449
     52  1500       0.0402       0.0402      5.2e-05        0.283        0.866       0.0104
     52  1600       0.0382       0.0376     0.000581        0.286         4.11       0.0453
     52  1601       0.0364       0.0364     5.02e-06        0.288        0.292       0.0042

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     52   100       0.0194       0.0192     0.000182        0.196        0.712       0.0195
     52   200       0.0257       0.0256     0.000172        0.236         1.55       0.0242
     52   203       0.0196       0.0194     0.000176        0.208         1.18       0.0245


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              52 5831.000    0.005       0.0259     0.000447       0.0264        0.228         1.83       0.0304
! Validation         52 5831.000    0.005       0.0218     0.000333       0.0222        0.212         1.57       0.0287
Wall time: 5831.000734005123

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     53   100       0.0279       0.0271     0.000727         0.23         3.59       0.0515
     53   200       0.0432        0.043     0.000237        0.299          1.9       0.0271
     53   300       0.0306       0.0275      0.00318        0.244         4.75        0.106
     53   400       0.0188       0.0187      0.00012          0.2        0.712       0.0155
     53   500       0.0244       0.0243      7.1e-05        0.239         1.23       0.0144
     53   600       0.0367       0.0362     0.000544        0.268         2.78        0.044
     53   700       0.0197       0.0192     0.000422        0.197         1.65       0.0372
     53   800        0.039       0.0387     0.000356        0.285         2.24       0.0309
     53   900       0.0267       0.0266     0.000173        0.235         1.62       0.0214
     53  1000       0.0137        0.013     0.000776        0.163         1.77       0.0538
     53  1100       0.0294       0.0292     0.000202        0.243         1.38       0.0214
     53  1200       0.0298       0.0297     0.000136        0.258         1.82       0.0152
     53  1300       0.0186       0.0186     4.91e-05        0.185         1.25       0.0104
     53  1400       0.0162        0.016     0.000179         0.19         1.58       0.0253
     53  1500       0.0206       0.0205     2.07e-05        0.209        0.463      0.00833
     53  1600       0.0331       0.0324      0.00067        0.247         3.95       0.0315
     53  1601         0.02       0.0198     0.000183        0.206        0.992       0.0262

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     53   100       0.0195       0.0187     0.000801        0.195         2.11       0.0522
     53   200       0.0274       0.0261      0.00123        0.234         5.05       0.0671
     53   203       0.0199       0.0185      0.00135        0.206         3.37       0.0703


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              53 5944.348    0.005       0.0254     0.000515       0.0259        0.227         2.01       0.0334
! Validation         53 5944.348    0.005       0.0222      0.00111       0.0234        0.214         3.62        0.062
Wall time: 5944.34839203814

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     54   100       0.0155       0.0153     0.000109        0.182          1.2       0.0172
     54   200       0.0179       0.0178     6.94e-05        0.194         1.01       0.0155
     54   300       0.0205       0.0204     6.51e-05        0.207         0.87       0.0124
     54   400       0.0286       0.0284     0.000187        0.248         1.21       0.0253
     54   500       0.0265       0.0263     0.000285        0.241         1.09       0.0279
     54   600        0.026        0.026      8.3e-06        0.225        0.304      0.00475
     54   700       0.0151       0.0151     4.47e-05        0.185        0.583       0.0121
     54   800       0.0219       0.0202      0.00178        0.192         2.53        0.075
     54   900       0.0196       0.0193     0.000346        0.208         2.17       0.0338
     54  1000        0.033       0.0328     0.000183         0.27        0.834       0.0174
     54  1100       0.0663        0.065      0.00125        0.312         2.97         0.06
     54  1200       0.0236       0.0232     0.000397        0.226         1.63       0.0327
     54  1300       0.0207       0.0205     0.000238        0.206         1.03       0.0247
     54  1400      0.00801      0.00781     0.000199        0.116        0.897        0.025
     54  1500       0.0546       0.0532       0.0014        0.335         5.24       0.0636
     54  1600       0.0184       0.0183     5.08e-05         0.19        0.675       0.0128
     54  1601       0.0244       0.0244     2.05e-05        0.227        0.175      0.00621

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     54   100        0.022       0.0219     0.000112        0.212        0.841       0.0199
     54   200       0.0323       0.0321     0.000232        0.262         1.03       0.0225
     54   203       0.0252       0.0251     0.000116        0.233        0.907       0.0189


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              54 6057.318    0.005       0.0288      0.00118         0.03        0.238         2.15       0.0359
! Validation         54 6057.318    0.005       0.0264     0.000189       0.0266        0.235         1.14       0.0195
Wall time: 6057.318746380974

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     55   100       0.0256       0.0255     0.000163        0.224         3.24       0.0227
     55   200       0.0355       0.0354     6.54e-05         0.28         3.15       0.0109
     55   300       0.0298       0.0292      0.00058        0.247         1.55       0.0378
     55   400      0.00905      0.00862     0.000432        0.115         1.11       0.0342
     55   500       0.0314        0.031     0.000334        0.247         2.13       0.0326
     55   600       0.0356       0.0354     0.000138        0.263         1.36       0.0177
     55   700       0.0276       0.0275     0.000126        0.246        0.858       0.0179
     55   800       0.0154       0.0154     2.49e-05        0.188        0.445      0.00927
     55   900       0.0218       0.0211     0.000631        0.217         2.94       0.0482
     55  1000       0.0259       0.0255     0.000422        0.231         1.98       0.0322
     55  1100        0.033       0.0309       0.0021        0.259         6.26       0.0883
     55  1200       0.0235       0.0225     0.000978        0.223         2.04       0.0531
     55  1300       0.0454       0.0453     0.000176        0.316         2.32       0.0252
     55  1400       0.0323       0.0322     4.27e-05        0.235        0.559       0.0107
     55  1500        0.027       0.0266     0.000411        0.241         1.63       0.0364
     55  1600       0.0466       0.0464     0.000164        0.315         1.76       0.0199
     55  1601       0.0156       0.0148     0.000729        0.184         3.82       0.0521

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     55   100       0.0228       0.0225     0.000289        0.214         1.26       0.0298
     55   200       0.0297       0.0296     6.24e-05        0.258        0.364      0.00885
     55   203       0.0246       0.0245     5.41e-05        0.241        0.675       0.0141


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              55 6169.578    0.005       0.0256     0.000466       0.0261        0.229         1.89       0.0314
! Validation         55 6169.578    0.005       0.0271     0.000143       0.0272         0.24         1.11       0.0177
Wall time: 6169.577982241986

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     56   100       0.0419       0.0394       0.0025        0.242         6.91       0.0652
     56   200       0.0211        0.021     8.79e-05        0.207        0.521       0.0153
     56   300       0.0277       0.0276     3.91e-05        0.221        0.435       0.0108
     56   400       0.0299       0.0297     0.000167        0.251         1.87       0.0212
     56   500       0.0242       0.0197      0.00451          0.2         9.94        0.114
     56   600       0.0216       0.0208     0.000837        0.205         2.28       0.0545
     56   700       0.0323       0.0279      0.00437        0.244         16.6        0.115
     56   800       0.0292        0.029     0.000157        0.251         0.99       0.0207
     56   900       0.0369       0.0365     0.000393        0.273         3.16       0.0344
     56  1000        0.019       0.0189     8.43e-05        0.198        0.833       0.0147
     56  1100      0.00914        0.009     0.000134        0.139         1.11       0.0192
     56  1200       0.0363       0.0359     0.000332         0.27         2.76       0.0338
     56  1300       0.0436       0.0435     0.000139        0.282         3.09       0.0212
     56  1400       0.0233       0.0214      0.00188        0.209         3.65       0.0824
     56  1500       0.0356       0.0355     0.000104        0.273         1.16       0.0126
     56  1600       0.0207       0.0184       0.0023        0.179         3.11       0.0882
     56  1601       0.0131       0.0121     0.000983        0.161         2.33       0.0605

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     56   100       0.0191       0.0184     0.000734        0.195         2.23       0.0483
     56   200       0.0266       0.0262     0.000311        0.237         2.17       0.0336
     56   203       0.0222       0.0218     0.000395        0.224         1.81       0.0376


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              56 6283.888    0.005       0.0257     0.000583       0.0263        0.231         2.03       0.0337
! Validation         56 6283.888    0.005       0.0223     0.000421       0.0227        0.215         2.21       0.0352
Wall time: 6283.888377442956

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     57   100       0.0245       0.0244     9.82e-05         0.24         1.25       0.0165
     57   200       0.0309       0.0308     9.71e-05        0.257         1.21       0.0158
     57   300       0.0246       0.0243     0.000351        0.202         2.88       0.0348
     57   400       0.0572        0.057     0.000206        0.322         1.76       0.0266
     57   500       0.0335        0.033     0.000514        0.272         7.72       0.0352
     57   600       0.0269       0.0269     3.82e-05        0.238        0.666       0.0117
     57   700       0.0247       0.0244     0.000293        0.238         1.81       0.0308
     57   800       0.0159       0.0158      0.00015        0.188         1.05       0.0199
     57   900       0.0126       0.0124     0.000159        0.165        0.842       0.0188
     57  1000       0.0207       0.0205     0.000207        0.207         1.09        0.026
     57  1100       0.0246       0.0244     0.000136        0.228         1.26       0.0212
     57  1200       0.0237       0.0236     4.65e-05        0.233        0.601       0.0125
     57  1300       0.0412        0.041     0.000184        0.285         2.31       0.0259
     57  1400       0.0309       0.0307     0.000207        0.245         0.94       0.0196
     57  1500       0.0406       0.0403     0.000367        0.293         1.37       0.0284
     57  1600       0.0373       0.0369     0.000407        0.282         2.53       0.0318
     57  1601       0.0225       0.0217     0.000804        0.214         1.32       0.0435

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     57   100       0.0196       0.0195     0.000108        0.201        0.487       0.0141
     57   200       0.0277       0.0274     0.000277        0.243         2.26       0.0321
     57   203       0.0206       0.0203     0.000362        0.212          1.7       0.0353


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              57 6395.082    0.005       0.0247     0.000422       0.0251        0.225         1.84       0.0306
! Validation         57 6395.082    0.005       0.0229     0.000366       0.0233        0.218          1.9       0.0326
Wall time: 6395.082685999107

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     58   100       0.0145       0.0143     0.000196        0.161        0.678       0.0238
     58   200       0.0567        0.056       0.0007        0.289         4.58       0.0425
     58   300       0.0298       0.0294     0.000367        0.239         1.23       0.0322
     58   400       0.0278       0.0274     0.000382        0.233         1.74       0.0327
     58   500       0.0154       0.0152     0.000199        0.171        0.804       0.0236
     58   600        0.041       0.0408     0.000213         0.28         1.75       0.0263
     58   700       0.0235       0.0233     0.000271        0.205         1.57       0.0314
     58   800       0.0284       0.0279     0.000501        0.241         3.23       0.0351
     58   900       0.0369       0.0366     0.000291        0.264          2.3       0.0247
     58  1000       0.0135       0.0133     0.000218        0.152         1.59       0.0225
     58  1100       0.0158       0.0151      0.00073        0.183         2.79       0.0467
     58  1200       0.0173       0.0169     0.000445        0.192         2.12       0.0385
     58  1300       0.0231       0.0209      0.00217        0.217         5.27       0.0855
     58  1400       0.0216       0.0216     4.11e-05        0.215         0.44       0.0103
     58  1500       0.0154       0.0142      0.00117        0.176         3.66       0.0625
     58  1600       0.0247       0.0239     0.000789        0.221         1.49       0.0453
     58  1601       0.0178       0.0174      0.00048        0.173         1.41       0.0405

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     58   100       0.0211       0.0207     0.000379        0.212         1.58       0.0354
     58   200       0.0271        0.027     3.69e-05        0.244         1.04       0.0109
     58   203       0.0224       0.0223     3.86e-05        0.227        0.527        0.011


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              58 6509.265    0.005        0.027     0.000535       0.0275        0.234         2.05       0.0341
! Validation         58 6509.265    0.005       0.0235     0.000202       0.0237        0.223         1.37       0.0214
Wall time: 6509.265157927992

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     59   100       0.0294       0.0292     0.000215        0.243         2.59       0.0237
     59   200       0.0147       0.0142     0.000582        0.175         2.43       0.0398
     59   300       0.0192       0.0189     0.000242        0.211         1.32        0.024
     59   400       0.0239       0.0232       0.0007         0.22         2.43       0.0506
     59   500       0.0323       0.0322      0.00012        0.248         1.47        0.017
     59   600       0.0204       0.0199     0.000519        0.208         2.74       0.0409
     59   700       0.0291        0.029     4.94e-05        0.243        0.786      0.00778
     59   800       0.0335       0.0314      0.00208        0.248         3.15       0.0757
     59   900       0.0242       0.0241     9.29e-05        0.236        0.744       0.0155
     59  1000       0.0401        0.039      0.00107        0.289         4.14        0.062
     59  1100       0.0199        0.019     0.000881        0.201         2.45       0.0566
     59  1200       0.0263       0.0259     0.000401        0.233         2.27       0.0357
     59  1300       0.0156       0.0145      0.00114         0.18         4.71       0.0652
     59  1400       0.0219       0.0213     0.000537        0.222         3.33       0.0414
     59  1500       0.0653       0.0603      0.00507        0.293         9.88        0.117
     59  1600       0.0305       0.0302     0.000323        0.247         1.48       0.0283
     59  1601        0.019       0.0188     0.000122        0.198        0.987       0.0206

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     59   100         0.02       0.0195       0.0005          0.2         1.82       0.0429
     59   200       0.0258       0.0256     0.000222        0.237         2.26       0.0274
     59   203       0.0198       0.0196     0.000176        0.208         1.08       0.0225


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              59 6621.332    0.005       0.0286     0.000639       0.0292        0.235         2.07       0.0347
! Validation         59 6621.332    0.005       0.0233      0.00058       0.0238         0.22         2.35       0.0394
Wall time: 6621.33241222403

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     60   100       0.0198       0.0195     0.000364        0.207         1.48        0.029
     60   200       0.0566       0.0548      0.00187        0.308         4.77       0.0472
     60   300       0.0273       0.0254      0.00191        0.217         7.61       0.0816
     60   400       0.0207       0.0204     0.000265        0.213        0.746       0.0215
     60   500       0.0222        0.022     0.000171        0.224         1.17       0.0244
     60   600         0.03       0.0296     0.000399        0.242         1.47       0.0332
     60   700       0.0117       0.0113     0.000435        0.155         1.68       0.0339
     60   800       0.0265       0.0262     0.000285        0.235         1.93       0.0281
     60   900       0.0257       0.0253     0.000381        0.231         1.57       0.0331
     60  1000       0.0242       0.0238     0.000336        0.221         1.82       0.0351
     60  1100       0.0233       0.0231     0.000163        0.223         1.04       0.0182
     60  1200       0.0195       0.0183      0.00121        0.181         2.02       0.0606
     60  1300       0.0251       0.0248     0.000277        0.224         2.07        0.025
     60  1400       0.0296       0.0295     6.93e-05        0.244        0.628       0.0134
     60  1500       0.0264       0.0263     9.68e-05        0.243        0.798       0.0166
     60  1600       0.0293       0.0287     0.000565         0.24         1.36       0.0363
     60  1601        0.028       0.0279     0.000102        0.248        0.929       0.0194

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     60   100       0.0186       0.0183     0.000296        0.196        0.795       0.0228
     60   200       0.0271       0.0267      0.00042        0.244         2.62       0.0393
     60   203       0.0205       0.0199     0.000586        0.208          2.2       0.0458


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              60 6735.159    0.005       0.0253     0.000608       0.0259        0.228         2.01       0.0337
! Validation         60 6735.159    0.005       0.0231     0.000545       0.0236        0.219         2.29       0.0405
Wall time: 6735.15940406709

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     61   100        0.018        0.018     2.74e-05        0.204        0.261      0.00739
     61   200       0.0163       0.0161     0.000112        0.177        0.866       0.0149
     61   300        0.258        0.258     0.000153        0.358         1.31       0.0213
     61   400       0.0289       0.0289     2.13e-05        0.242        0.309      0.00658
     61   500       0.0226       0.0224     0.000136        0.226         1.18       0.0198
     61   600       0.0251       0.0248     0.000234         0.23         1.14       0.0237
     61   700        0.014       0.0138      0.00028        0.166         1.72        0.031
     61   800       0.0257       0.0255     0.000207        0.239         1.32       0.0275
     61   900       0.0158       0.0155     0.000276        0.179         1.24       0.0312
     61  1000       0.0144       0.0143     3.31e-05         0.18        0.425      0.00886
     61  1100       0.0209       0.0208     8.27e-05        0.206        0.566       0.0148
     61  1200       0.0253       0.0253     2.21e-05        0.233         0.64      0.00725
     61  1300       0.0367       0.0364     0.000271        0.266        0.904       0.0239
     61  1400       0.0164       0.0151      0.00129         0.17         3.69       0.0683
     61  1500       0.0161       0.0146      0.00151        0.169         2.76       0.0745
     61  1600       0.0208       0.0207     4.81e-05        0.209        0.595       0.0115
     61  1601       0.0377       0.0377      2.4e-06        0.282        0.474      0.00299

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     61   100       0.0183       0.0181     0.000198        0.198        0.853       0.0224
     61   200       0.0246       0.0242     0.000457         0.23         2.67       0.0379
     61   203       0.0209       0.0206     0.000238        0.215         1.42       0.0296


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              61 6847.136    0.005       0.0238     0.000379       0.0242        0.222         1.74        0.029
! Validation         61 6847.136    0.005       0.0218     0.000392       0.0222        0.213         1.98       0.0341
Wall time: 6847.1359426020645

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     62   100        0.012       0.0119     9.03e-05        0.164        0.751       0.0156
     62   200       0.0146       0.0145     5.98e-05        0.163        0.542       0.0142
     62   300       0.0351       0.0335      0.00165        0.228         4.66       0.0558
     62   400       0.0233       0.0232     7.66e-05        0.227        0.652       0.0126
     62   500       0.0472       0.0471     8.74e-05        0.319          1.1       0.0151
     62   600       0.0266        0.026     0.000548         0.24          1.6       0.0394
     62   700       0.0267        0.026     0.000628        0.231         3.39       0.0472
     62   800       0.0222       0.0219     0.000304        0.215         1.31       0.0319
     62   900       0.0118       0.0116     0.000225        0.151         1.12       0.0283
     62  1000       0.0116       0.0115     5.92e-05        0.148        0.781       0.0132
     62  1100       0.0276       0.0267     0.000849        0.243         2.42        0.056
     62  1200       0.0285       0.0285     2.96e-05        0.245         0.43      0.00896
     62  1300       0.0199       0.0196     0.000343        0.197         1.39       0.0297
     62  1400       0.0177       0.0172     0.000476        0.196         2.34       0.0368
     62  1500       0.0102      0.00995      0.00026        0.142        0.936       0.0231
     62  1600        0.031       0.0309     0.000151        0.253         1.05       0.0196
     62  1601       0.0218       0.0211     0.000721        0.215         3.87       0.0518

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     62   100       0.0187       0.0186     0.000138        0.199        0.862         0.02
     62   200       0.0262       0.0262      5.1e-05        0.235        0.608       0.0125
     62   203       0.0216       0.0216     8.55e-06        0.221        0.271      0.00565


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              62 6959.422    0.005       0.0241     0.000321       0.0244        0.224         1.59       0.0264
! Validation         62 6959.422    0.005       0.0218     0.000102       0.0219        0.213         0.82        0.014
Wall time: 6959.421978899045
! Best model       62    0.014

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     63   100       0.0318       0.0308     0.000983        0.252         4.63       0.0557
     63   200       0.0293       0.0291     0.000156         0.25         1.87        0.022
     63   300       0.0177       0.0177     1.92e-05         0.19        0.499      0.00807
     63   400       0.0355       0.0354     0.000143        0.248         1.29       0.0168
     63   500       0.0126       0.0125     4.01e-05        0.153        0.349       0.0111
     63   600       0.0452       0.0451     7.73e-05        0.275         1.27       0.0164
     63   700       0.0242       0.0241     0.000125        0.218         1.15       0.0163
     63   800       0.0177       0.0174     0.000292        0.181            1       0.0249
     63   900       0.0315       0.0315     5.65e-05        0.267         1.42       0.0137
     63  1000       0.0353        0.035     0.000225        0.276         2.19       0.0281
     63  1100       0.0208       0.0204      0.00047        0.209         1.61       0.0416
     63  1200       0.0194       0.0192     0.000155          0.2        0.994       0.0227
     63  1300       0.0238       0.0235     0.000334        0.222         2.08        0.033
     63  1400       0.0222       0.0221     0.000151        0.217         4.32       0.0196
     63  1500       0.0402       0.0396     0.000599        0.259         2.38       0.0435
     63  1600       0.0257       0.0257      7.8e-05        0.237        0.733       0.0153
     63  1601       0.0212       0.0211     6.94e-05        0.211         1.15       0.0161

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     63   100       0.0223        0.021      0.00138        0.214         2.98        0.071
     63   200        0.028        0.027      0.00101        0.241         3.05        0.056
     63   203        0.026       0.0254     0.000575        0.238         2.19       0.0456


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              63 7073.316    0.005       0.0248       0.0004       0.0252        0.226         1.75       0.0289
! Validation         63 7073.316    0.005       0.0238      0.00106       0.0249        0.222         3.39       0.0591
Wall time: 7073.316299897153

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     64   100       0.0122       0.0117     0.000561        0.155         1.32       0.0364
     64   200       0.0257       0.0256     3.83e-05        0.236        0.442       0.0114
     64   300       0.0221       0.0219     0.000198        0.211         2.04       0.0265
     64   400       0.0274       0.0267     0.000646        0.239         3.06       0.0453
     64   500       0.0436       0.0431     0.000476         0.28         1.53       0.0332
     64   600       0.0142       0.0141       0.0001        0.164        0.603       0.0147
     64   700       0.0161       0.0145      0.00164        0.162         3.34       0.0732
     64   800       0.0347       0.0337     0.000973        0.257          4.3       0.0584
     64   900       0.0238       0.0235     0.000209        0.227        0.728       0.0206
     64  1000       0.0355       0.0353     0.000206        0.242         1.05       0.0246
     64  1100       0.0348       0.0345     0.000289        0.273          1.5       0.0312
     64  1200       0.0328       0.0328     6.17e-05        0.268         1.41       0.0136
     64  1300       0.0193       0.0191     0.000173        0.197        0.957        0.024
     64  1400       0.0184       0.0182     0.000201        0.198          1.5       0.0271
     64  1500       0.0369       0.0368     0.000101        0.261         1.68       0.0157
     64  1600       0.0154        0.015     0.000438        0.179         2.47       0.0399
     64  1601       0.0347       0.0342     0.000465        0.273          7.2       0.0385

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     64   100       0.0185       0.0181     0.000436        0.195         1.71       0.0394
     64   200        0.024       0.0239     0.000151        0.228         1.06       0.0211
     64   203       0.0188       0.0187     6.89e-05        0.209        0.755       0.0157


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              64 7184.789    0.005        0.024     0.000368       0.0243        0.223         1.71       0.0284
! Validation         64 7184.789    0.005       0.0213     0.000232       0.0216        0.209          1.5       0.0254
Wall time: 7184.789680619026

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     65   100        0.022       0.0218     0.000167         0.21         1.44       0.0215
     65   200       0.0208       0.0207     4.84e-05        0.197        0.565       0.0125
     65   300       0.0111       0.0107     0.000373        0.148         1.89       0.0308
     65   400       0.0384       0.0382     0.000186        0.278         1.61       0.0197
     65   500      0.00765       0.0076     4.35e-05        0.123        0.528        0.011
     65   600         0.04         0.04     6.11e-05        0.279         1.14       0.0143
     65   700       0.0207       0.0206     7.42e-05        0.208         1.24       0.0144
     65   800       0.0243       0.0237     0.000613        0.211         3.39       0.0474
     65   900       0.0259       0.0259     6.58e-05        0.233        0.622       0.0131
     65  1000       0.0313       0.0295      0.00178        0.253         3.52       0.0804
     65  1100       0.0195       0.0195      6.9e-06        0.194        0.195      0.00505
     65  1200       0.0238       0.0238     4.08e-05        0.228        0.696       0.0115
     65  1300       0.0413       0.0405     0.000713        0.292         4.42       0.0512
     65  1400        0.034       0.0334     0.000627        0.234         2.85       0.0402
     65  1500       0.0314       0.0308     0.000618        0.256         2.93       0.0414
     65  1600      0.00955      0.00933     0.000213        0.136        0.869       0.0256
     65  1601       0.0191        0.019     0.000122        0.205         1.47       0.0155

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     65   100       0.0206       0.0205     7.93e-05        0.207        0.718       0.0167
     65   200       0.0282        0.028      0.00018         0.25         2.09       0.0242
     65   203        0.022       0.0217     0.000321        0.228         1.61       0.0335


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              65 7294.769    0.005       0.0272     0.000817        0.028        0.235         2.13       0.0354
! Validation         65 7294.769    0.005       0.0253     0.000227       0.0255        0.232         1.59       0.0245
Wall time: 7294.768887972925

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     66   100       0.0274       0.0272       0.0002        0.246         1.64       0.0254
     66   200       0.0233       0.0229     0.000378        0.208            3       0.0298
     66   300       0.0328       0.0325      0.00032        0.258         1.27       0.0286
     66   400       0.0383       0.0336      0.00466        0.263           10        0.126
     66   500       0.0241        0.024     9.68e-05        0.221         1.17       0.0181
     66   600       0.0204       0.0203      0.00014        0.205        0.702       0.0187
     66   700       0.0212         0.02      0.00125        0.205         4.28       0.0646
     66   800       0.0156       0.0155     7.28e-05        0.174        0.574       0.0139
     66   900       0.0313       0.0311       0.0002        0.262         1.14       0.0237
     66  1000       0.0259       0.0255     0.000385         0.22         1.01       0.0311
     66  1100       0.0206       0.0205     9.07e-05        0.208        0.634       0.0164
     66  1200       0.0215       0.0214     1.97e-05        0.214        0.341       0.0069
     66  1300       0.0241       0.0236     0.000474        0.224         2.52        0.039
     66  1400       0.0358       0.0357      2.6e-05         0.27        0.695      0.00832
     66  1500       0.0204       0.0203     8.35e-05        0.203        0.694       0.0145
     66  1600       0.0213       0.0211     0.000184        0.208        0.974        0.024
     66  1601       0.0574       0.0573     0.000112         0.33         1.64       0.0202

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     66   100       0.0226       0.0221     0.000468        0.223         1.28        0.034
     66   200       0.0301       0.0292     0.000891        0.251         4.35       0.0575
     66   203        0.023       0.0223     0.000707         0.22         2.45       0.0511


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              66 7406.505    0.005       0.0258      0.00045       0.0262        0.231         1.88       0.0312
! Validation         66 7406.505    0.005       0.0258      0.00101       0.0269        0.235         3.46        0.058
Wall time: 7406.505548327928

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     67   100       0.0116       0.0113     0.000285        0.148        0.773       0.0247
     67   200       0.0176       0.0175     0.000113        0.188        0.804       0.0198
     67   300       0.0183       0.0177     0.000524        0.193         2.35       0.0439
     67   400       0.0275       0.0273     0.000289        0.239         1.34        0.028
     67   500         0.06       0.0521      0.00786        0.325         9.76       0.0948
     67   600         0.02         0.02     3.04e-05        0.187        0.303      0.00899
     67   700       0.0111       0.0108       0.0003        0.147          3.2       0.0291
     67   800       0.0181       0.0177     0.000374        0.197         2.54       0.0366
     67   900       0.0262        0.026      0.00023        0.237         1.44       0.0248
     67  1000       0.0135       0.0133     0.000144        0.167         1.19       0.0205
     67  1100       0.0228       0.0216      0.00123        0.209         3.12       0.0602
     67  1200       0.0146       0.0136     0.000987        0.167         2.29       0.0606
     67  1300       0.0445       0.0442     0.000327        0.301          2.6       0.0307
     67  1400       0.0254       0.0254     5.93e-05        0.236        0.591       0.0142
     67  1500       0.0221       0.0221     2.79e-05        0.221        0.386      0.00854
     67  1600       0.0228       0.0225      0.00028        0.215        0.643       0.0205
     67  1601       0.0222       0.0218     0.000388        0.215         2.14       0.0371

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     67   100       0.0196       0.0193     0.000249          0.2          1.2       0.0258
     67   200       0.0275       0.0274     7.61e-05        0.246        0.644       0.0135
     67   203       0.0198       0.0198     3.34e-05        0.213         0.53        0.011


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              67 7519.564    0.005       0.0251     0.000466       0.0255        0.228         1.79       0.0299
! Validation         67 7519.564    0.005       0.0234       0.0002       0.0236        0.222         1.33        0.022
Wall time: 7519.563918638043

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     68   100      0.00929      0.00889       0.0004        0.144         1.28       0.0361
     68   200       0.0123       0.0121     0.000162        0.168         1.38       0.0213
     68   300       0.0273       0.0272     0.000129        0.245         1.05       0.0202
     68   400       0.0496       0.0494     0.000237        0.318         1.89       0.0225
     68   500       0.0317       0.0316      7.6e-05        0.252        0.526       0.0138
     68   600       0.0196       0.0195     0.000134        0.207         1.03       0.0188
     68   700       0.0346        0.034     0.000556        0.271         2.69       0.0428
     68   800       0.0337       0.0333     0.000355        0.247         2.13       0.0297
     68   900       0.0348       0.0347     3.55e-05        0.259        0.728       0.0102
     68  1000       0.0326       0.0325     0.000118        0.262        0.747       0.0181
     68  1100        0.028       0.0279     5.01e-05        0.237        0.529       0.0111
     68  1200       0.0319       0.0317     0.000286        0.265         5.67       0.0296
     68  1300       0.0238       0.0225      0.00128         0.21         3.03       0.0684
     68  1400        0.034        0.034     4.89e-05        0.269        0.845      0.00877
     68  1500      0.00987      0.00984     2.34e-05        0.146        0.324      0.00722
     68  1600       0.0136       0.0135     2.22e-05        0.161        0.243      0.00733
     68  1601       0.0181       0.0176     0.000489        0.192         1.66       0.0392

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     68   100       0.0184       0.0179     0.000492        0.192         1.69       0.0407
     68   200       0.0241       0.0238     0.000267        0.226         1.96       0.0302
     68   203       0.0189       0.0187     0.000192        0.208         1.26       0.0262


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              68 7630.451    0.005       0.0252     0.000444       0.0257        0.227         1.79       0.0299
! Validation         68 7630.451    0.005       0.0208     0.000328       0.0211        0.207         1.88       0.0316
Wall time: 7630.451444132952

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     69   100       0.0264       0.0263     5.56e-05        0.227        0.494       0.0108
     69   200       0.0156       0.0155     9.23e-05        0.164        0.946       0.0175
     69   300       0.0182       0.0182      5.3e-05          0.2        0.609       0.0126
     69   400       0.0188       0.0176      0.00123        0.189          3.1       0.0659
     69   500       0.0188       0.0184     0.000369        0.182         1.37       0.0315
     69   600       0.0297       0.0296      0.00012        0.252         1.69       0.0188
     69   700       0.0499       0.0497     0.000234        0.305         1.73       0.0191
     69   800       0.0212        0.021     0.000148        0.199         1.38       0.0213
     69   900       0.0256       0.0256     3.67e-05        0.244        0.381      0.00795
     69  1000       0.0139       0.0137     0.000156        0.163         4.24       0.0204
     69  1100       0.0258       0.0256     0.000157        0.239        0.866        0.018
     69  1200       0.0242       0.0235      0.00067        0.223         1.51       0.0404
     69  1300       0.0349       0.0348     8.95e-05         0.26        0.661       0.0155
     69  1400       0.0161       0.0151     0.000975        0.178         2.14        0.058
     69  1500       0.0103       0.0103     6.48e-05        0.146        0.731       0.0141
     69  1600       0.0204       0.0193      0.00101        0.201         2.31       0.0555
     69  1601       0.0227       0.0221     0.000642        0.202         1.92       0.0464

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     69   100       0.0226       0.0218     0.000827        0.216          2.3       0.0484
     69   200       0.0285       0.0281     0.000343        0.248         3.19       0.0321
     69   203       0.0245       0.0241     0.000422        0.232         1.79       0.0372


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              69 7743.297    0.005       0.0259     0.000397       0.0263        0.227         1.76        0.029
! Validation         69 7743.297    0.005       0.0254     0.000559       0.0259         0.23         2.59       0.0383
Wall time: 7743.297648569103

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     70   100       0.0437       0.0436     5.42e-05        0.303        0.874       0.0138
     70   200       0.0161       0.0155     0.000615        0.185          2.4       0.0438
     70   300       0.0271       0.0268     0.000318        0.243         2.09       0.0312
     70   400       0.0365       0.0364     0.000107        0.246         1.07       0.0164
     70   500       0.0366       0.0362     0.000333        0.282         3.91       0.0345
     70   600       0.0415       0.0415     1.16e-05        0.305        0.383      0.00413
     70   700       0.0311       0.0307     0.000351        0.254         1.95       0.0355
     70   800       0.0234       0.0232     0.000226        0.216          3.5       0.0253
     70   900       0.0228       0.0223     0.000457        0.219         2.37       0.0412
     70  1000       0.0255       0.0255     3.67e-05        0.229        0.466      0.00971
     70  1100       0.0195       0.0194     0.000105         0.21        0.751       0.0157
     70  1200       0.0193       0.0192     0.000126          0.2         1.67        0.021
     70  1300       0.0174       0.0172     0.000197         0.19         1.25        0.026
     70  1400       0.0247       0.0243     0.000464        0.224          2.5       0.0332
     70  1500       0.0304       0.0262      0.00425        0.239         5.45        0.126
     70  1600       0.0235       0.0232     0.000269        0.217         2.52       0.0275
     70  1601       0.0286       0.0285     5.32e-05        0.254        0.512       0.0107

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     70   100        0.018       0.0178     0.000204        0.194         1.14       0.0249
     70   200        0.025        0.025     2.67e-05        0.231        0.634      0.00935
     70   203       0.0173       0.0173     3.46e-05        0.195        0.449      0.00935


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              70 7857.736    0.005        0.025     0.000537       0.0256        0.226         1.99       0.0332
! Validation         70 7857.736    0.005       0.0217     0.000108       0.0218        0.212        0.974       0.0148
Wall time: 7857.736533215037

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     71   100       0.0223        0.022     0.000309        0.219         1.55       0.0322
     71   200       0.0159       0.0158     8.24e-06         0.18        0.219      0.00505
     71   300       0.0306       0.0304     0.000192        0.254         1.62       0.0256
     71   400       0.0246       0.0246     2.92e-05        0.229        0.751      0.00858
     71   500       0.0171       0.0158      0.00135        0.177          3.5       0.0695
     71   600       0.0264       0.0254     0.000996        0.231         2.59       0.0607
     71   700       0.0296       0.0294     0.000129        0.242         1.13       0.0172
     71   800       0.0245       0.0232       0.0013        0.222         5.15       0.0673
     71   900       0.0146       0.0146     5.45e-05        0.176        0.811       0.0118
     71  1000       0.0259       0.0256     0.000215        0.231          1.7       0.0279
     71  1100       0.0435       0.0433     0.000289        0.289         1.17       0.0275
     71  1200       0.0215       0.0214     9.18e-05        0.204          1.1       0.0157
     71  1300       0.0758       0.0757      0.00014        0.366         1.23       0.0208
     71  1400       0.0173       0.0171     0.000125        0.175        0.619       0.0148
     71  1500       0.0471        0.047     6.42e-05        0.312        0.743       0.0133
     71  1600       0.0122        0.012     0.000215         0.16          1.5       0.0241
     71  1601       0.0347       0.0346      7.4e-05        0.276        0.571       0.0118

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     71   100       0.0192       0.0189     0.000216        0.204        0.584        0.018
     71   200       0.0279       0.0275     0.000372        0.244         2.36       0.0357
     71   203       0.0221       0.0217      0.00039        0.222         1.81       0.0377


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              71 7970.745    0.005       0.0254     0.000625       0.0261        0.229         2.15       0.0358
! Validation         71 7970.745    0.005       0.0235     0.000346       0.0238        0.222         1.77       0.0313
Wall time: 7970.744893476134

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     72   100       0.0247       0.0247     7.59e-05        0.231         1.33        0.014
     72   200       0.0287       0.0287     5.68e-05        0.235         1.21       0.0125
     72   300       0.0274       0.0272     0.000208         0.24         1.97       0.0263
     72   400       0.0256        0.025     0.000576        0.232         2.88       0.0441
     72   500       0.0177       0.0177     1.56e-05        0.188        0.322      0.00738
     72   600         0.01         0.01     1.55e-05         0.14        0.246      0.00703
     72   700       0.0154       0.0153     0.000104        0.173        0.984       0.0162
     72   800      0.00978      0.00925     0.000523        0.133          1.5       0.0425
     72   900       0.0452       0.0451     0.000115        0.308        0.556       0.0155
     72  1000       0.0135       0.0131     0.000417        0.167          1.4        0.035
     72  1100       0.0197       0.0195     0.000195        0.191          1.6       0.0237
     72  1200       0.0125        0.012     0.000505        0.155         1.29       0.0298
     72  1300       0.0299       0.0297      0.00022        0.258         1.53        0.023
     72  1400        0.025       0.0233      0.00165        0.216         2.95       0.0781
     72  1500       0.0339       0.0336     0.000323        0.279         2.17       0.0303
     72  1600        0.014       0.0139     2.57e-05        0.164        0.354       0.0082
     72  1601       0.0435       0.0431     0.000421        0.285         2.27       0.0388

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     72   100       0.0174       0.0173     0.000104        0.193        0.727       0.0154
     72   200       0.0231       0.0231     1.54e-05        0.224        0.601      0.00741
     72   203       0.0218       0.0218        5e-05        0.218        0.475       0.0099


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              72 8085.908    0.005       0.0236      0.00035       0.0239         0.22         1.66       0.0275
! Validation         72 8085.908    0.005       0.0212     8.13e-05       0.0213        0.209        0.749       0.0119
Wall time: 8085.908801537938
! Best model       72    0.012

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     73   100       0.0285       0.0285      5.5e-05        0.218        0.841       0.0141
     73   200       0.0262       0.0261     7.48e-05        0.217         0.82        0.013
     73   300       0.0463       0.0459     0.000423        0.285         2.98       0.0354
     73   400       0.0284       0.0281      0.00031        0.226         1.62       0.0304
     73   500       0.0378       0.0373     0.000463        0.264        0.834       0.0248
     73   600       0.0289       0.0289     1.74e-05        0.245         0.49      0.00585
     73   700       0.0443       0.0411      0.00319        0.274          6.8        0.106
     73   800       0.0236       0.0234     0.000237        0.227         1.35       0.0282
     73   900       0.0307       0.0306     0.000133        0.232            1       0.0168
     73  1000       0.0186        0.018     0.000597        0.187         2.61       0.0453
     73  1100       0.0749       0.0742     0.000727         0.36         3.21       0.0504
     73  1200       0.0237       0.0229     0.000854         0.21         2.42       0.0561
     73  1300       0.0334       0.0333     0.000176        0.272         4.08       0.0234
     73  1400       0.0293       0.0289     0.000418        0.258         2.22       0.0371
     73  1500       0.0199       0.0187      0.00114        0.203         3.41       0.0645
     73  1600       0.0183       0.0183     4.31e-05        0.204        0.595       0.0112
     73  1601       0.0108       0.0107     7.39e-05        0.146        0.558       0.0159

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     73   100       0.0206       0.0205     0.000147        0.206        0.685       0.0179
     73   200       0.0283       0.0279     0.000435        0.242         2.47       0.0396
     73   203       0.0218       0.0214     0.000438        0.216         1.93       0.0402


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              73 8199.457    0.005       0.0256     0.000695       0.0263        0.229         2.09        0.035
! Validation         73 8199.457    0.005       0.0237     0.000446       0.0241        0.223         1.92       0.0347
Wall time: 8199.45724605699

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     74   100       0.0178       0.0177     0.000119        0.192        0.776       0.0193
     74   200       0.0222       0.0221     0.000104        0.216        0.757       0.0176
     74   300       0.0291        0.029     0.000116        0.253         1.54        0.018
     74   400       0.0272       0.0272     8.84e-05        0.235         0.97       0.0181
     74   500       0.0339       0.0336     0.000256         0.26         1.56       0.0265
     74   600       0.0364       0.0362     0.000188        0.268         1.91       0.0263
     74   700        0.015       0.0145     0.000505        0.171         1.74        0.037
     74   800       0.0354        0.035     0.000313        0.266         1.35       0.0256
     74   900      0.00914        0.009     0.000141        0.136        0.823       0.0201
     74  1000       0.0227       0.0214      0.00137        0.217         4.66       0.0696
     74  1100        0.019        0.019     3.55e-05        0.188        0.346       0.0104
     74  1200       0.0261       0.0257      0.00041        0.244         1.55       0.0323
     74  1300       0.0219       0.0218     0.000101        0.221         1.05       0.0163
     74  1400        0.051       0.0478      0.00316        0.315         7.26          0.1
     74  1500       0.0126       0.0119     0.000704        0.157         1.74       0.0494
     74  1600       0.0458       0.0456     0.000255        0.308         2.54       0.0246
     74  1601       0.0223       0.0216     0.000712        0.218         2.47       0.0515

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     74   100       0.0294       0.0262      0.00324        0.232         4.76        0.108
     74   200       0.0371       0.0351      0.00198        0.276         5.49        0.085
     74   203       0.0372       0.0356      0.00166        0.276         3.75       0.0781


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              74 8314.497    0.005       0.0284     0.000703       0.0291        0.236         2.21       0.0369
! Validation         74 8314.497    0.005       0.0347      0.00336       0.0381        0.261         6.11        0.104
Wall time: 8314.497305247001

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     75   100       0.0478       0.0472     0.000643        0.281         3.73       0.0469
     75   200       0.0359       0.0358     5.03e-05        0.275         1.06        0.012
     75   300       0.0357       0.0356     0.000129        0.269         1.12        0.021
     75   400       0.0321       0.0317     0.000422        0.252         2.63       0.0386
     75   500       0.0206       0.0203      0.00036        0.193         1.14       0.0332
     75   600       0.0258       0.0252     0.000609         0.23         2.91       0.0471
     75   700       0.0127       0.0113      0.00138        0.153          3.1        0.071
     75   800       0.0237       0.0234     0.000242        0.209        0.804       0.0228
     75   900       0.0237       0.0229     0.000784        0.215         2.28       0.0475
     75  1000       0.0392       0.0376      0.00155        0.271         6.29        0.074
     75  1100        0.011        0.011     5.35e-05        0.121        0.294       0.0103
     75  1200       0.0171       0.0171     5.64e-05        0.192        0.466       0.0101
     75  1300       0.0199       0.0197     0.000229        0.206         1.83       0.0272
     75  1400       0.0228       0.0228     5.85e-06        0.225        0.197       0.0041
     75  1500       0.0184       0.0183     5.36e-05        0.196        0.531       0.0126
     75  1600       0.0299       0.0294     0.000455        0.249         2.57       0.0356
     75  1601       0.0327       0.0318     0.000822        0.268         2.55       0.0532

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     75   100       0.0184       0.0183     5.37e-05        0.199        0.501       0.0114
     75   200       0.0243       0.0243     4.99e-05         0.23         1.06       0.0135
     75   203       0.0253       0.0252     0.000101        0.235        0.712       0.0148


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              75 8429.052    0.005       0.0241     0.000335       0.0245        0.222         1.62       0.0268
! Validation         75 8429.052    0.005       0.0226     0.000145       0.0228        0.217         1.02       0.0178
Wall time: 8429.052136477083

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     76   100       0.0297       0.0295     0.000266        0.248         1.17       0.0232
     76   200       0.0284       0.0283     9.64e-05        0.247         1.17       0.0172
     76   300       0.0185       0.0183     0.000156        0.184         0.67       0.0198
     76   400      0.00971      0.00916     0.000546        0.143         1.65        0.044
     76   500       0.0295       0.0291     0.000452        0.259         2.39       0.0403
     76   600       0.0182       0.0179     0.000277        0.193         1.23       0.0271
     76   700        0.031        0.031     6.35e-05         0.23        0.584        0.014
     76   800       0.0235       0.0234     0.000109        0.227        0.874        0.017
     76   900       0.0255       0.0253     0.000156        0.232         1.43       0.0187
     76  1000       0.0174       0.0171       0.0003        0.192         1.36       0.0328
     76  1100       0.0173       0.0169     0.000393        0.186         1.38       0.0309
     76  1200       0.0298       0.0291     0.000663        0.251         2.25       0.0469
     76  1300       0.0157       0.0156      0.00012        0.182         1.23       0.0185
     76  1400       0.0135       0.0131     0.000337        0.156         1.34       0.0328
     76  1500       0.0166       0.0164     0.000145         0.19        0.981       0.0204
     76  1600       0.0182       0.0181     0.000118        0.191        0.695       0.0171
     76  1601       0.0249       0.0249     3.75e-05        0.235        0.543       0.0113

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     76   100       0.0186       0.0183     0.000355        0.197         1.52       0.0358
     76   200       0.0254       0.0253     0.000115        0.233         1.23       0.0183
     76   203       0.0183       0.0182     0.000119        0.199        0.924       0.0193


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              76 8551.761    0.005        0.025     0.000457       0.0255        0.226          1.9       0.0309
! Validation         76 8551.761    0.005       0.0221     0.000212       0.0223        0.214          1.4        0.023
Wall time: 8551.761072020046

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     77   100       0.0331       0.0325     0.000604        0.223         2.53       0.0457
     77   200        0.018        0.018     8.34e-05        0.195         1.09       0.0132
     77   300       0.0237       0.0233     0.000352        0.226         2.09        0.034
     77   400       0.0128       0.0126     0.000175        0.163         1.49       0.0172
     77   500       0.0501       0.0492     0.000971        0.328         3.94       0.0586
     77   600       0.0384       0.0382     0.000155        0.263         1.34       0.0234
     77   700       0.0337       0.0332     0.000581        0.247         2.53       0.0383
     77   800       0.0182       0.0111      0.00709        0.132          5.1        0.159
     77   900       0.0349       0.0348     9.66e-05        0.268         1.17       0.0172
     77  1000        0.032        0.032     4.13e-05        0.251        0.893       0.0122
     77  1100       0.0212        0.021       0.0002        0.209         1.29       0.0269
     77  1200       0.0148       0.0146     0.000216         0.17         0.83       0.0245
     77  1300       0.0978       0.0975     0.000286        0.259         1.93       0.0251
     77  1400       0.0289       0.0283     0.000593        0.246         3.41       0.0356
     77  1500       0.0147       0.0146     1.57e-05        0.182         0.27      0.00562
     77  1600       0.0653       0.0474       0.0178        0.289         13.4        0.254
     77  1601       0.0425       0.0368       0.0057        0.269         14.6        0.144

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     77   100       0.0193       0.0184     0.000963        0.197          2.6       0.0586
     77   200       0.0285        0.028     0.000493        0.243          3.3       0.0422
     77   203       0.0213       0.0209     0.000375        0.216         1.77        0.037


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              77 8678.552    0.005       0.0246     0.000802       0.0254        0.224         1.94       0.0332
! Validation         77 8678.552    0.005        0.022     0.000624       0.0226        0.214         2.87       0.0449
Wall time: 8678.552826500963

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     78   100       0.0372       0.0371     8.04e-05        0.285        0.985        0.017
     78   200       0.0278       0.0277     9.95e-05        0.237          1.3       0.0163
     78   300       0.0284       0.0279     0.000442        0.232         2.73       0.0404
     78   400       0.0269       0.0264     0.000515        0.231         1.22       0.0312
     78   500       0.0212       0.0209      0.00025        0.218          1.3       0.0271
     78   600       0.0109       0.0108      0.00016        0.155         4.65       0.0144
     78   700       0.0294       0.0289     0.000483        0.256            4       0.0405
     78   800       0.0219       0.0214       0.0005        0.212         2.93         0.04
     78   900       0.0316       0.0308     0.000768        0.265         3.26        0.047
     78  1000       0.0266       0.0265     6.11e-05        0.232         0.98        0.014
     78  1100       0.0144        0.013      0.00142         0.16         2.84         0.07
     78  1200       0.0356       0.0353     0.000259        0.259         2.69       0.0239
     78  1300       0.0329       0.0319      0.00097        0.249         2.92       0.0556
     78  1400       0.0166       0.0158     0.000829        0.177         2.76       0.0525
     78  1500       0.0157       0.0155     0.000231        0.182         1.89        0.025
     78  1600       0.0278       0.0278     5.06e-05         0.25        0.424      0.00884
     78  1601       0.0397       0.0391     0.000625        0.248         8.05        0.048

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     78   100       0.0215       0.0209     0.000577        0.209         1.88       0.0453
     78   200       0.0271       0.0268     0.000277        0.241         1.76       0.0293
     78   203       0.0188       0.0187     7.82e-05        0.204        0.817        0.017


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              78 8793.707    0.005       0.0259     0.000758       0.0267        0.233         2.13       0.0361
! Validation         78 8793.707    0.005        0.023     0.000305       0.0233        0.221         1.67       0.0278
Wall time: 8793.707547876053

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     79   100       0.0261       0.0256     0.000468        0.222         2.16       0.0383
     79   200       0.0171       0.0157      0.00138        0.172         1.56       0.0509
     79   300       0.0194       0.0192     0.000257        0.197         1.76       0.0217
     79   400       0.0231        0.023     9.18e-05        0.203        0.592       0.0135
     79   500       0.0358       0.0358     5.58e-05        0.249         0.78       0.0136
     79   600       0.0445       0.0444     5.72e-05        0.303        0.743       0.0132
     79   700       0.0424       0.0423      0.00014        0.291         1.61       0.0194
     79   800        0.018       0.0179     0.000109         0.18        0.762       0.0187
     79   900       0.0199       0.0189     0.000964        0.195         2.09       0.0543
     79  1000       0.0347       0.0343     0.000426        0.244         2.05       0.0312
     79  1100       0.0277       0.0276     0.000129        0.234         1.48        0.021
     79  1200       0.0147       0.0143     0.000384        0.178        0.973       0.0312
     79  1300       0.0444       0.0435     0.000953        0.302          4.2       0.0571
     79  1400       0.0187       0.0183     0.000404          0.2         2.77       0.0354
     79  1500       0.0105       0.0104      7.8e-05        0.148        0.519       0.0141
     79  1600       0.0207       0.0205     0.000123        0.207        0.629       0.0168
     79  1601      0.00585      0.00572     0.000131        0.114        0.616        0.022

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     79   100       0.0184       0.0182     0.000119        0.197        0.656       0.0164
     79   200        0.025       0.0249      0.00013        0.234         1.95       0.0203
     79   203       0.0212       0.0211     7.14e-05        0.221        0.715       0.0149


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              79 8907.857    0.005       0.0263     0.000541       0.0268        0.231         1.98       0.0329
! Validation         79 8907.857    0.005       0.0224      0.00018       0.0226        0.217         1.19       0.0193
Wall time: 8907.85729372711

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     80   100       0.0252       0.0246     0.000628        0.219         1.97       0.0459
     80   200       0.0331       0.0331     1.16e-05        0.259        0.312      0.00598
     80   300       0.0207       0.0204      0.00031        0.208         1.33       0.0298
     80   400       0.0159       0.0156     0.000277        0.182         1.83       0.0294
     80   500       0.0167       0.0166     1.37e-05        0.175        0.417      0.00555
     80   600       0.0292        0.029     0.000248         0.24         2.25       0.0275
     80   700       0.0107       0.0106     4.26e-05        0.148        0.527       0.0112
     80   800       0.0102       0.0101     4.57e-05        0.138        0.639       0.0104
     80   900       0.0196       0.0191     0.000508        0.203         1.64       0.0407
     80  1000       0.0222       0.0221     9.23e-05        0.217        0.662       0.0161
     80  1100       0.0545       0.0533      0.00115        0.284         4.36       0.0624
     80  1200      0.00923      0.00902     0.000207        0.118        0.937       0.0268
     80  1300        0.019       0.0187     0.000235        0.197         1.24       0.0287
     80  1400       0.0132       0.0131     8.46e-05         0.16         1.01       0.0174
     80  1500        0.016        0.016     2.84e-05        0.176        0.287      0.00784
     80  1600       0.0253       0.0247     0.000555         0.23         3.31       0.0455
     80  1601        0.696        0.695     0.000384        0.381         3.25       0.0374

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     80   100       0.0174       0.0172     0.000135        0.189        0.859        0.018
     80   200       0.0249       0.0249     4.94e-06         0.23        0.178       0.0035
     80   203       0.0208       0.0208     2.62e-05        0.217        0.471      0.00981


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              80 9020.818    0.005       0.0235     0.000374       0.0238        0.216         1.73       0.0286
! Validation         80 9020.818    0.005       0.0204     7.96e-05       0.0205        0.204        0.814       0.0123
Wall time: 9020.817977485945

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     81   100       0.0472       0.0468     0.000423        0.294            2       0.0348
     81   200       0.0251       0.0248     0.000305        0.234         1.56       0.0325
     81   300       0.0158       0.0156     0.000132         0.18        0.792        0.018
     81   400       0.0304       0.0298     0.000612        0.263         1.96       0.0409
     81   500       0.0305       0.0302     0.000265        0.246        0.991       0.0249
     81   600       0.0313       0.0306     0.000646        0.251         2.38       0.0445
     81   700       0.0161       0.0158     0.000326        0.174         1.11       0.0317
     81   800       0.0191       0.0187     0.000394        0.191          1.4       0.0315
     81   900       0.0102      0.00971      0.00045         0.14         1.72       0.0387
     81  1000       0.0178       0.0177     2.17e-05         0.19        0.339      0.00844
     81  1100       0.0263       0.0262     6.42e-05        0.244        0.697       0.0145
     81  1200         0.02       0.0199     6.07e-05        0.198        0.674        0.014
     81  1300       0.0326       0.0322     0.000412        0.242         2.91       0.0381
     81  1400       0.0255       0.0254     6.62e-05        0.229        0.659        0.015
     81  1500       0.0245       0.0243     0.000107        0.222        0.689       0.0178
     81  1600       0.0387       0.0386     0.000121         0.29         1.33       0.0193
     81  1601       0.0238       0.0238     4.37e-05        0.226         1.72       0.0118

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     81   100       0.0196       0.0192     0.000485        0.203          1.8        0.041
     81   200       0.0262        0.026     0.000201        0.238         1.69       0.0236
     81   203       0.0217       0.0215     0.000121        0.221         1.02       0.0212


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              81 9139.971    0.005       0.0263     0.000702        0.027        0.233          2.1       0.0352
! Validation         81 9139.971    0.005       0.0228     0.000237        0.023        0.219         1.47       0.0238
Wall time: 9139.971573304152

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     82   100       0.0238       0.0223      0.00148        0.211         3.98       0.0728
     82   200       0.0249       0.0242     0.000745        0.225         3.63       0.0419
     82   300       0.0249       0.0243     0.000572        0.229          1.5       0.0324
     82   400       0.0246       0.0242     0.000418        0.234         2.27       0.0379
     82   500       0.0222       0.0215     0.000649        0.209          2.9       0.0486
     82   600       0.0273       0.0272     9.46e-05        0.246        0.871       0.0156
     82   700       0.0367       0.0365     0.000246        0.286         2.18       0.0295
     82   800       0.0158       0.0157     9.26e-05        0.191        0.781       0.0163
     82   900        0.026       0.0258     0.000198         0.23         2.25       0.0255
     82  1000       0.0249       0.0249     2.11e-05        0.229        0.383      0.00672
     82  1100       0.0295        0.029     0.000543        0.246         2.58       0.0408
     82  1200       0.0602       0.0602     1.14e-05        0.353        0.377      0.00535
     82  1300       0.0409       0.0408     0.000122        0.283          1.6       0.0202
     82  1400       0.0196       0.0176        0.002        0.193         3.58       0.0849
     82  1500         0.02       0.0196     0.000401        0.189         1.51       0.0377
     82  1600       0.0172       0.0171     3.35e-05        0.182        0.621      0.00873
     82  1601       0.0189       0.0188     8.89e-05        0.179        0.415       0.0134

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     82   100         0.02       0.0188      0.00114        0.199         2.85       0.0647
     82   200       0.0245        0.024     0.000503        0.231         3.08       0.0432
     82   203       0.0205       0.0201     0.000353        0.212         1.74       0.0362


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              82 9252.635    0.005       0.0251     0.000552       0.0257        0.228         2.07       0.0345
! Validation         82 9252.635    0.005       0.0214     0.000749       0.0221        0.211         2.98       0.0493
Wall time: 9252.635174943134

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     83   100       0.0228       0.0226     0.000175        0.208            1       0.0244
     83   200       0.0443       0.0421      0.00222        0.269         4.36       0.0875
     83   300       0.0147       0.0147     2.45e-05        0.184        0.539      0.00835
     83   400       0.0128       0.0127      7.5e-05        0.164         1.08       0.0161
     83   500       0.0274       0.0272     0.000175        0.224         1.48       0.0209
     83   600       0.0233       0.0227     0.000633        0.217         2.22       0.0389
     83   700       0.0237       0.0235     0.000224        0.224         1.92       0.0223
     83   800       0.0283       0.0283     1.57e-05        0.241        0.456      0.00515
     83   900       0.0181       0.0181     7.03e-05        0.192        0.902       0.0146
     83  1000       0.0259       0.0256     0.000247        0.228         1.63       0.0285
     83  1100       0.0173       0.0172     8.95e-05        0.182         1.08       0.0158
     83  1200       0.0202       0.0202     5.05e-05        0.201        0.567       0.0119
     83  1300       0.0161       0.0158     0.000369        0.174         1.44       0.0339
     83  1400       0.0384       0.0383     6.87e-05        0.255         1.18       0.0156
     83  1500       0.0235       0.0235     2.51e-05         0.22        0.478      0.00842
     83  1600       0.0195        0.019     0.000451        0.199         1.53       0.0325
     83  1601       0.0515       0.0509     0.000551        0.323         3.47       0.0454

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     83   100       0.0176       0.0173     0.000239        0.192         1.19       0.0284
     83   200       0.0237       0.0237     5.06e-05        0.224        0.428       0.0105
     83   203       0.0208       0.0207     1.45e-05        0.212        0.309      0.00643


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              83 9366.185    0.005       0.0229     0.000347       0.0233        0.216         1.66       0.0276
! Validation         83 9366.185    0.005       0.0202     0.000176       0.0204        0.203         1.15       0.0199
Wall time: 9366.185625212966

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     84   100       0.0217       0.0217     4.73e-05        0.209        0.551       0.0121
     84   200       0.0148       0.0147     5.39e-05        0.167         0.48       0.0109
     84   300       0.0152       0.0148     0.000393         0.17        0.909       0.0295
     84   400       0.0184       0.0174     0.000921        0.188         1.61       0.0487
     84   500       0.0118       0.0117     7.99e-05        0.163         0.69       0.0168
     84   600       0.0261       0.0257     0.000421        0.226         1.51       0.0364
     84   700       0.0185       0.0182     0.000237        0.183         3.36       0.0241
     84   800        0.034       0.0334     0.000637        0.264         1.56       0.0369
     84   900        0.022       0.0218      0.00019        0.195         1.18       0.0225
     84  1000       0.0262       0.0259      0.00035         0.23         1.96       0.0318
     84  1100       0.0171       0.0169     0.000118        0.189        0.783       0.0191
     84  1200       0.0297       0.0296     3.64e-05        0.252         1.43       0.0108
     84  1300       0.0161       0.0159     0.000121        0.179        0.471       0.0159
     84  1400        0.022       0.0206      0.00138        0.205         2.57       0.0561
     84  1500       0.0196       0.0195      0.00011        0.203         1.57       0.0197
     84  1600       0.0284       0.0283     0.000121        0.239         1.32        0.018
     84  1601       0.0227       0.0227     2.59e-05        0.223        0.464      0.00967

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     84   100        0.019       0.0186     0.000441        0.202          1.7       0.0388
     84   200       0.0277       0.0276     0.000163        0.236         1.36       0.0234
     84   203        0.023       0.0229     7.09e-05        0.228         0.78       0.0162


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              84 9479.470    0.005       0.0275      0.00122       0.0287        0.235         2.06       0.0341
! Validation         84 9479.470    0.005       0.0232      0.00038       0.0236         0.22         1.95       0.0318
Wall time: 9479.470136604039

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     85   100       0.0207       0.0206     0.000166        0.201        0.895       0.0203
     85   200       0.0473        0.047     0.000294         0.32         1.56       0.0271
     85   300       0.0427       0.0392      0.00353        0.279         6.25       0.0659
     85   400       0.0294       0.0285     0.000942        0.232         2.51        0.056
     85   500       0.0198       0.0196     0.000283        0.198         1.42       0.0316
     85   600       0.0258       0.0257     8.07e-05         0.24        0.672       0.0128
     85   700       0.0362       0.0314      0.00486        0.238         6.29         0.13
     85   800       0.0474       0.0458      0.00158          0.3         2.26       0.0435
     85   900       0.0249       0.0249     3.88e-05        0.227        0.491      0.00929
     85  1000       0.0216       0.0216     3.64e-05        0.212         0.48       0.0111
     85  1100       0.0189       0.0189     1.98e-05        0.196        0.328       0.0078
     85  1200       0.0129       0.0128     7.17e-05        0.159        0.481       0.0131
     85  1300         0.02       0.0199     9.12e-05        0.187        0.701        0.018
     85  1400         0.03         0.03     2.71e-05         0.25        0.868      0.00933
     85  1500       0.0185       0.0184     9.45e-05        0.194        0.966       0.0157
     85  1600       0.0349       0.0348     9.29e-05        0.263         0.77       0.0162
     85  1601       0.0185       0.0181     0.000454        0.185         1.34       0.0389

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     85   100       0.0188       0.0186      0.00022        0.201        0.774        0.021
     85   200       0.0258       0.0254     0.000359        0.234         2.51       0.0363
     85   203       0.0225        0.022     0.000523         0.22         2.08       0.0433


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              85 9593.885    0.005        0.027     0.000527       0.0275        0.231         1.94       0.0321
! Validation         85 9593.885    0.005       0.0216     0.000444        0.022        0.212         2.25       0.0379
Wall time: 9593.884991469095

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     86   100       0.0268       0.0265     0.000335        0.237         1.92       0.0251
     86   200         0.02       0.0199     0.000102          0.2        0.807       0.0181
     86   300        0.029        0.029     1.28e-05        0.242        0.435      0.00645
     86   400      0.00844      0.00716      0.00128        0.124         2.13        0.067
     86   500       0.0128       0.0124     0.000349        0.159         2.11       0.0356
     86   600       0.0185       0.0183     0.000164        0.195        0.857        0.019
     86   700       0.0184       0.0181     0.000212        0.198         1.31       0.0273
     86   800       0.0232        0.023      0.00013        0.227        0.851       0.0166
     86   900        0.012       0.0117     0.000356        0.143         1.38       0.0356
     86  1000       0.0178       0.0174     0.000402        0.182         1.45        0.033
     86  1100       0.0234       0.0234     6.66e-05        0.212         2.44       0.0115
     86  1200       0.0285       0.0285     1.91e-05         0.25         1.03      0.00698
     86  1300       0.0167       0.0165     0.000239        0.184         1.57       0.0296
     86  1400         0.02        0.019     0.000968        0.184         2.03       0.0576
     86  1500        0.034       0.0334      0.00057        0.267         2.66       0.0449
     86  1600       0.0121       0.0121     6.42e-05        0.152        0.643       0.0138
     86  1601      0.00271      0.00249     0.000219       0.0734        0.794       0.0284

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     86   100       0.0172       0.0171     8.19e-05        0.192         0.65       0.0156
     86   200       0.0251       0.0251     1.03e-05        0.231        0.484      0.00553
     86   203       0.0212       0.0212     1.71e-05        0.218         0.31      0.00646


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              86 9707.473    0.005       0.0247     0.000408       0.0251        0.225         1.78       0.0297
! Validation         86 9707.473    0.005       0.0205     9.83e-05       0.0206        0.206        0.829       0.0139
Wall time: 9707.473315289943

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     87   100       0.0169       0.0169     4.06e-05        0.182        0.458        0.011
     87   200       0.0253       0.0252     6.52e-05        0.238        0.624        0.013
     87   300       0.0249       0.0243     0.000591        0.231         3.38       0.0468
     87   400       0.0189       0.0183     0.000585          0.2          1.9        0.043
     87   500       0.0284       0.0282     0.000216        0.234         1.38       0.0256
     87   600        0.026       0.0259     5.98e-05        0.226        0.655       0.0132
     87   700       0.0187       0.0186     0.000153          0.2        0.684        0.019
     87   800       0.0188       0.0187      0.00014        0.208         1.04       0.0217
     87   900       0.0227       0.0226     3.54e-05        0.214        0.438      0.00995
     87  1000       0.0248       0.0224      0.00235        0.225         4.44       0.0926
     87  1100       0.0227       0.0226      8.7e-05        0.213        0.487       0.0135
     87  1200       0.0241       0.0237     0.000394         0.22         1.65        0.037
     87  1300       0.0413       0.0411     0.000249        0.287         2.34       0.0283
     87  1400       0.0257       0.0256     8.67e-05        0.238        0.621       0.0152
     87  1500      0.00954      0.00932     0.000214        0.123        0.681       0.0231
     87  1600       0.0179       0.0179      8.3e-06        0.167        0.143      0.00478
     87  1601       0.0131       0.0129      0.00011        0.167        0.575       0.0177

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     87   100       0.0194       0.0191     0.000235          0.2        0.806       0.0223
     87   200       0.0269       0.0268     8.27e-05        0.242          0.8       0.0155
     87   203       0.0254       0.0253     5.25e-05        0.241        0.526        0.011


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              87 9817.850    0.005       0.0244     0.000422       0.0248        0.223          1.8       0.0302
! Validation         87 9817.850    0.005       0.0235     0.000195       0.0237        0.219         1.21       0.0216
Wall time: 9817.850589750102

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     88   100       0.0352       0.0351     7.74e-05        0.249        0.606        0.015
     88   200       0.0221       0.0215     0.000512        0.219         2.19       0.0428
     88   300       0.0225        0.018      0.00451        0.197         7.22         0.13
     88   400       0.0192       0.0191      2.5e-05        0.198        0.314      0.00821
     88   500       0.0309       0.0291      0.00187        0.257         3.64       0.0828
     88   600       0.0218       0.0215     0.000231        0.204         2.41       0.0283
     88   700       0.0253       0.0253     2.58e-05        0.225        0.326      0.00887
     88   800       0.0309       0.0306     0.000274        0.256         1.28       0.0308
     88   900       0.0278       0.0277     1.52e-05        0.241        0.515       0.0072
     88  1000        0.029       0.0287     0.000347         0.25         3.18       0.0262
     88  1100       0.0355       0.0343      0.00129        0.257         3.88       0.0376
     88  1200       0.0253       0.0252     8.44e-05        0.227        0.824       0.0163
     88  1300       0.0381       0.0381     3.77e-05        0.284        0.623       0.0109
     88  1400       0.0172       0.0172     1.51e-05        0.196        0.278      0.00579
     88  1500       0.0374       0.0372     0.000233        0.266         1.75       0.0268
     88  1600        0.032       0.0311     0.000876        0.255         4.47       0.0494
     88  1601       0.0491       0.0479      0.00122        0.279         5.48       0.0605

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     88   100       0.0181        0.018        8e-05          0.2        0.534       0.0137
     88   200       0.0262       0.0262     5.35e-05        0.237         1.04       0.0113
     88   203       0.0211       0.0211     2.82e-05        0.219        0.491       0.0102


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              88 9932.517    0.005       0.0261     0.000664       0.0267        0.231         1.98       0.0328
! Validation         88 9932.517    0.005       0.0218       0.0001       0.0219        0.214         0.86       0.0143
Wall time: 9932.517096844036

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     89   100       0.0241       0.0235     0.000603        0.227         1.47       0.0325
     89   200       0.0259       0.0253     0.000589        0.235         2.22       0.0462
     89   300       0.0226       0.0224     0.000204        0.215        0.546       0.0171
     89   400       0.0142       0.0142      2.7e-05        0.172         0.31      0.00883
     89   500       0.0301       0.0296     0.000413        0.251         2.57        0.037
     89   600       0.0184       0.0182     0.000222        0.197         1.67        0.025
     89   700       0.0245       0.0239     0.000586        0.232         2.19       0.0456
     89   800       0.0321       0.0319     0.000194        0.245         1.95       0.0239
     89   900       0.0253        0.025     0.000231        0.217         1.51       0.0229
     89  1000       0.0192       0.0185     0.000723        0.207         2.25       0.0469
     89  1100       0.0181       0.0181     2.88e-05        0.198        0.603      0.00843
     89  1200       0.0324       0.0319     0.000494         0.24         3.12       0.0319
     89  1300       0.0372       0.0371     0.000121        0.286        0.977       0.0204
     89  1400       0.0208       0.0194      0.00137        0.191         3.21       0.0704
     89  1500       0.0247       0.0221      0.00264        0.218         4.08       0.0967
     89  1600       0.0152       0.0151     9.79e-05        0.175        0.792       0.0171
     89  1601       0.0217       0.0216     0.000105        0.204         0.65       0.0188

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     89   100       0.0188       0.0179     0.000843        0.195         2.36       0.0551
     89   200       0.0266        0.026     0.000585        0.236         2.74       0.0438
     89   203       0.0222       0.0219     0.000367        0.221         1.75       0.0365


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              89 10044.610    0.005       0.0242     0.000448       0.0246        0.222         1.84       0.0309
! Validation         89 10044.610    0.005       0.0226     0.000649       0.0233        0.217          2.6       0.0453
Wall time: 10044.610690451926

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     90   100       0.0251        0.025      0.00011        0.241        0.834       0.0174
     90   200      0.00875      0.00865     9.86e-05        0.124        0.537       0.0179
     90   300       0.0173       0.0162      0.00111        0.177          2.8       0.0637
     90   400       0.0322       0.0319     0.000315        0.243         1.86       0.0317
     90   500       0.0199       0.0196     0.000291        0.192         1.84         0.03
     90   600        0.018       0.0179     0.000156        0.176         1.73       0.0218
     90   700       0.0176       0.0175     0.000156         0.18          1.4        0.022
     90   800       0.0246       0.0233      0.00135         0.22         5.46        0.069
     90   900       0.0219       0.0219     6.22e-06         0.21         0.24      0.00445
     90  1000       0.0136       0.0131     0.000467        0.162         2.33       0.0414
     90  1100       0.0232       0.0231     4.73e-05        0.228          2.6       0.0081
     90  1200       0.0162       0.0161        2e-05        0.181        0.463      0.00822
     90  1300      0.00917      0.00864     0.000534        0.118         1.68       0.0433
     90  1400       0.0212        0.021     0.000237        0.216        0.994       0.0207
     90  1500       0.0234       0.0227     0.000675        0.207         2.89       0.0493
     90  1600         0.13        0.129      0.00156        0.383         5.87       0.0685
     90  1601       0.0619       0.0577      0.00416        0.347         8.71        0.124

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     90   100       0.0179       0.0178     0.000152        0.191        0.981       0.0215
     90   200       0.0247       0.0246     6.08e-05        0.232        0.577       0.0106
     90   203       0.0171       0.0171     1.08e-05        0.193        0.256      0.00534


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              90 10158.931    0.005       0.0246     0.000417       0.0251         0.22          1.8       0.0299
! Validation         90 10158.931    0.005       0.0218     8.92e-05       0.0219        0.213        0.821       0.0125
Wall time: 10158.931680451147

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     91   100       0.0273       0.0268     0.000521        0.232         1.46       0.0405
     91   200       0.0222       0.0221     4.82e-05         0.22        0.785       0.0111
     91   300       0.0253       0.0251     0.000238        0.238         1.21       0.0268
     91   400       0.0174       0.0171     0.000358        0.178         1.58       0.0355
     91   500        0.024       0.0236      0.00039         0.23         1.62       0.0381
     91   600       0.0337       0.0331     0.000573        0.259         3.53       0.0446
     91   700       0.0191       0.0174      0.00174        0.192         2.54       0.0747
     91   800       0.0263       0.0261     0.000182         0.24         1.58       0.0243
     91   900       0.0247       0.0245     0.000204        0.214         1.75       0.0237
     91  1000       0.0229       0.0228     0.000105        0.225         1.73       0.0193
     91  1100       0.0114       0.0112     0.000138        0.138        0.654       0.0212
     91  1200       0.0177       0.0172     0.000444        0.189         1.84       0.0385
     91  1300        0.046       0.0419      0.00404        0.277         6.94         0.12
     91  1400       0.0172       0.0157      0.00156        0.176         3.95       0.0758
     91  1500       0.0199       0.0195     0.000489        0.205         2.12       0.0412
     91  1600       0.0152        0.015     0.000218        0.184         1.51       0.0275
     91  1601       0.0214       0.0212     0.000181        0.212         1.06       0.0221

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     91   100       0.0183       0.0181     0.000273        0.197         1.07       0.0276
     91   200       0.0264        0.026     0.000391        0.237         3.22       0.0366
     91   203       0.0232       0.0228     0.000325        0.226         1.54       0.0321


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              91 10270.039    0.005       0.0252     0.000465       0.0257        0.224         1.84       0.0307
! Validation         91 10270.039    0.005       0.0218     0.000379       0.0222        0.213         2.01       0.0337
Wall time: 10270.03919294593

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     92   100       0.0291       0.0291     8.16e-05        0.242         1.09       0.0139
     92   200       0.0218       0.0215     0.000247        0.206         1.14        0.026
     92   300       0.0126       0.0121     0.000531        0.151         1.63       0.0416
     92   400       0.0274       0.0272     0.000159         0.23        0.943       0.0229
     92   500       0.0187       0.0186      5.8e-05          0.2        0.914        0.013
     92   600       0.0142       0.0141     0.000119        0.158        0.741       0.0161
     92   700       0.0252       0.0249     0.000321        0.238         2.26       0.0297
     92   800       0.0335       0.0334     0.000132        0.256         1.05       0.0176
     92   900       0.0354       0.0353     8.58e-05        0.275        0.926       0.0146
     92  1000       0.0321       0.0312     0.000919         0.26         2.43       0.0497
     92  1100       0.0234       0.0232     0.000228        0.223         1.44       0.0268
     92  1200       0.0269       0.0259     0.000989        0.234         2.96       0.0584
     92  1300       0.0487       0.0485     0.000156        0.317         1.45       0.0191
     92  1400       0.0334       0.0312      0.00224        0.258         7.67       0.0905
     92  1500       0.0261        0.026     0.000111        0.239         1.81       0.0184
     92  1600       0.0301       0.0291      0.00103        0.247         3.79       0.0546
     92  1601       0.0428       0.0426     0.000185        0.307         2.15       0.0248

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     92   100       0.0195        0.019     0.000501        0.203         1.85       0.0411
     92   200       0.0299       0.0299     3.35e-05        0.251        0.772       0.0106
     92   203       0.0265       0.0263     0.000138        0.237         1.02       0.0212


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              92 10381.613    0.005       0.0248     0.000544       0.0254        0.225         1.85       0.0309
! Validation         92 10381.613    0.005       0.0247     0.000292        0.025        0.227         1.73       0.0261
Wall time: 10381.613705712138

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     93   100       0.0293       0.0291     0.000257        0.245         2.14       0.0263
     93   200       0.0224        0.022     0.000371        0.209         2.67        0.034
     93   300       0.0272        0.027     0.000178        0.238        0.928       0.0193
     93   400       0.0278       0.0276     0.000234        0.243         1.24       0.0258
     93   500       0.0272       0.0272     6.43e-05        0.243        0.678       0.0141
     93   600       0.0732       0.0695      0.00368        0.336         7.54       0.0914
     93   700        0.012       0.0119     9.14e-05        0.147        0.557       0.0162
     93   800       0.0198       0.0198     7.23e-06        0.208         0.25       0.0044
     93   900       0.0317       0.0315     0.000194         0.26         1.42       0.0227
     93  1000       0.0107      0.00952      0.00113        0.147         3.95       0.0605
     93  1100       0.0197       0.0197     6.12e-05        0.206        0.885       0.0146
     93  1200       0.0258       0.0254     0.000399        0.234         1.83        0.038
     93  1300       0.0198       0.0194     0.000328        0.208         1.83       0.0296
     93  1400        0.038       0.0375     0.000502         0.27         3.75       0.0431
     93  1500       0.0219       0.0218     9.35e-05        0.193         1.18        0.014
     93  1600       0.0178       0.0173     0.000518        0.185         1.38       0.0401
     93  1601       0.0332       0.0327     0.000522        0.258         1.77       0.0388

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     93   100       0.0207       0.0193      0.00145        0.205          3.1       0.0733
     93   200       0.0285       0.0276     0.000871        0.242         3.48       0.0529
     93   203       0.0272       0.0265     0.000673        0.243         2.39       0.0497


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              93 10493.915    0.005       0.0256     0.000491        0.026        0.228         1.88       0.0315
! Validation         93 10493.915    0.005       0.0253      0.00105       0.0264        0.226         3.48       0.0595
Wall time: 10493.91521716793

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     94   100       0.0182        0.018     0.000148        0.199        0.905       0.0192
     94   200       0.0174       0.0171      0.00038        0.195         1.57       0.0356
     94   300       0.0307       0.0307     3.15e-05        0.263         2.12      0.00641
     94   400       0.0144       0.0142     0.000143        0.177         1.16       0.0219
     94   500       0.0332        0.033     0.000111        0.248         1.79        0.018
     94   600        0.033       0.0328     0.000149        0.248         1.57       0.0211
     94   700       0.0303       0.0302     0.000112        0.256        0.726       0.0145
     94   800       0.0298       0.0296     0.000197        0.219         1.49       0.0245
     94   900       0.0207       0.0206     0.000134        0.209         1.77       0.0197
     94  1000       0.0291       0.0289     0.000195        0.256          1.6       0.0195
     94  1100       0.0121       0.0118     0.000374        0.136         1.08       0.0313
     94  1200       0.0221       0.0219     0.000145        0.196        0.651       0.0159
     94  1300       0.0245       0.0244     0.000153        0.218         1.25        0.023
     94  1400       0.0482       0.0481     0.000161        0.281        0.867        0.018
     94  1500       0.0389       0.0369      0.00206        0.263         5.11       0.0599
     94  1600      0.00295      0.00287      8.5e-05       0.0713         0.48       0.0149
     94  1601       0.0177       0.0172     0.000537        0.188         1.72       0.0448

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     94   100       0.0184       0.0183     0.000181          0.2         1.09       0.0233
     94   200       0.0255       0.0255     9.65e-06        0.236        0.338      0.00512
     94   203       0.0189       0.0189     3.74e-05          0.2        0.503       0.0105


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              94 10609.485    0.005       0.0241     0.000343       0.0245        0.221          1.6       0.0265
! Validation         94 10609.485    0.005       0.0216     0.000126       0.0218        0.212        0.979       0.0155
Wall time: 10609.485262349015

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     95   100       0.0304       0.0302     0.000196        0.255         4.64       0.0239
     95   200       0.0196       0.0189     0.000706        0.197         2.78       0.0473
     95   300       0.0097      0.00957     0.000127        0.135        0.676       0.0191
     95   400        0.021       0.0209     9.76e-05        0.208        0.932       0.0187
     95   500       0.0288       0.0288     5.56e-05        0.233        0.824       0.0118
     95   600       0.0364       0.0363     4.61e-05        0.261        0.834       0.0125
     95   700       0.0486        0.047      0.00164        0.296         3.95       0.0768
     95   800        0.026       0.0255     0.000482        0.222         3.39       0.0313
     95   900       0.0282        0.028     0.000127        0.247         0.33       0.0112
     95  1000       0.0193       0.0188     0.000455        0.201         2.62       0.0401
     95  1100       0.0195       0.0176      0.00189        0.195         1.66       0.0518
     95  1200       0.0613       0.0599      0.00141        0.303          3.7       0.0713
     95  1300       0.0378       0.0369     0.000876        0.279         3.49       0.0395
     95  1400       0.0274       0.0273     0.000126        0.246          3.1       0.0201
     95  1500       0.0288       0.0283     0.000506        0.228         1.87       0.0421
     95  1600       0.0391       0.0355      0.00361        0.269         4.83        0.115
     95  1601       0.0177       0.0143      0.00346        0.157         4.33        0.114

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     95   100       0.0171       0.0169     0.000136         0.19         0.71       0.0184
     95   200        0.026       0.0257     0.000336         0.23         2.91       0.0343
     95   203         0.02       0.0198     0.000276        0.208         1.52       0.0317


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              95 10720.236    0.005       0.0259     0.000523       0.0264        0.227          1.9       0.0321
! Validation         95 10720.236    0.005       0.0213     0.000312       0.0216        0.209         1.89       0.0315
Wall time: 10720.236176179023

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     96   100       0.0254       0.0235      0.00184        0.222          3.3       0.0797
     96   200       0.0153       0.0151     0.000241        0.178          2.6       0.0299
     96   300        0.018       0.0178     0.000196        0.198         1.22       0.0255
     96   400       0.0319       0.0317     0.000123        0.244         1.56       0.0188
     96   500       0.0255       0.0254     0.000138        0.227        0.874       0.0155
     96   600       0.0144       0.0143     0.000162        0.173        0.982       0.0209
     96   700       0.0165       0.0164     0.000115        0.178        0.803       0.0169
     96   800       0.0045      0.00438      0.00012       0.0958        0.568       0.0203
     96   900       0.0177       0.0176     0.000109        0.191        0.721       0.0176
     96  1000        0.018        0.018     3.87e-05         0.19         0.49      0.00977
     96  1100       0.0197       0.0195     0.000179        0.205         1.14       0.0238
     96  1200       0.0298       0.0295     0.000327        0.254         2.06       0.0274
     96  1300       0.0314       0.0295      0.00189        0.258         3.89       0.0811
     96  1400       0.0345       0.0342     0.000243        0.244        0.626       0.0219
     96  1500        0.021       0.0188      0.00216        0.178         3.37       0.0895
     96  1600        0.024       0.0238     0.000243        0.231         1.51        0.027
     96  1601       0.0198       0.0176      0.00219        0.194         7.28        0.089

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     96   100       0.0192       0.0191     0.000174        0.202        0.857       0.0216
     96   200       0.0297       0.0297     7.14e-05        0.244         1.18       0.0144
     96   203       0.0216       0.0215     0.000147        0.224            1       0.0209


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              96 10832.637    0.005       0.0235     0.000391       0.0239        0.218         1.72       0.0285
! Validation         96 10832.637    0.005       0.0238     0.000247        0.024         0.22         1.28       0.0233
Wall time: 10832.636864813045

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     97   100       0.0269       0.0268     5.59e-05        0.239        0.405       0.0108
     97   200       0.0138       0.0135     0.000285         0.17         1.21       0.0299
     97   300       0.0315       0.0313     0.000207        0.254        0.515       0.0165
     97   400       0.0153       0.0152     0.000171        0.178        0.905       0.0235
     97   500       0.0214       0.0213     8.15e-05        0.203        0.644       0.0157
     97   600      0.00781      0.00765     0.000159        0.123         0.82       0.0242
     97   700      0.00581      0.00527     0.000537       0.0922         1.26       0.0421
     97   800        0.023        0.023     1.51e-05        0.204        0.283      0.00594
     97   900       0.0248       0.0226      0.00218        0.219         5.43       0.0903
     97  1000       0.0318       0.0318     5.47e-05        0.268         1.13       0.0129
     97  1100       0.0481        0.048     5.35e-05        0.304         1.04       0.0122
     97  1200       0.0285       0.0284     1.06e-05        0.232        0.248      0.00519
     97  1300       0.0193       0.0191      0.00024        0.202         1.26        0.029
     97  1400       0.0288       0.0288     3.56e-05        0.249        0.734       0.0101
     97  1500       0.0157       0.0154     0.000273        0.171        0.934       0.0268
     97  1600        0.035       0.0349     0.000116        0.274        0.982       0.0205
     97  1601       0.0278       0.0277     0.000156        0.249        0.862       0.0186

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     97   100       0.0191       0.0177      0.00137        0.199         3.07        0.066
     97   200       0.0272       0.0265     0.000742        0.239         3.72       0.0514
     97   203       0.0249       0.0241     0.000835         0.23         2.63       0.0548


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              97 10946.260    0.005       0.0238     0.000612       0.0245         0.22         1.91       0.0317
! Validation         97 10946.260    0.005       0.0219     0.000902       0.0228        0.213         3.37       0.0545
Wall time: 10946.260259459028

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     98   100       0.0245       0.0245     5.35e-05        0.215        0.697       0.0126
     98   200        0.033       0.0329     0.000128        0.247         1.68       0.0197
     98   300       0.0237       0.0229     0.000793        0.223         2.56       0.0534
     98   400        0.023       0.0229      0.00014         0.21         1.25       0.0194
     98   500        0.019       0.0187     0.000306        0.185         1.21       0.0332
     98   600       0.0319       0.0314     0.000524         0.23         3.84       0.0409
     98   700        0.022       0.0219     7.76e-05        0.216        0.558       0.0142
     98   800       0.0364       0.0362     0.000179        0.264         2.37       0.0224
     98   900       0.0193       0.0188     0.000544          0.2         1.98       0.0379
     98  1000       0.0239       0.0238     0.000139        0.226         1.17       0.0172
     98  1100       0.0196       0.0194     0.000203        0.205         1.31       0.0272
     98  1200       0.0132        0.013     0.000243        0.166         1.49       0.0296
     98  1300      0.00368      0.00353     0.000152       0.0842        0.635       0.0227
     98  1400        0.014       0.0139     7.66e-05        0.171        0.604       0.0137
     98  1500       0.0198       0.0192      0.00058        0.201         4.25       0.0448
     98  1600       0.0293       0.0292     3.69e-05        0.248        0.799       0.0108
     98  1601      0.00254      0.00234     0.000203       0.0707        0.768       0.0274

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     98   100       0.0183       0.0182     9.47e-05        0.194          0.7       0.0153
     98   200       0.0266       0.0266     2.14e-05        0.236        0.395      0.00714
     98   203       0.0186       0.0185     1.21e-05        0.199        0.289      0.00602


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              98 11058.585    0.005       0.0237     0.000429       0.0241         0.22          1.8         0.03
! Validation         98 11058.585    0.005       0.0213     9.23e-05       0.0214         0.21        0.864       0.0139
Wall time: 11058.585123586003

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     99   100        0.018       0.0175     0.000405        0.195         2.53       0.0293
     99   200       0.0219       0.0215     0.000342        0.211         1.56       0.0352
     99   300       0.0302       0.0294       0.0008        0.252         3.67       0.0491
     99   400       0.0182        0.018     0.000145        0.192        0.882       0.0209
     99   500       0.0181       0.0178     0.000278        0.186         1.51       0.0299
     99   600       0.0316       0.0312      0.00032        0.244         2.58       0.0334
     99   700       0.0148       0.0146     0.000189        0.173        0.886       0.0233
     99   800       0.0169       0.0169        7e-05        0.191         1.09       0.0126
     99   900       0.0198       0.0194     0.000428        0.187         1.44       0.0321
     99  1000       0.0264       0.0263     8.87e-05        0.233        0.741       0.0129
     99  1100       0.0247       0.0243     0.000433        0.221         1.39       0.0292
     99  1200       0.0189       0.0187     0.000169        0.204         1.04       0.0227
     99  1300        0.014       0.0136     0.000387        0.152        0.983       0.0341
     99  1400       0.0296       0.0295     9.37e-05        0.252        0.746       0.0161
     99  1500       0.0263       0.0253      0.00102        0.205         2.54       0.0605
     99  1600       0.0284       0.0279     0.000463        0.225         2.31       0.0364
     99  1601        0.021       0.0209      7.1e-05        0.217        0.497       0.0148

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     99   100       0.0189       0.0178      0.00115        0.198         2.75       0.0648
     99   200       0.0253       0.0245     0.000786        0.228         3.68       0.0526
     99   203       0.0219       0.0215     0.000418        0.221         1.89       0.0394


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              99 11174.520    0.005       0.0237     0.000535       0.0242         0.22         1.95       0.0324
! Validation         99 11174.520    0.005       0.0221     0.000839       0.0229        0.213         3.16       0.0525
Wall time: 11174.520550763002

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
    100   100        0.025       0.0249     0.000102        0.235        0.859       0.0165
    100   200       0.0117       0.0115     0.000216        0.153         1.35       0.0267
    100   300       0.0137       0.0135     0.000201        0.153            1       0.0224
    100   400       0.0499       0.0498     9.33e-05        0.284        0.848       0.0134
    100   500        0.032       0.0316     0.000453        0.259         1.63       0.0325
    100   600       0.0161       0.0159     0.000275        0.173         1.25       0.0304
    100   700       0.0217       0.0216     0.000155        0.206         1.11       0.0202
    100   800        0.019       0.0188     0.000113        0.191         1.01       0.0201
    100   900       0.0358       0.0333      0.00246        0.268         5.47       0.0938
    100  1000       0.0274       0.0273     2.29e-05        0.232        0.315      0.00677
    100  1100       0.0157       0.0155     0.000118        0.178        0.699       0.0164
    100  1200       0.0463       0.0459     0.000376         0.29         3.26       0.0311
    100  1300       0.0416       0.0415      9.5e-05        0.273        0.674       0.0149
    100  1400       0.0271       0.0266     0.000473        0.229         1.44       0.0346
    100  1500         0.03         0.03     1.97e-05        0.256        0.349      0.00728
    100  1600       0.0244       0.0241     0.000266        0.231        0.894       0.0245
    100  1601       0.0279       0.0277     0.000207        0.256         2.13       0.0278

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
    100   100       0.0198       0.0197     8.25e-05        0.208         0.51       0.0136
    100   200       0.0297       0.0293     0.000413        0.243         3.22       0.0367
    100   203       0.0222       0.0219     0.000238        0.223         1.41       0.0294


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train             100 11289.800    0.005       0.0239     0.000393       0.0243        0.222         1.78       0.0292
! Validation        100 11289.800    0.005       0.0234     0.000437       0.0238        0.222         2.27       0.0366
Wall time: 11289.800615451997
! Stop training: max epochs
Wall time: 11289.848580366
Cumulative wall time: 11289.848580366
Testset is used.
Using all frames from the specified test dataset, yielding a test set size of 811 frames.
Starting...

--- Evaluation Time consumption: 6.023164s ---

--- Evaluation Final result: ---
               f_mae =  0.235376           
              f_rmse =  0.326531           
             N_f_mae =  0.211467           
            Si_f_mae =  0.262160           
         psavg_f_mae =  0.236814           
            N_f_rmse =  0.307054           
           Si_f_rmse =  0.347055           
        psavg_f_rmse =  0.327055           
               e_mae =  1.662815           
             e/N_mae =  0.027575           
Training QAT Model...
After QAT training...
loaded model from training session
               f_mae =  0.235376           
              f_rmse =  0.326531           
             N_f_mae =  0.211467           
            Si_f_mae =  0.262160           
         psavg_f_mae =  0.236814           
            N_f_rmse =  0.307054           
           Si_f_rmse =  0.347055           
        psavg_f_rmse =  0.327055           
               e_mae =  1.662815           
             e/N_mae =  0.027575           
