Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat_bs4_lr0.003', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs4_lr0.003', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 4, 'max_epochs': 100, 'learning_rate': 0.003, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_e/N_mae', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat_bs4_lr0.003', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs4_lr0.003', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 4, 'max_epochs': 100, 'learning_rate': 0.003, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_e/N_mae', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False, 'dataset_extra_fixed_fields': {'r_max': 6.0}, 'validation_dataset_extra_fixed_fields': {'r_max': 6.0}, 'dataset_config': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml', 'metrics_config': PosixPath('/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml'), 'base_model_file': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/best_model.pth', 'output_fields': []}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
RescaleOutput(
  (model): GradientOutput(
    (func): SequentialGraphNetwork(
      (one_hot): OneHotAtomEncoding()
      (radial_basis): RadialBasisEdgeEncoding(
        (basis): NormalizedBasis(
          (basis): BesselBasis()
        )
        (cutoff): PolynomialCutoff()
      )
      (spharm): SphericalHarmonicEdgeAttrs(
        (sh): SphericalHarmonics()
      )
      (allegro): Allegro_Module(
        (latents): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (env_embed_mlps): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (tps): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (linears): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (env_linears): ModuleList(
          (0): Identity()
          (1): Identity()
          (2): Identity()
        )
        (_env_weighter): MakeWeightedChannels()
        (final_latent): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng): ScalarMLP(
        (_module): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng_sum): EdgewiseEnergySum()
      (per_species_rescale): PerSpeciesScaleShift()
      (total_energy_sum): AtomwiseReduce()
    )
  )
)
Number of weights: 43096
! Starting training ...

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      0   100         1.76         1.06        0.698          1.4         60.1         1.51
      0   200         1.83         1.01        0.816         1.51          103         1.67
      0   203         1.97         1.38        0.589         1.74         71.1         1.48


  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Initial Validation          0   17.959    0.003         1.16        0.805         1.97         1.51         90.7         1.64
Wall time: 17.958946879021823
! Best model        0    1.644

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1   100        0.424        0.418      0.00631        0.864         5.81       0.0984
      1   200        0.324        0.311       0.0135         0.82         16.5        0.187
      1   300        0.165        0.154       0.0108        0.539         8.43        0.187
      1   400        0.146        0.144      0.00222        0.564         3.76       0.0812
      1   500        0.258        0.257      0.00092        0.681         3.38       0.0511
      1   600        0.106        0.105     0.000934        0.474          1.8       0.0482
      1   700         0.13        0.128      0.00153        0.517         4.42       0.0671
      1   800        0.211         0.21      0.00167        0.641         4.97       0.0661
      1   900       0.0535       0.0515      0.00196        0.347         2.04       0.0593
      1  1000        0.184        0.183      0.00196         0.58          6.6       0.0814
      1  1100        0.106        0.101      0.00479        0.438          6.5        0.132
      1  1200        0.117        0.109      0.00713        0.492         9.66        0.151
      1  1300         0.06       0.0564      0.00361         0.34         4.32        0.116
      1  1400       0.0484       0.0447      0.00362        0.304         6.36        0.116
      1  1500       0.0882       0.0856      0.00253        0.443         4.46       0.0929
      1  1600         0.07       0.0695     0.000511         0.38         2.44       0.0376
      1  1601        0.087       0.0866     0.000403        0.439         1.55       0.0323

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1   100       0.0578       0.0566      0.00122        0.341         2.15        0.053
      1   200        0.103        0.103      0.00064        0.452         3.64       0.0477
      1   203       0.0767       0.0764     0.000312        0.403         1.16       0.0242


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               1  159.020    0.003        0.183      0.00825        0.191        0.576         6.99        0.115
! Validation          1  159.020    0.003        0.077      0.00133       0.0784        0.407         3.18       0.0536
Wall time: 159.020519672893
! Best model        1    0.054

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2   100       0.0556       0.0523      0.00329        0.331         3.13        0.083
      2   200       0.0551       0.0549      0.00019        0.338         1.16       0.0256
      2   300        0.111         0.11     0.000559        0.474         2.18       0.0362
      2   400       0.0721       0.0703      0.00183        0.381          2.7       0.0701
      2   500        0.075        0.068        0.007         0.37         7.33        0.155
      2   600       0.0711       0.0703     0.000815        0.384         2.26       0.0471
      2   700       0.0588       0.0579     0.000837        0.348         2.03       0.0501
      2   800       0.0741       0.0738     0.000372        0.405         1.87       0.0295
      2   900       0.0563       0.0555     0.000766        0.347         1.78       0.0371
      2  1000       0.0665       0.0658     0.000735        0.371         2.55       0.0501
      2  1100       0.0813       0.0803      0.00103        0.398         3.55       0.0485
      2  1200       0.0793       0.0789     0.000374        0.406         1.42       0.0321
      2  1300       0.0748       0.0738     0.000985        0.383         3.58        0.056
      2  1400       0.0526       0.0521     0.000483        0.352         1.84       0.0383
      2  1500       0.0555       0.0543      0.00126        0.352         3.06       0.0638
      2  1600        0.069       0.0687     0.000273         0.39         1.57       0.0272
      2  1601       0.0549       0.0527      0.00222        0.346         5.83       0.0884

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2   100       0.0416       0.0404      0.00119        0.292         2.68       0.0578
      2   200       0.0748       0.0743     0.000511        0.383         3.97       0.0319
      2   203       0.0581       0.0578     0.000337        0.353         1.49       0.0311


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               2  278.417    0.003       0.0682      0.00247       0.0706        0.376         4.24       0.0693
! Validation          2  278.417    0.003       0.0542      0.00105       0.0553        0.343         3.29       0.0442
Wall time: 278.41772158187814
! Best model        2    0.044

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3   100       0.0404         0.04     0.000386        0.303         2.18       0.0369
      3   200        0.069       0.0655      0.00353        0.383         8.82        0.106
      3   300       0.0559       0.0553     0.000584        0.344         1.71       0.0389
      3   400         0.09        0.085      0.00507        0.424         5.01        0.117
      3   500       0.0405       0.0346      0.00597        0.277         28.3         0.13
      3   600       0.0347       0.0347     3.21e-05        0.228        0.295      0.00985
      3   700       0.0361       0.0361      5.2e-05        0.263        0.569       0.0102
      3   800       0.0672        0.064      0.00319        0.348         3.83       0.0979
      3   900       0.0593       0.0583      0.00097        0.353         2.74       0.0571
      3  1000       0.0289       0.0281     0.000734        0.233         1.77       0.0487
      3  1100       0.0731       0.0717      0.00139        0.383         3.73       0.0527
      3  1200       0.0546       0.0542     0.000366        0.331         1.39       0.0314
      3  1300       0.0522       0.0512     0.000954        0.343         2.42       0.0504
      3  1400        0.054       0.0539     0.000109         0.32         2.57       0.0186
      3  1500       0.0407       0.0395      0.00112        0.298         1.85       0.0509
      3  1600       0.0607       0.0598     0.000911        0.341         2.17       0.0476
      3  1601       0.0474       0.0471     0.000346        0.327         1.63       0.0339

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3   100       0.0546       0.0531      0.00143        0.325         2.95       0.0651
      3   200       0.0671       0.0669     0.000166        0.366         1.68       0.0227
      3   203       0.0764        0.076      0.00044        0.404         1.92         0.04


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               3  392.553    0.003        0.056      0.00163       0.0576        0.341         3.52        0.057
! Validation          3  392.553    0.003       0.0678      0.00114       0.0689        0.378          2.9       0.0476
Wall time: 392.55310552194715

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4   100       0.0396        0.037      0.00251        0.281          7.9       0.0792
      4   200       0.0519       0.0517       0.0002        0.344         1.76        0.025
      4   300         0.04       0.0388      0.00119        0.293         4.42       0.0623
      4   400        0.104        0.103     0.000958        0.392         4.25       0.0581
      4   500       0.0612       0.0599      0.00132        0.343         6.29       0.0519
      4   600         0.04       0.0398     0.000241        0.286         1.76       0.0281
      4   700       0.0534       0.0525     0.000852        0.312         1.33       0.0407
      4   800       0.0185       0.0171      0.00145        0.172          2.5        0.072
      4   900       0.0283       0.0282     5.85e-05        0.245         0.79        0.013
      4  1000       0.0228       0.0223     0.000503        0.214         1.69       0.0404
      4  1100       0.0539       0.0532     0.000688         0.34         2.32       0.0484
      4  1200       0.0542       0.0536     0.000539        0.342         1.37       0.0286
      4  1300       0.0502       0.0496     0.000642         0.33         3.57       0.0484
      4  1400       0.0336        0.032      0.00153        0.252         4.04       0.0623
      4  1500       0.0358       0.0331      0.00271        0.257         3.72          0.1
      4  1600       0.0462       0.0461     6.92e-05        0.301        0.751       0.0135
      4  1601       0.0492       0.0488     0.000445         0.33         1.88       0.0391

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4   100       0.0387       0.0385     0.000268        0.291         1.13       0.0281
      4   200       0.0554       0.0551     0.000304        0.333         1.64       0.0282
      4   203       0.0521       0.0519     0.000178        0.334         1.22       0.0254


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               4  505.212    0.003       0.0494      0.00145       0.0508        0.321         3.34       0.0544
! Validation          4  505.212    0.003       0.0453     0.000802       0.0461        0.313          2.5       0.0427
Wall time: 505.2123024109751
! Best model        4    0.043

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5   100       0.0748       0.0744     0.000356        0.385         2.18       0.0276
      5   200       0.0478       0.0469     0.000923        0.317         2.79       0.0516
      5   300       0.0611       0.0604     0.000663        0.365         4.98       0.0472
      5   400       0.0609       0.0603     0.000584        0.358         1.98       0.0432
      5   500       0.0337       0.0315      0.00227        0.244         3.93       0.0919
      5   600        0.042       0.0414     0.000554        0.302         1.82       0.0379
      5   700       0.0203       0.0194      0.00084        0.185         1.52       0.0461
      5   800       0.0217       0.0214     0.000284        0.213        0.851       0.0245
      5   900        0.054       0.0539     0.000124        0.341        0.667       0.0165
      5  1000       0.0557       0.0553     0.000451        0.341         3.48       0.0395
      5  1100       0.0548       0.0546     0.000182        0.322         3.22       0.0221
      5  1200       0.0346       0.0344     0.000259         0.27         1.78       0.0285
      5  1300         0.03       0.0281      0.00197        0.237         3.46       0.0829
      5  1400       0.0331       0.0327     0.000439        0.268         1.08        0.034
      5  1500       0.0532       0.0529      0.00038        0.324         1.79        0.034
      5  1600       0.0486       0.0481     0.000437        0.331         1.66       0.0346
      5  1601       0.0334        0.033     0.000394        0.272         1.72       0.0358

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5   100       0.0382       0.0323      0.00587        0.263         6.45        0.145
      5   200       0.0471       0.0437      0.00342        0.302         8.93        0.112
      5   203       0.0549       0.0514      0.00349        0.328         5.48        0.114


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               5  619.798    0.003       0.0463      0.00112       0.0474        0.311         2.93       0.0482
! Validation          5  619.798    0.003       0.0411      0.00451       0.0456        0.296         7.74        0.125
Wall time: 619.7984087478835

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6   100       0.0626       0.0625     0.000148        0.352         1.44       0.0212
      6   200       0.0647       0.0641     0.000532        0.367         6.02       0.0354
      6   300       0.0307       0.0277      0.00298        0.227         3.18       0.0937
      6   400       0.0365       0.0354      0.00104        0.267         3.16       0.0551
      6   500       0.0454       0.0453     9.04e-05        0.287         1.39       0.0172
      6   600       0.0348       0.0342     0.000546        0.253         1.69       0.0389
      6   700       0.0391       0.0383     0.000799        0.273         4.35       0.0319
      6   800       0.0619       0.0609      0.00105         0.33         3.67       0.0528
      6   900       0.0472       0.0471      9.3e-05        0.299         1.28       0.0185
      6  1000       0.0526       0.0525     8.53e-05         0.32        0.983       0.0161
      6  1100       0.0359       0.0348      0.00102        0.265         1.73       0.0445
      6  1200       0.0301       0.0297     0.000437         0.25         1.62       0.0381
      6  1300       0.0478       0.0469     0.000894        0.307         2.76       0.0554
      6  1400        0.035       0.0348     0.000165        0.278         1.26       0.0209
      6  1500       0.0518       0.0517     0.000165        0.324         1.95       0.0237
      6  1600       0.0687       0.0684     0.000242        0.327         2.49       0.0279
      6  1601       0.0838       0.0832     0.000572        0.403         3.72       0.0355

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6   100       0.0286       0.0269      0.00165        0.237         3.41       0.0749
      6   200        0.042       0.0414     0.000656        0.292         3.96       0.0482
      6   203       0.0447       0.0438      0.00084        0.306         2.68       0.0559


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               6  735.286    0.003       0.0415      0.00092       0.0424        0.294         2.66        0.044
! Validation          6  735.286    0.003       0.0381      0.00143       0.0395        0.282         4.03       0.0646
Wall time: 735.2859522418585

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7   100       0.0554       0.0539      0.00146        0.341         4.03       0.0697
      7   200       0.0429       0.0396       0.0033        0.296         3.04       0.0843
      7   300       0.0274       0.0271     0.000305        0.224         1.07       0.0307
      7   400       0.0555        0.055      0.00044        0.344         1.47       0.0333
      7   500       0.0329       0.0324     0.000531        0.261         2.68         0.04
      7   600        0.025       0.0239      0.00107        0.233         3.63       0.0623
      7   700       0.0457       0.0454     0.000346        0.309         6.75       0.0274
      7   800       0.0338       0.0331     0.000686        0.279         3.68       0.0501
      7   900       0.0187       0.0174      0.00133        0.188         2.15       0.0627
      7  1000       0.0527       0.0518     0.000821        0.319         2.78       0.0478
      7  1100         0.05       0.0493     0.000674        0.279         1.68       0.0448
      7  1200       0.0611       0.0588      0.00228        0.336         6.78       0.0807
      7  1300       0.0451       0.0446      0.00047        0.281         1.75       0.0349
      7  1400       0.0394       0.0345      0.00489        0.258         7.94        0.135
      7  1500       0.0317       0.0316     8.78e-05        0.246        0.428       0.0126
      7  1600       0.0355       0.0351      0.00042        0.273         1.63       0.0346
      7  1601       0.0399       0.0399     7.02e-05        0.278        0.631        0.015

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7   100       0.0312       0.0295      0.00167        0.252         2.54       0.0669
      7   200       0.0447       0.0424      0.00223        0.298         5.98       0.0905
      7   203       0.0479       0.0461      0.00181        0.316         3.95       0.0823


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               7  851.950    0.003       0.0399       0.0009       0.0408        0.286         2.66       0.0435
! Validation          7  851.950    0.003       0.0388       0.0025       0.0413        0.287         5.19       0.0912
Wall time: 851.9507346290629

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8   100       0.0443       0.0431       0.0012        0.305         4.71       0.0646
      8   200       0.0482       0.0474     0.000868         0.33         2.52       0.0525
      8   300       0.0386       0.0384     0.000244        0.278         1.16       0.0248
      8   400       0.0509       0.0508     0.000104        0.318         1.31       0.0185
      8   500       0.0238       0.0233     0.000509        0.226         1.42       0.0391
      8   600        0.037       0.0353      0.00167        0.265         3.83       0.0758
      8   700       0.0386       0.0381     0.000567        0.294         2.21        0.046
      8   800       0.0669       0.0663     0.000556        0.371         2.32        0.034
      8   900       0.0288       0.0259      0.00297        0.234         5.03       0.0936
      8  1000        0.027       0.0267     0.000302        0.236         1.18       0.0283
      8  1100       0.0361       0.0356     0.000483         0.27         1.11        0.029
      8  1200       0.0432       0.0428     0.000421        0.306         2.18       0.0346
      8  1300       0.0449       0.0447     0.000205        0.293            2       0.0204
      8  1400       0.0468       0.0463      0.00047        0.312         1.74       0.0347
      8  1500       0.0639       0.0636     0.000264        0.352         2.19       0.0309
      8  1600       0.0284       0.0282     0.000217        0.249         1.24       0.0274
      8  1601       0.0248       0.0242     0.000597        0.225          2.2       0.0458

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8   100       0.0305       0.0302     0.000319        0.253         1.05       0.0271
      8   200       0.0476        0.047     0.000657        0.317         3.52       0.0477
      8   203       0.0512       0.0507     0.000511        0.333         2.04       0.0426


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               8  969.546    0.003        0.039        0.001         0.04        0.285         2.78       0.0461
! Validation          8  969.546    0.003       0.0402     0.000647       0.0409        0.295         2.74        0.044
Wall time: 969.5460751820356

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9   100         0.04       0.0397     0.000328        0.301         2.13       0.0315
      9   200       0.0301       0.0299      0.00022         0.25         1.27       0.0246
      9   300       0.0415         0.04       0.0015        0.297         3.77       0.0633
      9   400       0.0325       0.0306      0.00185        0.245         4.18       0.0829
      9   500       0.0311         0.03      0.00113         0.25         2.48       0.0607
      9   600       0.0368       0.0368     6.91e-05        0.278         1.49       0.0144
      9   700       0.0581       0.0554      0.00264        0.342          6.2       0.0991
      9   800      0.00861      0.00859     2.67e-05        0.127        0.429      0.00861
      9   900       0.0347       0.0346     0.000172        0.261         1.45       0.0202
      9  1000       0.0262       0.0252      0.00102        0.229         2.73       0.0489
      9  1100       0.0389       0.0387     0.000188        0.276          1.9       0.0217
      9  1200       0.0486       0.0484     0.000225        0.287         2.13       0.0271
      9  1300         0.03       0.0292     0.000793        0.251         1.96       0.0494
      9  1400       0.0572       0.0571     8.68e-05        0.335        0.963       0.0134
      9  1500        0.034       0.0337     0.000224         0.27         1.12       0.0233
      9  1600       0.0406       0.0399     0.000726        0.277         3.85       0.0472
      9  1601       0.0351        0.035     4.82e-05        0.274        0.642       0.0134

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9   100       0.0289       0.0284     0.000487        0.244         1.67       0.0405
      9   200       0.0408       0.0402       0.0006        0.291         2.88       0.0442
      9   203       0.0375       0.0364      0.00107         0.28         3.02       0.0629


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               9 1082.629    0.003       0.0381     0.000788       0.0389        0.278         2.46        0.041
! Validation          9 1082.629    0.003       0.0353     0.000847       0.0362        0.274         3.08       0.0513
Wall time: 1082.6292749119457

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10   100       0.0287       0.0287     1.39e-05        0.242        0.214      0.00462
     10   200       0.0262       0.0257     0.000509        0.214         4.48       0.0367
     10   300       0.0247       0.0245     0.000156        0.225        0.625       0.0173
     10   400       0.0415       0.0407     0.000772        0.296         5.16       0.0475
     10   500        0.025       0.0248     0.000212        0.232        0.916       0.0253
     10   600       0.0279       0.0275     0.000481        0.248         1.75       0.0395
     10   700       0.0522         0.05      0.00223        0.318         2.74       0.0812
     10   800       0.0191       0.0171      0.00194         0.19         8.42        0.084
     10   900       0.0464       0.0462     0.000139        0.281         1.66       0.0205
     10  1000       0.0468       0.0462     0.000599        0.308         3.09        0.044
     10  1100       0.0208       0.0208     7.88e-05        0.218         1.01       0.0133
     10  1200       0.0484       0.0477     0.000657        0.299         4.06       0.0408
     10  1300        0.108        0.108     0.000209        0.404         1.17       0.0255
     10  1400       0.0505       0.0505     7.31e-05        0.327        0.999       0.0132
     10  1500       0.0589       0.0577       0.0012        0.343         3.84       0.0659
     10  1600       0.0333       0.0332     8.66e-05        0.253        0.593       0.0144
     10  1601       0.0353       0.0352     0.000172        0.276         1.91       0.0249

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10   100       0.0288       0.0287     8.43e-05        0.251        0.702       0.0148
     10   200       0.0401         0.04     9.17e-05        0.294         1.16       0.0153
     10   203       0.0437       0.0436        3e-05        0.308        0.401      0.00836


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              10 1194.707    0.003       0.0406      0.00125       0.0418        0.279          2.6       0.0427
! Validation         10 1194.707    0.003       0.0389     0.000219       0.0391        0.289         1.31       0.0198
Wall time: 1194.7073684239294
! Best model       10    0.020

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11   100       0.0361       0.0356     0.000523        0.287         1.75       0.0364
     11   200       0.0344       0.0344      6.3e-06        0.268        0.288      0.00438
     11   300       0.0328       0.0304      0.00236        0.248         4.13       0.0918
     11   400       0.0295        0.029     0.000498        0.253         1.67       0.0391
     11   500       0.0187       0.0178     0.000841        0.179          1.7       0.0507
     11   600       0.0426       0.0424     0.000192        0.301         1.37       0.0259
     11   700        0.032       0.0315     0.000482        0.264         2.35        0.041
     11   800       0.0404       0.0386      0.00176        0.286          3.4       0.0726
     11   900        0.025       0.0244     0.000505        0.226         2.68       0.0413
     11  1000       0.0406       0.0403     0.000305        0.296         1.62       0.0279
     11  1100       0.0358       0.0343       0.0015        0.265         4.43       0.0742
     11  1200       0.0255       0.0253     0.000182        0.227         1.13       0.0255
     11  1300       0.0374       0.0373     6.97e-05         0.28         1.35       0.0111
     11  1400       0.0354       0.0348     0.000602        0.254          2.9        0.044
     11  1500       0.0288       0.0286     0.000187        0.255         2.27        0.025
     11  1600       0.0328         0.03      0.00279        0.252         6.62       0.0984
     11  1601       0.0162       0.0153     0.000865        0.192         2.72       0.0567

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11   100       0.0227       0.0226     0.000158        0.224        0.797       0.0204
     11   200       0.0329       0.0327     0.000158        0.264         1.27       0.0227
     11   203        0.034       0.0338     0.000192        0.271        0.939       0.0196


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              11 1307.726    0.003       0.0354      0.00072       0.0361        0.272         2.44       0.0403
! Validation         11 1307.726    0.003       0.0301      0.00023       0.0303        0.252         1.36       0.0233
Wall time: 1307.7266664959025

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12   100       0.0314       0.0313     0.000116        0.256        0.717       0.0155
     12   200       0.0861       0.0807      0.00543        0.379          7.8        0.141
     12   300       0.0205       0.0199     0.000652        0.197         1.81       0.0477
     12   400       0.0413       0.0379       0.0033        0.285         6.56         0.11
     12   500       0.0474       0.0455      0.00189        0.315         5.59       0.0796
     12   600       0.0147       0.0126       0.0021        0.158         3.86       0.0884
     12   700       0.0647       0.0646     0.000149        0.358        0.988       0.0198
     12   800       0.0299       0.0299     6.22e-05        0.252        0.427      0.00944
     12   900       0.0491       0.0474      0.00165        0.315         5.41       0.0774
     12  1000       0.0281       0.0277     0.000337        0.238         3.24       0.0341
     12  1100       0.0402       0.0391      0.00107         0.28         4.31        0.042
     12  1200       0.0464       0.0464      8.9e-06         0.31        0.383      0.00429
     12  1300       0.0476       0.0474     0.000151        0.299         1.18       0.0212
     12  1400       0.0268       0.0205      0.00633        0.203         5.82        0.152
     12  1500       0.0285       0.0277     0.000824        0.247         2.66       0.0554
     12  1600       0.0613       0.0609     0.000352        0.354          3.2       0.0333
     12  1601       0.0218       0.0216     0.000185        0.213        0.912       0.0193

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12   100       0.0253       0.0245     0.000774        0.234         2.06       0.0507
     12   200        0.037       0.0357       0.0013        0.276         5.11       0.0692
     12   203       0.0366       0.0357     0.000916        0.277         2.68       0.0559


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              12 1422.361    0.003       0.0343     0.000885       0.0352        0.267         2.59       0.0431
! Validation         12 1422.361    0.003       0.0316      0.00124       0.0328         0.26         3.83       0.0648
Wall time: 1422.361706102034

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13   100       0.0445       0.0441     0.000446        0.306         2.55       0.0367
     13   200       0.0256       0.0253     0.000297        0.233         1.14       0.0243
     13   300       0.0399       0.0369      0.00295        0.277         8.21        0.104
     13   400       0.0404       0.0403     0.000134        0.284         1.02        0.018
     13   500       0.0258       0.0238      0.00192        0.226         4.39       0.0841
     13   600       0.0328       0.0323     0.000483        0.252          1.3       0.0272
     13   700        0.035       0.0345     0.000566         0.28         2.09       0.0435
     13   800       0.0311       0.0304     0.000602        0.255         2.91       0.0447
     13   900       0.0302       0.0296     0.000621        0.237         1.31       0.0407
     13  1000        0.051       0.0488      0.00219        0.307         10.6       0.0887
     13  1100       0.0776        0.077     0.000597        0.386          5.7       0.0471
     13  1200       0.0356       0.0352     0.000382        0.268         1.61       0.0333
     13  1300       0.0175       0.0173     0.000259        0.177        0.927       0.0276
     13  1400       0.0452       0.0439      0.00123        0.288         3.07       0.0663
     13  1500       0.0404       0.0402      0.00015        0.288          1.8       0.0212
     13  1600       0.0227        0.022     0.000725        0.212         2.82       0.0414
     13  1601        0.069       0.0689     7.76e-05        0.389        0.969       0.0154

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13   100       0.0251       0.0242     0.000989        0.229         2.51       0.0542
     13   200       0.0365       0.0361     0.000404         0.28         3.45       0.0349
     13   203       0.0351       0.0349     0.000209        0.274         1.22       0.0254


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              13 1535.330    0.003       0.0342     0.000787        0.035        0.266         2.46        0.041
! Validation         13 1535.330    0.003       0.0316     0.000489       0.0321         0.26          2.3       0.0332
Wall time: 1535.330673663877

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14   100       0.0272       0.0265     0.000709        0.229         2.02       0.0498
     14   200       0.0333       0.0325     0.000707        0.245         3.27        0.049
     14   300       0.0316       0.0316     4.22e-05        0.261        0.625        0.011
     14   400       0.0162       0.0156     0.000636        0.175         1.57       0.0455
     14   500        0.038       0.0358      0.00218        0.251         2.84       0.0658
     14   600       0.0306       0.0304     0.000154        0.259         1.49       0.0191
     14   700       0.0158       0.0137      0.00208        0.173         3.76       0.0822
     14   800       0.0321       0.0319     0.000208         0.25         1.92       0.0252
     14   900       0.0423       0.0418      0.00044        0.299         2.51       0.0306
     14  1000       0.0222       0.0219     0.000247        0.223         1.24       0.0258
     14  1100       0.0471       0.0467      0.00043        0.305         1.53       0.0298
     14  1200       0.0475       0.0468     0.000748        0.302         2.97       0.0528
     14  1300         0.04         0.04     4.58e-05        0.285        0.459      0.00983
     14  1400       0.0154       0.0154     2.43e-05        0.162        0.324      0.00913
     14  1500       0.0438       0.0436      0.00019        0.294         2.09       0.0254
     14  1600        0.028       0.0278     0.000256         0.25         1.79       0.0248
     14  1601       0.0226       0.0225     0.000145        0.225         2.09       0.0218

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14   100       0.0215       0.0214      6.1e-05        0.216        0.481       0.0104
     14   200       0.0313       0.0313     1.43e-05        0.256        0.374       0.0061
     14   203       0.0311       0.0311     6.75e-05        0.265        0.762       0.0159


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              14 1647.116    0.003       0.0327     0.000564       0.0333        0.261         2.11       0.0345
! Validation         14 1647.116    0.003       0.0288     0.000156        0.029        0.246         1.03       0.0174
Wall time: 1647.1166818160564
! Best model       14    0.017

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15   100        0.032       0.0317     0.000244        0.268         1.25       0.0261
     15   200       0.0261       0.0258     0.000223        0.202          1.3       0.0264
     15   300       0.0315       0.0307     0.000795        0.241         2.05       0.0494
     15   400       0.0298       0.0298      4.8e-05        0.258        0.851      0.00948
     15   500       0.0119       0.0116     0.000335        0.148        0.892       0.0308
     15   600       0.0603       0.0588      0.00146        0.322         4.94       0.0692
     15   700       0.0482       0.0481     0.000105         0.32         1.36       0.0147
     15   800       0.0274        0.027     0.000404        0.246         2.39       0.0384
     15   900       0.0457       0.0454     0.000278        0.309         2.02       0.0242
     15  1000       0.0361       0.0359     0.000243        0.252         2.03       0.0273
     15  1100       0.0341       0.0321      0.00205        0.268         2.96       0.0709
     15  1200       0.0232       0.0231     0.000108        0.216        0.597       0.0155
     15  1300       0.0325       0.0284      0.00409        0.248          9.1        0.118
     15  1400       0.0307       0.0306     5.26e-05        0.253        0.841       0.0101
     15  1500       0.0219       0.0213     0.000615        0.221         2.36       0.0445
     15  1600       0.0375       0.0373     0.000254         0.27         1.78       0.0271
     15  1601       0.0121        0.012     9.98e-05        0.156          0.6       0.0178

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15   100       0.0215       0.0213     0.000205        0.218         1.06       0.0254
     15   200       0.0304       0.0303     4.52e-05        0.252        0.854       0.0111
     15   203       0.0315       0.0314     4.88e-05        0.261        0.531       0.0111


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              15 1762.370    0.003       0.0313     0.000642        0.032        0.255         2.25       0.0372
! Validation         15 1762.370    0.003       0.0272     0.000149       0.0274         0.24         1.11       0.0175
Wall time: 1762.3702126489952

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16   100       0.0376       0.0373     0.000267        0.263         2.28       0.0272
     16   200        0.031       0.0307     0.000294        0.247         2.33       0.0257
     16   300       0.0191       0.0187     0.000352        0.197         4.19       0.0353
     16   400       0.0388       0.0343      0.00454        0.264          7.9        0.129
     16   500       0.0457       0.0421      0.00369        0.291         6.52        0.116
     16   600       0.0212       0.0209     0.000283        0.213         1.31       0.0279
     16   700       0.0247       0.0244     0.000329         0.23         1.27       0.0269
     16   800       0.0296       0.0293     0.000324        0.258         2.87       0.0256
     16   900       0.0288       0.0287      0.00012        0.254        0.879       0.0183
     16  1000       0.0365       0.0293       0.0072        0.249         6.71        0.161
     16  1100       0.0439       0.0437     0.000172         0.31            2       0.0224
     16  1200       0.0332       0.0328     0.000373        0.257         2.81       0.0359
     16  1300       0.0282       0.0272      0.00104        0.225         1.57       0.0505
     16  1400       0.0339       0.0339     3.02e-05        0.256        0.664       0.0104
     16  1500       0.0343       0.0331      0.00122        0.267         4.66       0.0666
     16  1600       0.0239       0.0235     0.000323        0.227         1.77       0.0334
     16  1601      0.00394      0.00387     6.41e-05       0.0916        0.433       0.0155

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16   100        0.025       0.0229       0.0021        0.226         3.81       0.0869
     16   200       0.0344       0.0331      0.00136        0.262         5.36       0.0698
     16   203       0.0345       0.0333      0.00121        0.266         3.11       0.0649


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              16 1874.693    0.003       0.0331     0.000991       0.0341        0.262          2.6       0.0433
! Validation         16 1874.693    0.003       0.0291      0.00166       0.0307        0.248         4.65       0.0747
Wall time: 1874.692992608063

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17   100       0.0264       0.0263     2.17e-05        0.227        0.289      0.00779
     17   200         0.04       0.0398     0.000203         0.29         1.08       0.0256
     17   300       0.0322       0.0319     0.000279        0.234        0.953       0.0279
     17   400       0.0215       0.0214     0.000102        0.203        0.726       0.0174
     17   500       0.0239       0.0238     7.63e-05         0.21         1.03       0.0155
     17   600       0.0293       0.0285     0.000818        0.244          1.8       0.0474
     17   700       0.0196       0.0186        0.001        0.196         2.22       0.0505
     17   800       0.0236        0.023     0.000536         0.22          1.8       0.0432
     17   900        0.027       0.0266     0.000493        0.241         2.61       0.0368
     17  1000       0.0417       0.0406      0.00113        0.301         7.56       0.0641
     17  1100       0.0261       0.0258     0.000255        0.231         1.17       0.0275
     17  1200       0.0324       0.0318     0.000541        0.271         2.05       0.0428
     17  1300       0.0557       0.0508      0.00486        0.339         7.22        0.119
     17  1400       0.0287       0.0286     0.000117        0.238        0.793       0.0205
     17  1500       0.0235       0.0234     8.21e-05         0.21        0.517       0.0131
     17  1600       0.0163       0.0162      8.9e-05        0.186         1.15       0.0147
     17  1601       0.0242        0.024     0.000189        0.215        0.925       0.0196

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17   100       0.0328       0.0285      0.00432        0.246         5.42        0.127
     17   200        0.043       0.0396      0.00333        0.286         7.53        0.111
     17   203       0.0381       0.0346      0.00347        0.279         5.39        0.112


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              17 1990.334    0.003        0.035      0.00122       0.0362        0.266         2.45       0.0409
! Validation         17 1990.334    0.003       0.0351      0.00401       0.0391        0.275         7.08        0.119
Wall time: 1990.3341070690658

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18   100       0.0391       0.0388     0.000272        0.291         1.44       0.0301
     18   200       0.0203       0.0199     0.000373        0.197         1.11       0.0318
     18   300       0.0283       0.0281     0.000222        0.252          1.7       0.0271
     18   400        0.033       0.0329     0.000101         0.27        0.827       0.0172
     18   500       0.0207       0.0201     0.000617        0.186         1.87       0.0474
     18   600       0.0315       0.0292      0.00231         0.24         4.81       0.0921
     18   700       0.0236       0.0232     0.000317        0.232         1.48       0.0293
     18   800       0.0317       0.0316     0.000131        0.245         1.08       0.0189
     18   900       0.0395        0.039      0.00052         0.28         2.17       0.0372
     18  1000       0.0221       0.0221     3.66e-05        0.219            1       0.0113
     18  1100       0.0412       0.0405      0.00076        0.301         8.13       0.0515
     18  1200       0.0348       0.0346     0.000282        0.277         2.05       0.0298
     18  1300       0.0243       0.0241     0.000221        0.233        0.964       0.0247
     18  1400       0.0255       0.0249      0.00061        0.232         4.35       0.0462
     18  1500       0.0379       0.0365       0.0014        0.273         4.59       0.0721
     18  1600       0.0173       0.0171     0.000208        0.185        0.894       0.0261
     18  1601       0.0156       0.0153     0.000292        0.168         1.19       0.0326

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18   100       0.0244       0.0242     0.000209        0.225         1.17       0.0261
     18   200       0.0357       0.0357     5.64e-05        0.277          1.1        0.012
     18   203       0.0322       0.0321     2.79e-06        0.268        0.153      0.00319


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              18 2104.357    0.003       0.0315      0.00074       0.0323        0.255         2.14       0.0352
! Validation         18 2104.357    0.003       0.0305     0.000372       0.0309        0.256          1.6       0.0266
Wall time: 2104.357254212955

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19   100       0.0968       0.0961     0.000719          0.3         1.98       0.0448
     19   200       0.0487       0.0487     6.96e-06        0.291         0.29      0.00412
     19   300       0.0316       0.0315     0.000114        0.268         1.48       0.0193
     19   400       0.0275       0.0274      3.6e-05         0.24        0.694      0.00886
     19   500        0.024       0.0239     0.000186        0.234        0.995       0.0215
     19   600       0.0319       0.0318     4.39e-05        0.265        0.527        0.011
     19   700       0.0345       0.0341     0.000339        0.275         2.13       0.0352
     19   800       0.0239       0.0236      0.00025        0.223        0.887       0.0234
     19   900       0.0183       0.0182     0.000124        0.202        0.939       0.0173
     19  1000       0.0344       0.0341     0.000293        0.276         1.44       0.0301
     19  1100       0.0216       0.0206      0.00101         0.21         3.37       0.0601
     19  1200       0.0406       0.0403     0.000317        0.299         2.11       0.0278
     19  1300       0.0242       0.0239      0.00026        0.222         1.63       0.0278
     19  1400       0.0299       0.0296     0.000334        0.252         1.59       0.0331
     19  1500        0.032        0.032     6.03e-05        0.265        0.887       0.0123
     19  1600       0.0225       0.0225     1.94e-05        0.225        0.505      0.00761
     19  1601       0.0301       0.0296     0.000483        0.256         2.37        0.038

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19   100       0.0205       0.0202     0.000332        0.205         1.43       0.0307
     19   200       0.0306       0.0306     2.57e-05        0.251        0.511      0.00922
     19   203       0.0275       0.0274     8.01e-05        0.251        0.599       0.0125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              19 2219.619    0.003       0.0299     0.000498       0.0304        0.249         1.98       0.0327
! Validation         19 2219.619    0.003       0.0264     0.000206       0.0266        0.235         1.35        0.021
Wall time: 2219.6197783800308

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20   100       0.0432       0.0422      0.00108         0.27         4.75       0.0575
     20   200       0.0246       0.0245      0.00013        0.238         1.33        0.019
     20   300       0.0268       0.0266     0.000168         0.23        0.779       0.0204
     20   400       0.0272       0.0262      0.00102        0.226         2.59        0.057
     20   500       0.0241       0.0236     0.000496        0.225         1.33       0.0353
     20   600        0.015       0.0144     0.000572        0.175         2.81       0.0449
     20   700       0.0285       0.0281     0.000334        0.238         2.46       0.0261
     20   800       0.0246        0.024     0.000631        0.227         1.72       0.0476
     20   900       0.0302       0.0301     7.62e-05        0.247        0.536       0.0142
     20  1000       0.0381       0.0378     0.000282        0.259         1.18       0.0275
     20  1100       0.0303       0.0299     0.000417        0.246         1.45       0.0329
     20  1200       0.0418       0.0411     0.000697        0.288         5.61       0.0452
     20  1300        0.019       0.0186     0.000417        0.193         1.59       0.0346
     20  1400        0.033       0.0328     0.000269        0.239          1.2       0.0309
     20  1500       0.0334       0.0331     0.000269        0.261         2.02       0.0299
     20  1600       0.0221       0.0217     0.000391        0.216         1.73        0.036
     20  1601       0.0414       0.0414      5.4e-05        0.282         2.75       0.0134

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20   100         0.02       0.0193     0.000743        0.206         2.28       0.0502
     20   200       0.0321       0.0318     0.000284        0.259         1.71       0.0303
     20   203       0.0281       0.0276     0.000425        0.249         1.91       0.0397


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              20 2334.481    0.003         0.03     0.000526       0.0305        0.248         2.07       0.0341
! Validation         20 2334.481    0.003       0.0262     0.000409       0.0266        0.235          2.1       0.0341
Wall time: 2334.4811519079376

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21   100       0.0297       0.0292     0.000525        0.258         2.05       0.0427
     21   200       0.0416       0.0416     3.66e-05        0.292         0.91      0.00942
     21   300       0.0174       0.0165     0.000943        0.179         1.96       0.0562
     21   400       0.0221        0.022     0.000154         0.22         1.67       0.0219
     21   500       0.0254       0.0253      0.00015        0.224        0.966       0.0226
     21   600       0.0352       0.0351     6.57e-05        0.255        0.772       0.0143
     21   700       0.0245       0.0241     0.000434        0.229         2.89       0.0378
     21   800       0.0328       0.0327      0.00016        0.268         1.86       0.0184
     21   900       0.0173       0.0172     0.000113        0.185         1.11       0.0137
     21  1000       0.0182       0.0178     0.000401        0.191         2.02       0.0336
     21  1100       0.0194       0.0187     0.000689        0.185         1.68       0.0478
     21  1200       0.0214       0.0204     0.000925         0.21         3.56       0.0574
     21  1300       0.0253       0.0204      0.00486        0.217         8.63        0.129
     21  1400       0.0255       0.0249     0.000596        0.232          2.5       0.0452
     21  1500       0.0364       0.0363     9.03e-05         0.28        0.733       0.0153
     21  1600       0.0669       0.0648       0.0021        0.355         5.38       0.0885
     21  1601       0.0133       0.0131     0.000229        0.131        0.663       0.0237

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21   100       0.0195       0.0192     0.000329        0.206         1.46       0.0315
     21   200       0.0302       0.0301     0.000105         0.25         1.31       0.0171
     21   203       0.0279       0.0278     8.84e-05         0.25        0.827       0.0172


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              21 2456.262    0.003         0.03     0.000611       0.0306        0.249         2.17       0.0363
! Validation         21 2456.262    0.003       0.0256     0.000225       0.0258        0.232         1.46       0.0222
Wall time: 2456.262801080942

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22   100       0.0243       0.0233     0.000983        0.224         3.25       0.0567
     22   200       0.0277       0.0276     0.000115        0.233        0.848       0.0194
     22   300       0.0268       0.0264     0.000341        0.244         2.08       0.0312
     22   400       0.0354       0.0353     0.000119        0.267        0.863       0.0196
     22   500       0.0422       0.0418     0.000469          0.3         2.25       0.0399
     22   600       0.0215       0.0214     0.000108        0.213         1.41       0.0198
     22   700       0.0193       0.0186     0.000757        0.179         1.99       0.0527
     22   800       0.0469       0.0465     0.000381        0.329          1.7       0.0353
     22   900       0.0384       0.0379     0.000494        0.267         1.98       0.0402
     22  1000       0.0305       0.0304     5.01e-05         0.26         1.05       0.0128
     22  1100       0.0205       0.0201     0.000346         0.21         1.61       0.0335
     22  1200       0.0215       0.0213     0.000175        0.212        0.634       0.0203
     22  1300       0.0238       0.0227      0.00104        0.205         1.81       0.0552
     22  1400       0.0392       0.0383      0.00081        0.277         4.26       0.0509
     22  1500        0.034       0.0338     0.000267        0.269         1.11       0.0243
     22  1600       0.0389       0.0382     0.000689        0.273          4.6       0.0394
     22  1601       0.0285       0.0285     5.51e-05        0.248        0.541       0.0113

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22   100       0.0208         0.02     0.000724        0.212          1.4       0.0391
     22   200       0.0313       0.0304     0.000945        0.252         4.31       0.0565
     22   203       0.0332       0.0327     0.000521        0.267          2.1       0.0437


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              22 2575.683    0.003       0.0296     0.000584       0.0302        0.247         2.15       0.0356
! Validation         22 2575.683    0.003       0.0283     0.000867       0.0292        0.244          2.9       0.0507
Wall time: 2575.6831802930683

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23   100       0.0267       0.0262     0.000508        0.234         2.37       0.0423
     23   200       0.0603       0.0601     0.000166        0.344         1.74       0.0243
     23   300       0.0198       0.0197     5.21e-05        0.195         0.79       0.0123
     23   400       0.0364       0.0348      0.00163        0.252          3.2       0.0766
     23   500       0.0306       0.0306     2.16e-05        0.251        0.303      0.00615
     23   600       0.0262       0.0261     7.43e-05        0.235        0.927       0.0164
     23   700       0.0292       0.0289     0.000301         0.23         2.02       0.0302
     23   800       0.0406       0.0404     0.000155        0.281         1.76         0.02
     23   900       0.0155       0.0148      0.00063        0.181          3.1       0.0479
     23  1000       0.0172        0.016      0.00125        0.164         2.18       0.0634
     23  1100        0.016       0.0159     6.58e-05         0.18        0.571       0.0136
     23  1200       0.0249       0.0242     0.000681        0.229         1.89       0.0448
     23  1300        0.028        0.028     3.67e-05        0.248        0.788       0.0107
     23  1400       0.0321        0.032     0.000112        0.267         1.27       0.0188
     23  1500       0.0435       0.0434      0.00011        0.307         1.57       0.0174
     23  1600       0.0423       0.0422     8.64e-05        0.302         1.38       0.0172
     23  1601      0.00911      0.00879     0.000313        0.134        0.839       0.0275

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23   100       0.0187       0.0181     0.000658        0.199         2.02       0.0426
     23   200       0.0301       0.0299     0.000217        0.248         1.66       0.0256
     23   203       0.0272       0.0269     0.000316        0.244         1.58       0.0328


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              23 2691.834    0.003       0.0275     0.000454       0.0279        0.239         1.85       0.0304
! Validation         23 2691.834    0.003        0.025     0.000391       0.0253        0.229         2.01       0.0305
Wall time: 2691.8339946649503

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24   100        0.037       0.0368     0.000215        0.258         1.38       0.0245
     24   200        0.033       0.0321     0.000905        0.253         2.29       0.0457
     24   300       0.0203       0.0199     0.000472        0.208         1.84       0.0383
     24   400       0.0311       0.0309     0.000116        0.247         1.05       0.0194
     24   500       0.0172       0.0172     7.04e-05        0.188        0.604       0.0148
     24   600       0.0884       0.0845      0.00394        0.391         8.44          0.1
     24   700       0.0201       0.0197     0.000385        0.197        0.926       0.0297
     24   800       0.0188       0.0177       0.0011        0.191         3.13        0.063
     24   900        0.032       0.0313      0.00065        0.258         2.11        0.045
     24  1000       0.0446       0.0432      0.00136        0.304         4.28       0.0693
     24  1100       0.0449       0.0449     4.21e-05        0.307        0.512       0.0106
     24  1200       0.0419       0.0409      0.00103        0.302         4.43       0.0597
     24  1300       0.0269       0.0267     0.000157        0.223        0.578       0.0157
     24  1400       0.0227       0.0222     0.000426        0.219         1.77       0.0368
     24  1500       0.0179       0.0164      0.00155        0.191          4.4       0.0751
     24  1600       0.0323       0.0322     4.93e-05        0.276        0.745       0.0123
     24  1601       0.0244       0.0241     0.000311        0.207         1.08       0.0317

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24   100       0.0181       0.0179     0.000209        0.195         1.12       0.0248
     24   200       0.0283       0.0283     7.91e-05        0.244        0.736       0.0155
     24   203       0.0238       0.0237     6.03e-05        0.232        0.609       0.0127


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              24 2807.144    0.003       0.0285     0.000529       0.0291        0.243         2.06       0.0337
! Validation         24 2807.144    0.003       0.0242     0.000148       0.0244        0.225         1.09       0.0177
Wall time: 2807.1439565280452

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25   100       0.0253       0.0252     9.18e-05        0.235         0.92       0.0171
     25   200       0.0459       0.0456      0.00029        0.318          2.7       0.0277
     25   300       0.0234       0.0234     2.63e-05        0.226        0.411      0.00857
     25   400       0.0238       0.0236     0.000228        0.222         1.66       0.0239
     25   500       0.0215       0.0209     0.000545        0.202         1.82       0.0392
     25   600       0.0182        0.018     0.000279        0.175         1.59        0.029
     25   700       0.0178       0.0177     9.73e-05          0.2        0.892       0.0186
     25   800       0.0208       0.0206      0.00013        0.202        0.867       0.0192
     25   900       0.0246       0.0244      0.00026        0.218         1.77       0.0283
     25  1000       0.0134       0.0133     0.000108        0.146        0.674       0.0184
     25  1100       0.0179       0.0177     0.000162        0.181        0.904       0.0208
     25  1200       0.0195       0.0195     2.59e-05        0.193        0.328       0.0078
     25  1300       0.0205       0.0202     0.000267        0.186        0.974       0.0306
     25  1400       0.0159       0.0155     0.000463        0.175         1.42       0.0298
     25  1500       0.0191        0.019     3.27e-05        0.184        0.379      0.00944
     25  1600       0.0318        0.031     0.000713        0.234         2.07        0.048
     25  1601       0.0359       0.0357      0.00012        0.272         1.72       0.0191

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25   100       0.0191       0.0185     0.000626        0.201         2.03       0.0432
     25   200        0.028       0.0278     0.000224        0.244         1.41       0.0255
     25   203        0.031       0.0307     0.000296        0.261         1.54        0.032


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              25 2924.841    0.003       0.0282     0.000505       0.0287        0.242         1.94       0.0319
! Validation         25 2924.841    0.003       0.0261     0.000382       0.0265        0.233         2.04       0.0312
Wall time: 2924.8412587798666

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26   100       0.0283       0.0281     0.000241        0.238         1.18       0.0287
     26   200       0.0282       0.0275     0.000752        0.241         4.19       0.0491
     26   300       0.0236       0.0235     9.94e-05        0.222         1.08       0.0163
     26   400       0.0287       0.0283      0.00046        0.245         1.44       0.0369
     26   500       0.0248       0.0246     0.000181        0.229          2.9       0.0253
     26   600       0.0249       0.0249     8.09e-05        0.224        0.594       0.0124
     26   700       0.0182        0.018     0.000274         0.19         1.05       0.0298
     26   800      0.00541      0.00538     3.39e-05       0.0966        0.258      0.00888
     26   900       0.0242        0.024     0.000228         0.22         1.05       0.0264
     26  1000       0.0318       0.0318     4.68e-05        0.263        0.773       0.0122
     26  1100       0.0272       0.0272     1.11e-05        0.247        0.237       0.0047
     26  1200       0.0238       0.0235     0.000272        0.225         2.48       0.0281
     26  1300       0.0193       0.0188     0.000546        0.185         1.39       0.0394
     26  1400        0.038        0.038     3.39e-05        0.267        0.714      0.00822
     26  1500       0.0159       0.0158     0.000114        0.188         0.66       0.0164
     26  1600       0.0242        0.024     0.000199        0.221         1.63       0.0239
     26  1601       0.0153       0.0153     3.78e-06        0.181        0.126      0.00311

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26   100       0.0188       0.0188     6.24e-05        0.204          0.6       0.0129
     26   200       0.0287       0.0287     7.61e-06        0.248        0.203      0.00393
     26   203       0.0261       0.0261     1.63e-05        0.238        0.335      0.00698


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              26 3042.414    0.003       0.0279     0.000412       0.0283        0.239          1.8       0.0298
! Validation         26 3042.414    0.003       0.0251     0.000118       0.0252        0.229        0.932       0.0144
Wall time: 3042.4147421258967
! Best model       26    0.014

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27   100       0.0208       0.0203     0.000532        0.192          1.4       0.0405
     27   200       0.0156       0.0156     3.46e-05        0.185        0.862       0.0108
     27   300       0.0184       0.0182      0.00018        0.186        0.949       0.0223
     27   400       0.0439       0.0438     2.16e-05        0.305          1.5      0.00749
     27   500       0.0337       0.0321      0.00158        0.262         4.36       0.0457
     27   600       0.0185       0.0184     3.87e-05        0.195        0.556      0.00924
     27   700       0.0316       0.0314     0.000182        0.253         2.33       0.0249
     27   800       0.0417       0.0411       0.0006        0.273         3.21       0.0459
     27   900       0.0266       0.0264     0.000148        0.234         1.35       0.0198
     27  1000       0.0185       0.0183     0.000216        0.194         1.19       0.0267
     27  1100       0.0406       0.0404     0.000259         0.29         2.22       0.0294
     27  1200       0.0414       0.0404     0.000989        0.301          8.3         0.06
     27  1300       0.0184       0.0181     0.000346         0.19         2.08       0.0345
     27  1400        0.015       0.0149     7.36e-06        0.167        0.168      0.00375
     27  1500       0.0774       0.0766     0.000843        0.323         3.12       0.0497
     27  1600       0.0163       0.0158     0.000438        0.184         1.68       0.0395
     27  1601         0.06         0.06     5.61e-05        0.355        0.769       0.0127

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27   100        0.018       0.0179     6.42e-05        0.199        0.602       0.0131
     27   200       0.0275       0.0275     8.62e-06        0.243        0.229      0.00439
     27   203       0.0245       0.0245     1.66e-05        0.237        0.374      0.00779


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              27 3156.986    0.003       0.0268     0.000443       0.0273        0.236         1.86       0.0307
! Validation         27 3156.986    0.003       0.0238     7.32e-05       0.0239        0.223        0.738        0.011
Wall time: 3156.9863417390734
! Best model       27    0.011

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28   100       0.0266       0.0264     0.000235        0.208         2.54       0.0257
     28   200       0.0218       0.0217     6.56e-05        0.217        0.733       0.0153
     28   300       0.0462       0.0458       0.0004        0.286         1.91       0.0367
     28   400       0.0262       0.0259      0.00024         0.23         1.19       0.0249
     28   500       0.0298       0.0296     0.000161        0.245         1.89       0.0212
     28   600       0.0275       0.0274     0.000119        0.241         1.34       0.0164
     28   700       0.0292       0.0292     4.17e-05        0.244        0.553      0.00905
     28   800       0.0224       0.0223      0.00012        0.223         1.28       0.0208
     28   900       0.0365        0.036     0.000504        0.268         1.65        0.036
     28  1000       0.0169       0.0165      0.00038        0.181        0.947       0.0305
     28  1100         0.04       0.0399      5.3e-05        0.293        0.581       0.0114
     28  1200       0.0193       0.0191     0.000254        0.195         2.31       0.0294
     28  1300       0.0224       0.0221     0.000307         0.22         1.82       0.0311
     28  1400       0.0239       0.0229     0.000937        0.218         3.37       0.0589
     28  1500        0.011      0.00954      0.00148        0.133         2.82       0.0687
     28  1600       0.0621       0.0612      0.00091        0.316         4.24       0.0492
     28  1601       0.0182       0.0181     9.33e-06        0.205         0.39      0.00569

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28   100       0.0187       0.0185     0.000117        0.195        0.698       0.0177
     28   200       0.0267       0.0264     0.000249        0.237         2.43       0.0297
     28   203       0.0225       0.0222     0.000242        0.224         1.44       0.0301


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              28 3275.442    0.003       0.0261     0.000347       0.0265        0.233         1.62       0.0269
! Validation         28 3275.442    0.003       0.0241     0.000292       0.0244        0.224         1.84       0.0298
Wall time: 3275.4428310010117

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29   100       0.0533       0.0519      0.00141        0.302         3.72       0.0713
     29   200       0.0297       0.0287     0.000964        0.249          2.7       0.0563
     29   300       0.0382       0.0377     0.000473        0.287         3.67       0.0388
     29   400      0.00927      0.00922     5.75e-05        0.125         0.44       0.0123
     29   500       0.0289       0.0285     0.000351        0.247         2.19       0.0354
     29   600       0.0191       0.0186     0.000481        0.198         2.04       0.0409
     29   700       0.0393        0.039     0.000239        0.273         2.11       0.0256
     29   800       0.0271       0.0268     0.000289        0.235         1.93       0.0314
     29   900       0.0213       0.0207      0.00061        0.204         2.01       0.0452
     29  1000        0.018        0.018     3.34e-05        0.191        0.301       0.0082
     29  1100       0.0354       0.0346     0.000819        0.274         5.02       0.0519
     29  1200       0.0271       0.0269     0.000195        0.244         1.07       0.0214
     29  1300       0.0401       0.0395     0.000583        0.289         2.95       0.0466
     29  1400       0.0335        0.033     0.000553        0.272         3.45       0.0434
     29  1500       0.0196       0.0193     0.000371        0.197         1.38       0.0347
     29  1600       0.0342       0.0341     9.03e-05        0.265         1.13       0.0155
     29  1601       0.0356       0.0354     0.000143        0.263         1.15       0.0218

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29   100       0.0206       0.0193      0.00128        0.209         3.01       0.0684
     29   200       0.0314       0.0307     0.000637        0.255         2.83       0.0473
     29   203       0.0299       0.0291     0.000811        0.252          2.6       0.0542


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              29 3388.781    0.003       0.0268     0.000479       0.0273        0.236         1.93       0.0318
! Validation         29 3388.781    0.003       0.0257      0.00113       0.0269        0.233         3.64       0.0602
Wall time: 3388.781758283032

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30   100       0.0361       0.0357     0.000416        0.245          2.3       0.0377
     30   200       0.0324       0.0323     0.000134        0.247         1.37       0.0182
     30   300        0.021        0.021     7.86e-05        0.214        0.751       0.0147
     30   400       0.0281       0.0281     5.39e-05        0.247        0.848       0.0114
     30   500        0.035       0.0349     3.84e-05        0.271        0.697       0.0111
     30   600       0.0317       0.0315     0.000172        0.247         1.32       0.0215
     30   700      0.00989      0.00957      0.00032        0.136         1.05       0.0304
     30   800       0.0251       0.0247     0.000409        0.211         2.15       0.0385
     30   900      0.00888      0.00864     0.000242        0.127        0.639       0.0214
     30  1000       0.0317       0.0306      0.00108        0.243         2.36       0.0584
     30  1100         0.02       0.0198     0.000239         0.21         1.59       0.0229
     30  1200       0.0286       0.0283     0.000362        0.241         2.31       0.0343
     30  1300       0.0247       0.0243     0.000414        0.236         2.52       0.0331
     30  1400       0.0252        0.025     0.000252        0.227         1.69       0.0251
     30  1500       0.0254       0.0253     0.000173        0.232        0.691       0.0192
     30  1600        0.035       0.0349     6.92e-05        0.275         1.02        0.014
     30  1601       0.0545       0.0543     0.000206        0.311         2.13       0.0227

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30   100       0.0214       0.0208     0.000593        0.213         1.97       0.0453
     30   200       0.0303         0.03     0.000353        0.256         2.34       0.0356
     30   203       0.0294       0.0292     0.000178         0.26         1.23       0.0257


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              30 3507.057    0.003       0.0268     0.000484       0.0273        0.235          1.9       0.0316
! Validation         30 3507.057    0.003       0.0262     0.000403       0.0266        0.236         1.87       0.0315
Wall time: 3507.057085858891

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31   100       0.0327       0.0327     5.14e-05        0.246        0.569       0.0123
     31   200       0.0246       0.0246     3.87e-07        0.234        0.108      0.00103
     31   300        0.024       0.0239      5.4e-05        0.221         1.06       0.0131
     31   400       0.0212       0.0196      0.00159        0.206         4.73       0.0766
     31   500       0.0261       0.0254     0.000708        0.238          2.1       0.0438
     31   600        0.021       0.0208     0.000185        0.218         1.34       0.0228
     31   700       0.0247       0.0238     0.000858        0.228         2.86       0.0554
     31   800      0.00941      0.00931     0.000101        0.134         0.45       0.0159
     31   900       0.0131        0.013     7.47e-05        0.165        0.449        0.013
     31  1000       0.0192       0.0187     0.000444        0.188         1.51       0.0401
     31  1100       0.0192       0.0191      0.00014        0.194        0.938       0.0197
     31  1200       0.0198       0.0196       0.0002        0.206         1.08       0.0225
     31  1300        0.021       0.0208       0.0002        0.205        0.977       0.0206
     31  1400       0.0339       0.0337     0.000191        0.266         1.21       0.0209
     31  1500       0.0308       0.0308     6.98e-05        0.266         1.01       0.0158
     31  1600       0.0181        0.018     0.000131        0.177        0.776       0.0213
     31  1601       0.0239       0.0235     0.000311        0.235         1.63        0.034

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31   100       0.0197       0.0191       0.0006         0.21         1.98       0.0455
     31   200        0.027       0.0265     0.000424        0.241         2.31       0.0386
     31   203        0.025       0.0248     0.000226        0.237         1.37       0.0286


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              31 3621.429    0.003       0.0273     0.000478       0.0278        0.237         1.86       0.0308
! Validation         31 3621.429    0.003       0.0243     0.000493       0.0248        0.227         2.27       0.0386
Wall time: 3621.429129394004

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32   100       0.0224       0.0223     0.000114         0.21        0.717       0.0184
     32   200       0.0201       0.0194     0.000746        0.194         3.18       0.0366
     32   300       0.0651        0.059      0.00618         0.35         10.2        0.108
     32   400       0.0306       0.0304     0.000253        0.249         2.24       0.0293
     32   500       0.0286       0.0278     0.000803        0.249         3.04       0.0365
     32   600       0.0138       0.0137     5.75e-05        0.176        0.502       0.0132
     32   700       0.0287       0.0284     0.000234        0.251         3.75       0.0249
     32   800       0.0271       0.0271     3.13e-05        0.234        0.452      0.00885
     32   900       0.0316       0.0315     5.53e-05        0.248        0.491       0.0117
     32  1000         0.02       0.0195     0.000478        0.206         1.59       0.0388
     32  1100       0.0214       0.0201       0.0013        0.185         2.39       0.0674
     32  1200       0.0227       0.0202      0.00245        0.192         4.94        0.092
     32  1300       0.0225       0.0221     0.000438        0.218         1.25       0.0297
     32  1400       0.0344       0.0339      0.00053        0.269         3.55       0.0407
     32  1500       0.0257       0.0257     3.13e-05        0.233         0.65      0.00997
     32  1600       0.0696       0.0694     0.000238        0.347         1.99       0.0288
     32  1601       0.0351       0.0348     0.000373        0.272          1.7       0.0354

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32   100       0.0231        0.021      0.00211        0.215         3.86       0.0851
     32   200       0.0319       0.0306      0.00137        0.254         4.87       0.0706
     32   203       0.0324       0.0306      0.00179        0.256         3.93       0.0818


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              32 3737.837    0.003       0.0266     0.000454        0.027        0.234         1.81       0.0297
! Validation         32 3737.837    0.003        0.027      0.00154       0.0286        0.238         4.54       0.0728
Wall time: 3737.837473147083

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33   100      0.00881      0.00832     0.000487        0.132         1.13       0.0387
     33   200       0.0185       0.0185     3.82e-05        0.178        0.373      0.00901
     33   300       0.0232       0.0231     9.94e-05        0.223        0.713       0.0169
     33   400       0.0253       0.0246     0.000709        0.232         3.18       0.0506
     33   500       0.0542       0.0541     8.91e-05        0.311         1.38       0.0161
     33   600       0.0303       0.0258      0.00453        0.215         4.31        0.122
     33   700       0.0301       0.0298     0.000291        0.256         4.28       0.0295
     33   800       0.0266       0.0253      0.00138         0.23         7.82       0.0683
     33   900       0.0281       0.0278     0.000274         0.25          1.7       0.0293
     33  1000       0.0333       0.0325     0.000808        0.254         3.49       0.0432
     33  1100       0.0356       0.0352     0.000388        0.267         2.25       0.0362
     33  1200       0.0228       0.0228     2.34e-05         0.22        0.438      0.00744
     33  1300       0.0397       0.0396     0.000101        0.286         1.23       0.0182
     33  1400        0.021       0.0198      0.00122        0.207          3.4        0.062
     33  1500       0.0365       0.0358     0.000779        0.252         2.31       0.0509
     33  1600       0.0231       0.0229      0.00014         0.22        0.797       0.0201
     33  1601       0.0392       0.0392     3.73e-05        0.294        0.898       0.0118

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33   100       0.0189       0.0183     0.000558        0.197         1.57       0.0406
     33   200       0.0303       0.0293      0.00101        0.254         3.72       0.0599
     33   203       0.0255       0.0244      0.00108        0.235         3.04       0.0633


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              33 3850.534    0.003       0.0274     0.000595       0.0279        0.238         2.05        0.034
! Validation         33 3850.534    0.003       0.0248      0.00107       0.0259        0.229          3.3       0.0594
Wall time: 3850.534567290917

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34   100       0.0173       0.0172      9.3e-05        0.196        0.789       0.0164
     34   200        0.019       0.0186     0.000346        0.199         2.08       0.0355
     34   300       0.0322       0.0318      0.00047        0.253         3.01       0.0397
     34   400       0.0207       0.0206     0.000167        0.215         1.03       0.0216
     34   500       0.0469       0.0466     0.000288        0.314         1.74       0.0294
     34   600       0.0222       0.0222     3.63e-05        0.216        0.517      0.00947
     34   700       0.0226       0.0226     6.88e-05        0.216         1.32       0.0139
     34   800       0.0231        0.023     9.35e-05        0.225        0.678       0.0144
     34   900       0.0227       0.0224     0.000266        0.219         1.32       0.0308
     34  1000       0.0383       0.0379     0.000364        0.276         2.08       0.0338
     34  1100       0.0203       0.0201     0.000257        0.191        0.921       0.0277
     34  1200       0.0303       0.0299     0.000396        0.237         1.36       0.0325
     34  1300       0.0287       0.0284     0.000379        0.246         2.06       0.0326
     34  1400       0.0244       0.0236     0.000794        0.222          2.9       0.0481
     34  1500       0.0161        0.016     7.44e-05        0.189         0.78       0.0162
     34  1600       0.0406         0.04     0.000597        0.282         3.14       0.0369
     34  1601       0.0296       0.0295     0.000167        0.251         2.45       0.0234

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34   100       0.0201       0.0196     0.000502         0.21         1.86       0.0423
     34   200       0.0277       0.0274      0.00029        0.242         1.71       0.0312
     34   203        0.025       0.0249     0.000178        0.237         1.24       0.0258


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              34 3962.724    0.003       0.0267     0.000388       0.0271        0.235         1.74       0.0287
! Validation         34 3962.724    0.003       0.0244     0.000394       0.0248        0.227         2.09       0.0342
Wall time: 3962.7243372290395

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35   100       0.0101      0.00972     0.000394        0.126        0.948       0.0331
     35   200       0.0189       0.0188     0.000125          0.2        0.844       0.0197
     35   300       0.0185       0.0184     0.000153        0.179        0.673       0.0199
     35   400       0.0322       0.0321     9.38e-05        0.263         1.14        0.015
     35   500       0.0239       0.0237     0.000174        0.224         1.45       0.0222
     35   600      0.00967        0.009      0.00067        0.128         1.77       0.0491
     35   700       0.0224       0.0223     0.000114        0.222         1.01       0.0172
     35   800       0.0245       0.0242     0.000276        0.227         1.68       0.0311
     35   900       0.0357       0.0327      0.00301        0.263         7.09       0.0972
     35  1000       0.0256       0.0255      9.5e-05        0.232        0.828       0.0159
     35  1100       0.0326       0.0325     0.000126        0.265         1.38       0.0179
     35  1200       0.0374       0.0373     9.84e-05        0.268          1.2       0.0163
     35  1300       0.0241        0.024     9.46e-05        0.213        0.652       0.0155
     35  1400         0.03       0.0299     0.000143        0.229         2.87       0.0227
     35  1500       0.0328       0.0323     0.000506        0.268         2.13       0.0396
     35  1600       0.0109       0.0109     4.66e-05        0.145        0.454         0.01
     35  1601        0.014       0.0139     0.000183        0.169         1.01        0.026

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35   100       0.0179       0.0178     5.57e-05        0.195        0.572       0.0135
     35   200       0.0248       0.0248     6.65e-06        0.232        0.445      0.00352
     35   203       0.0239       0.0239     9.39e-06        0.229         0.24        0.005


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              35 4078.823    0.003       0.0252      0.00033       0.0256        0.229         1.63       0.0269
! Validation         35 4078.823    0.003       0.0232     0.000105       0.0233         0.22        0.842       0.0138
Wall time: 4078.8237738569733

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36   100        0.027       0.0261     0.000926         0.23         4.21       0.0575
     36   200       0.0418       0.0413     0.000465        0.243         2.69       0.0349
     36   300       0.0191        0.018      0.00105        0.186         1.74       0.0532
     36   400       0.0295       0.0294     7.47e-05        0.252         1.04       0.0136
     36   500       0.0257       0.0254     0.000275        0.239         1.86       0.0272
     36   600       0.0259       0.0259     3.97e-05        0.227        0.729      0.00845
     36   700       0.0351       0.0347     0.000406        0.259         1.91       0.0361
     36   800       0.0196       0.0196     9.24e-06        0.206        0.219      0.00456
     36   900       0.0228       0.0226     0.000151        0.219         1.33       0.0219
     36  1000       0.0181       0.0178     0.000242         0.18        0.985       0.0236
     36  1100        0.033        0.033      7.5e-05        0.264        0.543       0.0109
     36  1200       0.0256       0.0254     0.000183        0.234         2.03       0.0236
     36  1300       0.0311       0.0311      1.7e-05        0.256        0.381      0.00659
     36  1400         0.02       0.0198     0.000177        0.205         1.11       0.0233
     36  1500       0.0278       0.0277      9.9e-05        0.242        0.803       0.0167
     36  1600       0.0236       0.0235     0.000105        0.227        0.954       0.0167
     36  1601       0.0253        0.025     0.000333        0.238         1.69       0.0352

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36   100       0.0171       0.0166     0.000478        0.187         1.79       0.0415
     36   200       0.0257       0.0255     0.000244        0.234          1.5       0.0278
     36   203       0.0254       0.0252     0.000242        0.237         1.42       0.0296


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              36 4191.792    0.003       0.0251     0.000405       0.0255        0.228         1.78       0.0293
! Validation         36 4191.792    0.003       0.0227     0.000447       0.0232        0.218         2.06       0.0354
Wall time: 4191.792045043083

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37   100       0.0217       0.0216     4.75e-05        0.217        0.749       0.0117
     37   200       0.0165       0.0162     0.000315        0.188         1.11        0.029
     37   300       0.0417       0.0412     0.000437        0.292         3.12       0.0404
     37   400        0.038       0.0377     0.000256        0.267          1.2       0.0281
     37   500       0.0136       0.0134     0.000201        0.164        0.854       0.0253
     37   600       0.0254       0.0253     0.000115        0.235        0.788       0.0189
     37   700       0.0184       0.0183     9.08e-05        0.204        0.801       0.0167
     37   800       0.0254       0.0246     0.000709        0.225         4.12       0.0494
     37   900        0.017       0.0169     0.000137        0.172        0.988       0.0178
     37  1000       0.0223       0.0221     0.000218        0.221         1.35       0.0281
     37  1100       0.0274       0.0273     9.39e-05        0.231         1.06       0.0129
     37  1200       0.0243       0.0243     7.15e-05        0.233        0.993       0.0163
     37  1300       0.0262       0.0251      0.00116        0.212         2.43       0.0649
     37  1400       0.0265       0.0258     0.000722        0.219         2.72       0.0518
     37  1500       0.0123       0.0114     0.000814        0.156         1.83       0.0476
     37  1600       0.0437       0.0424      0.00134        0.285         5.09       0.0593
     37  1601       0.0269       0.0256      0.00136        0.219         2.76       0.0649

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37   100       0.0188       0.0187     9.49e-05        0.203        0.756       0.0168
     37   200       0.0266       0.0263     0.000302        0.241         1.76        0.029
     37   203       0.0239       0.0232      0.00064        0.228         2.32       0.0482


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              37 4306.490    0.003       0.0259      0.00056       0.0265        0.231         2.12       0.0355
! Validation         37 4306.490    0.003       0.0254     0.000429       0.0258        0.232            2       0.0339
Wall time: 4306.490147534991

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38   100       0.0305       0.0301     0.000371        0.257          2.2       0.0337
     38   200       0.0426       0.0425     0.000129        0.299         1.72       0.0193
     38   300        0.033       0.0329     0.000126        0.255        0.846       0.0157
     38   400       0.0253       0.0253     5.93e-05        0.225        0.788       0.0132
     38   500         0.03       0.0296      0.00033        0.233         2.19       0.0325
     38   600       0.0173        0.017     0.000277        0.182         1.32       0.0313
     38   700       0.0281       0.0278     0.000294        0.227         1.41       0.0302
     38   800       0.0169       0.0168     0.000125        0.186        0.829       0.0183
     38   900       0.0321       0.0266      0.00555         0.23         5.75        0.139
     38  1000       0.0291       0.0289     0.000233        0.255         1.36       0.0283
     38  1100       0.0202       0.0202     6.09e-05        0.205        0.423       0.0115
     38  1200      0.00815      0.00815     8.35e-06        0.117        0.184       0.0051
     38  1300       0.0134        0.013      0.00044        0.151         1.58       0.0389
     38  1400        0.016       0.0153     0.000765        0.177         2.28       0.0489
     38  1500       0.0202       0.0201     0.000102        0.209        0.832       0.0173
     38  1600       0.0587       0.0514      0.00727        0.311         9.94       0.0958
     38  1601       0.0286       0.0285     2.09e-05        0.263        0.648       0.0074

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38   100       0.0176       0.0175      7.9e-05        0.195        0.596       0.0128
     38   200       0.0258       0.0258     5.67e-06        0.237         0.38       0.0039
     38   203        0.025        0.025     1.26e-05        0.233        0.286      0.00596


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              38 4419.310    0.003       0.0263     0.000716        0.027         0.23         1.87       0.0306
! Validation         38 4419.310    0.003       0.0226     9.34e-05       0.0227        0.216        0.854       0.0128
Wall time: 4419.310169212986

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39   100       0.0256       0.0252     0.000439        0.229         1.68       0.0353
     39   200       0.0135       0.0135     1.38e-05        0.169        0.309      0.00643
     39   300      0.00814      0.00797     0.000162        0.134        0.891       0.0243
     39   400       0.0213       0.0213     1.64e-05        0.209        0.317      0.00639
     39   500       0.0408       0.0404     0.000456        0.268          2.7       0.0402
     39   600       0.0391       0.0367      0.00242        0.267         6.16       0.0819
     39   700       0.0307       0.0306     5.95e-05        0.256        0.488       0.0102
     39   800       0.0248       0.0246     0.000206        0.235         1.37       0.0249
     39   900       0.0398       0.0397     9.96e-05        0.291          1.1       0.0167
     39  1000       0.0367       0.0354      0.00132        0.274         3.78       0.0671
     39  1100       0.0282       0.0279     0.000328        0.232         1.06       0.0312
     39  1200       0.0186       0.0175      0.00112        0.177         1.77       0.0545
     39  1300       0.0278       0.0277     9.69e-05        0.243         1.48       0.0154
     39  1400       0.0185       0.0184     0.000149        0.188        0.686       0.0208
     39  1500       0.0323       0.0314     0.000892        0.256         5.13       0.0564
     39  1600        0.024        0.024     4.81e-05        0.223        0.702       0.0122
     39  1601       0.0197       0.0195     0.000154        0.198         0.81       0.0231

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39   100       0.0194       0.0193     0.000105        0.202        0.422       0.0128
     39   200       0.0267       0.0265      0.00013        0.238         1.51       0.0209
     39   203       0.0234       0.0233     3.31e-05        0.228        0.505       0.0105


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              39 4533.178    0.003       0.0252     0.000401       0.0256        0.229         1.77       0.0295
! Validation         39 4533.178    0.003       0.0236     0.000166       0.0237        0.223         1.13       0.0196
Wall time: 4533.177978306077

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40   100       0.0245       0.0239     0.000564        0.226          3.1       0.0445
     40   200       0.0177       0.0176     7.97e-05        0.183        0.578        0.014
     40   300       0.0281        0.028     9.35e-05        0.254         1.15       0.0173
     40   400       0.0165       0.0161     0.000357        0.194         1.73       0.0359
     40   500       0.0178       0.0174      0.00043        0.194         2.57       0.0352
     40   600       0.0324       0.0321     0.000321        0.268         2.16       0.0295
     40   700       0.0142        0.014     0.000264        0.171         1.41       0.0272
     40   800       0.0113       0.0111       0.0002        0.152        0.799        0.024
     40   900       0.0118       0.0116     0.000209        0.131         0.84        0.027
     40  1000       0.0197       0.0196     9.25e-05          0.2        0.773       0.0167
     40  1100       0.0239       0.0231     0.000779        0.223         2.56       0.0534
     40  1200       0.0285       0.0281     0.000444        0.251         2.14       0.0377
     40  1300       0.0285       0.0283     0.000145        0.229          1.4       0.0177
     40  1400       0.0111       0.0111     3.15e-05        0.144        0.368       0.0103
     40  1500       0.0328       0.0324      0.00037        0.261         1.57       0.0371
     40  1600       0.0334       0.0333     0.000149        0.255         1.49       0.0219
     40  1601       0.0286       0.0286      2.7e-05        0.256        0.411      0.00856

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40   100       0.0182        0.018     0.000264        0.192         1.04       0.0266
     40   200       0.0303       0.0297     0.000611        0.249         3.76       0.0474
     40   203       0.0201       0.0197     0.000479        0.215         2.03       0.0423


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              40 4647.777    0.003       0.0249     0.000366       0.0253        0.227         1.74       0.0286
! Validation         40 4647.777    0.003       0.0236     0.000464       0.0241        0.221         2.32       0.0381
Wall time: 4647.777203954058

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41   100       0.0359       0.0354      0.00045        0.265         3.55       0.0389
     41   200       0.0141        0.014     0.000127        0.153        0.653       0.0161
     41   300       0.0331       0.0327     0.000361        0.272         2.29       0.0351
     41   400       0.0228       0.0225     0.000276        0.227         1.73       0.0242
     41   500       0.0288       0.0283     0.000501        0.222         1.92       0.0384
     41   600       0.0455       0.0454     3.02e-05        0.291        0.739      0.00929
     41   700      0.00234      0.00184     0.000498       0.0647          1.2       0.0427
     41   800       0.0177       0.0176     0.000118        0.193        0.744       0.0174
     41   900       0.0258       0.0257     7.23e-05        0.225            1       0.0102
     41  1000       0.0178       0.0176     0.000164        0.179        0.721       0.0219
     41  1100       0.0225       0.0223     0.000246        0.214         1.11       0.0241
     41  1200       0.0283       0.0278     0.000523         0.25          2.3       0.0406
     41  1300        0.027       0.0266     0.000403        0.228         1.28       0.0324
     41  1400       0.0375       0.0368     0.000707        0.276          2.8        0.051
     41  1500       0.0233       0.0228     0.000465        0.212         1.84       0.0369
     41  1600         0.02       0.0199     0.000172        0.191          1.1       0.0244
     41  1601       0.0157       0.0156     3.19e-05        0.187        0.818      0.00969

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41   100       0.0177       0.0177     6.08e-05        0.195        0.368       0.0106
     41   200       0.0257       0.0256     0.000116        0.235          1.7       0.0195
     41   203       0.0212       0.0212     6.09e-05        0.218        0.723       0.0151


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              41 4761.153    0.003       0.0252     0.000339       0.0256        0.228         1.61       0.0266
! Validation         41 4761.153    0.003       0.0221     0.000139       0.0222        0.214          1.1       0.0185
Wall time: 4761.153647926869

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42   100       0.0226       0.0217     0.000852        0.219         3.88       0.0557
     42   200       0.0338       0.0337     7.59e-05        0.264        0.776       0.0146
     42   300       0.0101      0.00992     0.000211        0.133         2.94       0.0274
     42   400       0.0185       0.0185     5.66e-05        0.189         0.49       0.0112
     42   500       0.0351        0.035     9.84e-05        0.263        0.876       0.0137
     42   600       0.0185       0.0185      6.3e-05        0.198         0.63       0.0143
     42   700       0.0234       0.0227     0.000618        0.225         3.34       0.0338
     42   800       0.0255       0.0249     0.000638        0.215         1.64       0.0466
     42   900       0.0275       0.0271     0.000468        0.235         1.89       0.0373
     42  1000       0.0266       0.0266     6.34e-06        0.231        0.282      0.00451
     42  1100       0.0213       0.0212     0.000116        0.214        0.732       0.0186
     42  1200      0.00503      0.00491      0.00012        0.102        0.513       0.0172
     42  1300       0.0344       0.0343     6.31e-05        0.245        0.498       0.0128
     42  1400       0.0146       0.0145     8.75e-05         0.16        0.688       0.0166
     42  1500       0.0334       0.0332     0.000257        0.259          2.4       0.0269
     42  1600       0.0317       0.0308     0.000837        0.251         3.88       0.0416
     42  1601       0.0185       0.0185     6.71e-05        0.191        0.593       0.0136

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42   100       0.0189       0.0187     0.000159        0.201        0.986       0.0236
     42   200       0.0257       0.0256     0.000123        0.237        0.525        0.015
     42   203       0.0247       0.0247     3.86e-05        0.233        0.423      0.00881


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              42 4875.691    0.003       0.0257     0.000556       0.0263         0.23         1.72       0.0278
! Validation         42 4875.691    0.003       0.0228     0.000225        0.023        0.217         1.24       0.0221
Wall time: 4875.691058317898

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43   100       0.0149       0.0147     0.000166        0.168        0.834       0.0224
     43   200        0.025       0.0245     0.000517        0.225          2.8       0.0405
     43   300       0.0294       0.0292     0.000257        0.247         2.35       0.0297
     43   400       0.0254       0.0253     0.000121        0.237          1.4       0.0202
     43   500       0.0246       0.0244     0.000187        0.227        0.953       0.0237
     43   600       0.0219       0.0214     0.000492        0.215          6.5       0.0427
     43   700       0.0219       0.0214     0.000516        0.213         2.94        0.043
     43   800        0.028       0.0279     0.000125        0.245         1.28       0.0192
     43   900       0.0427       0.0422      0.00044         0.28         1.73        0.034
     43  1000       0.0157       0.0156     6.78e-05        0.183        0.733       0.0121
     43  1100       0.0178       0.0174     0.000425        0.168         1.25        0.035
     43  1200       0.0236        0.023     0.000532        0.223         3.55       0.0433
     43  1300        0.032        0.032     6.41e-05        0.243        0.582       0.0135
     43  1400       0.0279       0.0278     6.07e-05        0.223         1.85       0.0136
     43  1500       0.0219       0.0214      0.00054        0.208         1.81       0.0394
     43  1600       0.0269       0.0268     9.27e-05        0.237        0.847        0.016
     43  1601        0.038       0.0377     0.000257        0.273         1.43       0.0298

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43   100       0.0178       0.0176      0.00018        0.194         1.09       0.0236
     43   200       0.0257       0.0257     4.72e-05        0.235        0.637      0.00966
     43   203       0.0215       0.0215     3.73e-05        0.223        0.513       0.0107


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              43 4988.941    0.003       0.0248     0.000395       0.0251        0.227          1.7        0.028
! Validation         43 4988.941    0.003       0.0222     0.000131       0.0223        0.214         1.07       0.0164
Wall time: 4988.941477630055

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44   100       0.0195       0.0195     4.95e-05        0.208        0.398      0.00829
     44   200       0.0308       0.0306     0.000204        0.251         1.34       0.0237
     44   300       0.0224       0.0222     0.000214        0.203         1.04        0.022
     44   400       0.0248       0.0246     0.000248        0.227         2.12       0.0208
     44   500       0.0297       0.0295     0.000233        0.238         1.76       0.0283
     44   600       0.0311       0.0309      0.00017        0.257         1.99       0.0248
     44   700       0.0169       0.0167     0.000217        0.192         1.56       0.0267
     44   800       0.0213       0.0209     0.000382         0.21         1.63       0.0358
     44   900        0.019        0.019     5.46e-05        0.203        0.526       0.0127
     44  1000       0.0273       0.0272     0.000151        0.245         1.56       0.0215
     44  1100       0.0238       0.0237     0.000125        0.226        0.772       0.0179
     44  1200      0.00968      0.00962     5.75e-05        0.133        0.465       0.0143
     44  1300       0.0287       0.0286     3.98e-05        0.232        0.538       0.0113
     44  1400       0.0286       0.0285     0.000129        0.241         1.35       0.0184
     44  1500        0.017       0.0167     0.000332        0.186         1.42       0.0305
     44  1600       0.0172       0.0169     0.000381        0.179         1.45       0.0356
     44  1601       0.0356       0.0346     0.000945        0.274         4.52       0.0594

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44   100       0.0199       0.0196     0.000289        0.209         1.35       0.0285
     44   200       0.0282       0.0282     6.92e-05         0.25            1       0.0153
     44   203       0.0215       0.0214      3.5e-05        0.216         0.54       0.0113


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              44 5101.457    0.003       0.0265     0.000494        0.027        0.233         1.67       0.0276
! Validation         44 5101.457    0.003       0.0243     0.000245       0.0246        0.227         1.47       0.0229
Wall time: 5101.457728205016

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45   100       0.0379       0.0379     1.22e-05        0.289        0.631      0.00519
     45   200       0.0208       0.0208     4.18e-05         0.21         0.44       0.0109
     45   300        0.025       0.0248     0.000142        0.232        0.839       0.0191
     45   400        0.015        0.015     1.93e-05        0.165        0.266       0.0074
     45   500       0.0247       0.0236      0.00115         0.22         2.63       0.0545
     45   600        0.019       0.0188     0.000218        0.201         1.74       0.0218
     45   700       0.0306       0.0304     0.000166        0.247        0.936       0.0221
     45   800       0.0278       0.0276     0.000225        0.224         1.12       0.0269
     45   900       0.0118       0.0116     0.000136        0.158        0.751       0.0208
     45  1000       0.0251       0.0247     0.000335         0.24         1.59       0.0332
     45  1100       0.0283       0.0282     0.000149        0.238         1.21       0.0199
     45  1200       0.0306       0.0303      0.00028        0.262         5.62       0.0258
     45  1300       0.0276       0.0274     0.000248        0.236            1       0.0262
     45  1400       0.0144       0.0141     0.000341        0.168         1.18       0.0337
     45  1500       0.0153       0.0151     0.000203        0.173         1.65       0.0244
     45  1600       0.0188       0.0187     8.83e-05        0.203        0.848       0.0177
     45  1601       0.0142       0.0141     9.84e-05        0.153        0.556        0.017

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45   100       0.0178       0.0177     5.39e-05        0.194        0.494       0.0103
     45   200       0.0258       0.0257     1.33e-05        0.236        0.473      0.00675
     45   203       0.0203       0.0203     1.47e-05        0.213        0.336        0.007


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              45 5216.446    0.003       0.0244     0.000387       0.0248        0.226         1.74       0.0287
! Validation         45 5216.446    0.003        0.022     0.000118       0.0221        0.215        0.934        0.015
Wall time: 5216.445819183951

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46   100       0.0263       0.0259     0.000314        0.223            1       0.0226
     46   200       0.0222       0.0222     3.14e-05        0.208        0.455      0.00926
     46   300       0.0137       0.0135     0.000133        0.175        0.828       0.0173
     46   400       0.0222       0.0217      0.00043        0.204         1.73       0.0399
     46   500       0.0129       0.0128     9.38e-05        0.153        0.729       0.0173
     46   600       0.0194       0.0192     0.000186        0.209        0.725       0.0198
     46   700       0.0518       0.0517     0.000121        0.335         1.26       0.0188
     46   800       0.0187       0.0186     7.25e-05        0.202         1.08       0.0142
     46   900       0.0152       0.0151     4.53e-05         0.18        0.473      0.00952
     46  1000       0.0176       0.0174     0.000159        0.195         1.78       0.0217
     46  1100       0.0139       0.0135     0.000403        0.172         1.55       0.0373
     46  1200       0.0247       0.0241     0.000566        0.215         2.77       0.0447
     46  1300        0.023       0.0225     0.000487        0.217         1.58       0.0352
     46  1400       0.0267       0.0266      0.00014        0.238         1.01       0.0211
     46  1500       0.0152       0.0151     0.000121        0.176         1.52       0.0195
     46  1600       0.0297       0.0296     0.000109        0.248         1.27       0.0175
     46  1601       0.0114       0.0113     8.04e-05        0.152        0.636       0.0141

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46   100       0.0172       0.0171     8.61e-05        0.192        0.686        0.016
     46   200       0.0266       0.0266     7.62e-06        0.239        0.369      0.00473
     46   203        0.027        0.027     7.61e-06        0.248        0.236      0.00492


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              46 5329.609    0.003       0.0244     0.000352       0.0248        0.224         1.69       0.0275
! Validation         46 5329.609    0.003       0.0229     0.000128       0.0231        0.219         1.06       0.0164
Wall time: 5329.609616952948

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47   100       0.0233       0.0231     0.000226        0.195         1.37       0.0252
     47   200       0.0333       0.0332     9.91e-05        0.249         1.12       0.0176
     47   300       0.0223       0.0215     0.000746        0.204         3.24       0.0367
     47   400       0.0277       0.0274     0.000309        0.236         1.46       0.0297
     47   500       0.0138       0.0137     0.000169        0.173         1.15       0.0212
     47   600       0.0229       0.0228      9.3e-05        0.207        0.663       0.0179
     47   700       0.0249       0.0249      5.8e-05         0.22         1.94       0.0122
     47   800       0.0284        0.028      0.00046        0.234         2.32       0.0327
     47   900       0.0174       0.0169     0.000501        0.195         2.54       0.0409
     47  1000       0.0328       0.0321     0.000664        0.233         3.77       0.0442
     47  1100       0.0278       0.0277     0.000117        0.245         2.82       0.0192
     47  1200       0.0228       0.0228     5.32e-05        0.201        0.576       0.0116
     47  1300       0.0162       0.0161     9.95e-05        0.182        0.761       0.0186
     47  1400       0.0135       0.0134     0.000128        0.153        0.808       0.0188
     47  1500       0.0372       0.0363     0.000891        0.287         2.56       0.0533
     47  1600       0.0141        0.014     7.66e-05        0.164        0.585       0.0153
     47  1601       0.0167       0.0167     1.42e-05        0.191        0.488      0.00716

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47   100       0.0183       0.0176     0.000624        0.197         1.97       0.0419
     47   200       0.0287       0.0286     0.000159         0.25         2.04       0.0231
     47   203       0.0237       0.0234     0.000249        0.226          1.4       0.0293


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              47 5443.004    0.003       0.0245     0.000368       0.0249        0.224         1.68       0.0281
! Validation         47 5443.004    0.003       0.0232     0.000328       0.0235        0.221         1.86       0.0273
Wall time: 5443.004860128043

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48   100       0.0191       0.0188     0.000293        0.185         1.26       0.0292
     48   200       0.0292       0.0292     5.15e-05        0.257         1.06       0.0113
     48   300       0.0187       0.0182     0.000574        0.204         2.32       0.0429
     48   400       0.0219       0.0218     7.64e-05        0.218        0.726       0.0151
     48   500       0.0339       0.0328      0.00116        0.271         8.67       0.0625
     48   600        0.013       0.0127      0.00025        0.148        0.959        0.021
     48   700       0.0373       0.0369     0.000412        0.281         2.04       0.0363
     48   800       0.0237       0.0234     0.000291        0.209         1.32       0.0287
     48   900        0.038        0.038     3.42e-05        0.282        0.953      0.00907
     48  1000       0.0311       0.0305     0.000552        0.259         2.39       0.0433
     48  1100       0.0252       0.0246     0.000595        0.233         3.25        0.045
     48  1200       0.0158       0.0156     0.000214        0.186         1.72       0.0275
     48  1300       0.0338       0.0337     0.000181        0.259         1.84       0.0212
     48  1400       0.0383       0.0382        8e-05        0.273        0.766       0.0147
     48  1500       0.0238        0.023     0.000798        0.222         3.19       0.0504
     48  1600        0.034       0.0338     0.000267        0.263         1.05       0.0222
     48  1601        0.047       0.0469     7.52e-05        0.309        0.587        0.012

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48   100       0.0186       0.0185     6.18e-05          0.2        0.413       0.0113
     48   200        0.026       0.0259     0.000115        0.237         1.11       0.0172
     48   203       0.0208       0.0205      0.00026        0.207          1.4       0.0291


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              48 5556.438    0.003       0.0234     0.000329       0.0238         0.22         1.63        0.027
! Validation         48 5556.438    0.003       0.0231     0.000223       0.0234         0.22         1.39       0.0235
Wall time: 5556.438650107011

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49   100       0.0181       0.0177      0.00041        0.186         1.66        0.036
     49   200       0.0363       0.0354     0.000869        0.265         3.78       0.0509
     49   300        0.019       0.0188     0.000178        0.186         1.01       0.0221
     49   400        0.037       0.0365       0.0005        0.285         2.53       0.0406
     49   500       0.0211       0.0209     0.000149        0.205        0.934       0.0224
     49   600       0.0241        0.024     5.92e-05        0.224        0.859       0.0118
     49   700       0.0255       0.0252     0.000238        0.231         1.31       0.0258
     49   800        0.023       0.0228     0.000141        0.226        0.892       0.0186
     49   900       0.0221        0.022     2.18e-05         0.22        0.378      0.00788
     49  1000       0.0219       0.0217     0.000113        0.213            1        0.017
     49  1100       0.0152       0.0148     0.000441        0.177         1.72       0.0338
     49  1200       0.0347       0.0339     0.000805        0.267         4.03       0.0546
     49  1300       0.0095      0.00856     0.000942        0.125         2.17       0.0582
     49  1400       0.0168       0.0167     4.81e-05        0.164        0.377       0.0124
     49  1500       0.0165       0.0161     0.000422        0.175         1.51       0.0362
     49  1600        0.037       0.0356      0.00138        0.279         9.73       0.0717
     49  1601       0.0391       0.0382     0.000851         0.28         2.71       0.0564

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49   100       0.0182       0.0181     0.000108        0.195        0.552       0.0153
     49   200       0.0298       0.0295     0.000295        0.252         2.23        0.033
     49   203       0.0202         0.02     0.000217        0.209         1.31       0.0273


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              49 5671.526    0.003       0.0246     0.000547       0.0251        0.225         1.78       0.0297
! Validation         49 5671.526    0.003       0.0241     0.000256       0.0244        0.225         1.63       0.0267
Wall time: 5671.526565507054

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50   100      0.00906      0.00837     0.000697        0.128         1.96       0.0499
     50   200       0.0239       0.0239     3.69e-05        0.233        0.754      0.00798
     50   300       0.0185       0.0177     0.000839        0.192         2.38       0.0547
     50   400       0.0252       0.0244     0.000796        0.206         3.49       0.0534
     50   500       0.0215        0.021     0.000497        0.195         1.09        0.031
     50   600       0.0171       0.0165     0.000615         0.19         2.06       0.0473
     50   700       0.0257       0.0255     0.000223        0.239         1.49       0.0275
     50   800       0.0121        0.012     0.000154        0.152        0.948       0.0211
     50   900       0.0153       0.0145     0.000822        0.176         2.25       0.0542
     50  1000       0.0243        0.024     0.000255        0.225         2.02       0.0279
     50  1100       0.0214       0.0213       0.0001        0.204        0.459        0.013
     50  1200       0.0253       0.0253     7.73e-05        0.226         1.33       0.0158
     50  1300       0.0129       0.0125     0.000445        0.164         1.56       0.0341
     50  1400       0.0221        0.021      0.00116        0.202         2.62       0.0637
     50  1500       0.0174        0.017     0.000454        0.182         1.68       0.0401
     50  1600       0.0104       0.0101     0.000318         0.15         1.37       0.0307
     50  1601       0.0245       0.0241     0.000411        0.204          1.5       0.0344

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50   100       0.0179       0.0178     0.000186        0.196         1.07       0.0238
     50   200       0.0249       0.0248     8.91e-05         0.23        0.591       0.0136
     50   203       0.0214       0.0214     4.68e-05        0.215        0.513       0.0107


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              50 5784.092    0.003       0.0244     0.000351       0.0248        0.226         1.68       0.0276
! Validation         50 5784.092    0.003       0.0217     0.000144       0.0219        0.213         1.05       0.0175
Wall time: 5784.092473129975

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     51   100       0.0215       0.0214     0.000115        0.208         1.07       0.0199
     51   200       0.0292        0.029     0.000155        0.257         1.72       0.0208
     51   300       0.0246       0.0246     1.79e-06        0.219        0.125      0.00209
     51   400       0.0384       0.0374      0.00106        0.274         4.26       0.0606
     51   500       0.0203       0.0203     1.79e-05        0.201        0.347      0.00784
     51   600       0.0218       0.0216     0.000115        0.201         1.22       0.0195
     51   700       0.0152       0.0131      0.00212        0.163         5.18       0.0886
     51   800       0.0346       0.0341     0.000495        0.267         4.09       0.0424
     51   900       0.0167       0.0162      0.00053        0.171         1.38       0.0409
     51  1000       0.0239       0.0238     0.000113        0.221        0.771       0.0161
     51  1100       0.0157       0.0154     0.000244        0.185         1.78       0.0297
     51  1200       0.0229       0.0226     0.000292        0.219         1.99       0.0315
     51  1300       0.0157       0.0154     0.000312        0.155         1.13        0.032
     51  1400       0.0492       0.0487     0.000424        0.329         2.55       0.0345
     51  1500       0.0305       0.0298      0.00066        0.258         2.33       0.0486
     51  1600       0.0415       0.0412     0.000307        0.284         1.82       0.0315
     51  1601       0.0392       0.0391     0.000147        0.272          1.7       0.0176

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     51   100       0.0193       0.0192      2.7e-05        0.208        0.295      0.00803
     51   200       0.0302       0.0301     7.05e-05        0.254         1.03        0.016
     51   203       0.0213       0.0212     0.000134        0.217         0.98       0.0204


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              51 5896.715    0.003       0.0256     0.000356       0.0259        0.229         1.67       0.0273
! Validation         51 5896.715    0.003       0.0254      0.00021       0.0256        0.232         1.34       0.0228
Wall time: 5896.7150862868875

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     52   100       0.0207       0.0206      3.8e-05        0.211        0.518       0.0102
     52   200       0.0262       0.0261     6.37e-05        0.236        0.652       0.0136
     52   300        0.024       0.0238     0.000158        0.227        0.958         0.02
     52   400       0.0411       0.0406     0.000427         0.27         1.85        0.037
     52   500       0.0179       0.0179     3.63e-05        0.199        0.591      0.00996
     52   600       0.0185       0.0184     7.06e-05        0.196        0.676       0.0156
     52   700       0.0091      0.00909     1.07e-05        0.136        0.275      0.00589
     52   800       0.0246       0.0245      0.00012        0.238         1.24       0.0179
     52   900       0.0161       0.0161     8.36e-06        0.173        0.165      0.00458
     52  1000       0.0233        0.023     0.000296        0.219         1.62       0.0318
     52  1100       0.0154        0.015     0.000447        0.168          2.2       0.0393
     52  1200       0.0368       0.0367     0.000113        0.256          1.2       0.0199
     52  1300       0.0174       0.0174      6.2e-05        0.188         0.49       0.0123
     52  1400        0.019       0.0187     0.000206        0.192         1.04       0.0258
     52  1500       0.0405       0.0405     7.66e-05         0.29         1.08       0.0145
     52  1600       0.0355       0.0354     0.000129        0.276         1.72       0.0172
     52  1601        0.035        0.035     6.72e-06        0.274        0.317      0.00475

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     52   100       0.0174       0.0173     0.000107        0.193        0.626       0.0164
     52   200       0.0248       0.0247     9.45e-05        0.229         1.06       0.0167
     52   203       0.0212       0.0211       0.0001        0.216        0.752       0.0157


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              52 6009.495    0.003       0.0245     0.000321       0.0249        0.223         1.61       0.0262
! Validation         52 6009.495    0.003       0.0213     0.000151       0.0215        0.211         1.09       0.0194
Wall time: 6009.495753546944

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     53   100       0.0296       0.0295     8.38e-05        0.238         1.21       0.0173
     53   200       0.0362       0.0361     0.000109         0.27         1.58       0.0185
     53   300       0.0206       0.0205     0.000104        0.209         0.85       0.0186
     53   400       0.0168       0.0167     8.63e-05        0.184        0.784       0.0173
     53   500        0.021        0.021     1.44e-05        0.217         0.48      0.00698
     53   600       0.0309       0.0308      0.00017        0.248         1.42       0.0229
     53   700       0.0203       0.0184      0.00192        0.193         3.45       0.0767
     53   800       0.0375       0.0373     0.000211        0.284         1.64       0.0256
     53   900       0.0272       0.0271     9.04e-05        0.234        0.892       0.0133
     53  1000       0.0126       0.0121     0.000494        0.155         1.16       0.0394
     53  1100       0.0297       0.0293     0.000401        0.236         2.25       0.0361
     53  1200       0.0301       0.0297     0.000392        0.256         2.87       0.0375
     53  1300       0.0175       0.0169     0.000569        0.175         5.99       0.0411
     53  1400       0.0182       0.0179     0.000313        0.201         2.05       0.0287
     53  1500       0.0208       0.0208     1.62e-05        0.208        0.332       0.0068
     53  1600       0.0311       0.0304     0.000736        0.245         4.24       0.0405
     53  1601       0.0203       0.0202     2.54e-05        0.208        0.287      0.00871

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     53   100       0.0183        0.018     0.000243        0.195        0.724       0.0209
     53   200       0.0266       0.0264     0.000199         0.24         1.23       0.0246
     53   203       0.0241        0.024     0.000128         0.23        0.924       0.0192


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              53 6123.481    0.003       0.0227     0.000322        0.023        0.217         1.61       0.0265
! Validation         53 6123.481    0.003       0.0224     0.000273       0.0227        0.216         1.44       0.0265
Wall time: 6123.481109264074

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     54   100        0.017       0.0169     9.76e-05        0.189        0.979       0.0163
     54   200       0.0204       0.0202     0.000218        0.201         2.11       0.0255
     54   300       0.0216       0.0215     2.84e-05        0.211         0.45       0.0072
     54   400       0.0267       0.0265     0.000156        0.243         1.08       0.0225
     54   500       0.0293       0.0291     0.000221        0.253         1.17       0.0275
     54   600       0.0252       0.0249     0.000307        0.225         2.59       0.0314
     54   700       0.0178       0.0173     0.000512        0.192         1.99       0.0415
     54   800       0.0187       0.0184     0.000295        0.188         1.08       0.0308
     54   900       0.0144       0.0143      5.6e-05         0.18         0.56       0.0112
     54  1000       0.0276       0.0274     0.000138        0.245        0.849       0.0177
     54  1100       0.0459       0.0452     0.000609        0.265         1.44       0.0412
     54  1200       0.0233       0.0231     0.000194        0.223         1.31       0.0248
     54  1300       0.0223       0.0198      0.00249        0.194          4.3        0.095
     54  1400      0.00676      0.00664     0.000113        0.111        0.693       0.0204
     54  1500       0.0367       0.0363     0.000358        0.279         1.97       0.0332
     54  1600       0.0175       0.0174     0.000106         0.19         1.19       0.0171
     54  1601       0.0221       0.0218     0.000244        0.217         2.89         0.03

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     54   100       0.0253       0.0208      0.00449        0.213         5.38        0.128
     54   200       0.0314       0.0272      0.00423        0.243         8.27        0.124
     54   203       0.0256       0.0218      0.00381        0.223         5.72        0.119


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              54 6235.455    0.003        0.026     0.000648       0.0266        0.227         1.91       0.0324
! Validation         54 6235.455    0.003       0.0255       0.0047       0.0302        0.232         7.48        0.129
Wall time: 6235.45570755098

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     55   100        0.025        0.025     3.14e-05        0.221         1.27       0.0106
     55   200        0.035       0.0342     0.000873        0.269         9.62        0.056
     55   300       0.0275       0.0273     0.000162        0.239         1.32       0.0168
     55   400      0.00718      0.00714     3.69e-05        0.103        0.316      0.00861
     55   500       0.0265       0.0263     0.000126        0.238         1.46       0.0204
     55   600       0.0352       0.0349     0.000238        0.254         1.75       0.0277
     55   700       0.0282       0.0281     6.38e-05        0.246        0.666       0.0139
     55   800       0.0171       0.0147      0.00242        0.184         4.51        0.094
     55   900       0.0212       0.0197      0.00153        0.208         4.55       0.0757
     55  1000       0.0264       0.0264     8.38e-05        0.231         1.27       0.0168
     55  1100       0.0306       0.0305     9.23e-05        0.255        0.677       0.0138
     55  1200       0.0222       0.0208       0.0014        0.215         2.93       0.0708
     55  1300       0.0404       0.0391      0.00131        0.293         6.34         0.07
     55  1400       0.0258       0.0257      0.00014        0.209         1.18       0.0221
     55  1500       0.0304       0.0304     8.65e-05        0.259        0.731       0.0162
     55  1600        0.046       0.0458     0.000275        0.307         1.21       0.0256
     55  1601       0.0118       0.0114     0.000431        0.161         3.03       0.0392

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     55   100       0.0193        0.019     0.000356        0.199         1.57       0.0337
     55   200       0.0274       0.0273     0.000145        0.241         1.92       0.0226
     55   203       0.0209       0.0208     0.000109        0.213        0.913        0.019


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              55 6350.218    0.003       0.0239     0.000355       0.0243        0.223         1.69       0.0278
! Validation         55 6350.218    0.003       0.0225     0.000232       0.0227        0.216         1.61       0.0241
Wall time: 6350.2185283228755

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     56   100       0.0403       0.0385      0.00184        0.229         5.03        0.049
     56   200       0.0208       0.0208     3.94e-05        0.207        0.392       0.0113
     56   300       0.0232       0.0232     1.27e-05        0.209        0.191      0.00419
     56   400        0.031       0.0309     0.000111        0.264         1.24       0.0158
     56   500       0.0176       0.0172     0.000353        0.186         4.26       0.0306
     56   600       0.0193       0.0188     0.000539        0.193         1.95       0.0444
     56   700        0.023       0.0222     0.000872        0.217         7.97       0.0555
     56   800       0.0249       0.0249      1.8e-05        0.229        0.273       0.0057
     56   900       0.0331       0.0317      0.00139        0.256         5.47       0.0545
     56  1000       0.0191       0.0191     3.53e-05        0.194         0.65         0.01
     56  1100       0.0105       0.0104     6.94e-05        0.151        0.777       0.0157
     56  1200       0.0339       0.0332      0.00074         0.26         4.59       0.0522
     56  1300       0.0395       0.0393     0.000143        0.273         3.55       0.0178
     56  1400       0.0219       0.0217     0.000274        0.206         1.26       0.0275
     56  1500       0.0338       0.0337     4.52e-05        0.264        0.728      0.00749
     56  1600       0.0188       0.0175       0.0013        0.185         2.34       0.0659
     56  1601       0.0149       0.0134      0.00148        0.172         2.07       0.0644

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     56   100       0.0175       0.0173     0.000141        0.191        0.995       0.0222
     56   200       0.0253       0.0253     4.92e-05        0.231        0.513       0.0105
     56   203       0.0193       0.0192     4.56e-05        0.209        0.492       0.0103


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              56 6467.293    0.003       0.0236     0.000371        0.024        0.221          1.6       0.0265
! Validation         56 6467.293    0.003       0.0212     0.000107       0.0213         0.21        0.912       0.0149
Wall time: 6467.2932904849295

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     57   100       0.0219       0.0217     0.000171        0.221         1.53       0.0213
     57   200        0.028       0.0275     0.000466        0.244         3.06       0.0346
     57   300       0.0232       0.0231     0.000144        0.201         1.41       0.0192
     57   400       0.0472       0.0472     6.17e-05        0.303        0.857        0.013
     57   500       0.0334       0.0334     7.26e-05        0.275         0.96       0.0127
     57   600       0.0262       0.0262     4.44e-05        0.232         0.54       0.0117
     57   700       0.0275       0.0274     6.82e-05        0.245        0.845       0.0145
     57   800       0.0165       0.0161      0.00038        0.192         1.86       0.0316
     57   900       0.0158       0.0137      0.00211        0.173         3.05       0.0857
     57  1000       0.0253       0.0248     0.000523        0.228         1.71       0.0402
     57  1100       0.0257       0.0256     0.000102        0.236        0.997       0.0163
     57  1200       0.0215       0.0213     0.000165        0.215         1.16       0.0242
     57  1300       0.0424       0.0418     0.000545        0.292         4.05       0.0399
     57  1400       0.0373       0.0372     5.57e-05        0.275        0.731       0.0116
     57  1500       0.0347       0.0342     0.000499        0.277         1.81       0.0377
     57  1600       0.0353       0.0348     0.000421        0.273         3.06       0.0356
     57  1601       0.0229       0.0226     0.000335        0.232         1.19        0.034

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     57   100       0.0216       0.0205       0.0011        0.205         2.33        0.059
     57   200       0.0301       0.0282      0.00189        0.252         6.11       0.0827
     57   203       0.0229       0.0217      0.00117        0.223         3.18       0.0663


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              57 6580.582    0.003       0.0243     0.000367       0.0247        0.225         1.74       0.0287
! Validation         57 6580.582    0.003       0.0245       0.0015        0.026        0.227         4.26       0.0719
Wall time: 6580.582791432971

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     58   100       0.0125       0.0124     0.000143        0.141        0.507       0.0178
     58   200        0.033       0.0324     0.000527         0.25         4.19       0.0318
     58   300       0.0444        0.044     0.000431        0.293         1.14       0.0315
     58   400       0.0262       0.0259     0.000263         0.23         2.35       0.0275
     58   500       0.0164       0.0157     0.000709        0.163         1.75       0.0488
     58   600       0.0288       0.0288     3.47e-05        0.254        0.702      0.00915
     58   700       0.0208       0.0206     0.000207        0.188         1.11       0.0258
     58   800       0.0206       0.0189      0.00167        0.197         5.18       0.0783
     58   900       0.0204       0.0199     0.000406        0.206         2.99       0.0367
     58  1000       0.0165       0.0163     0.000206        0.174        0.965       0.0239
     58  1100       0.0161       0.0159     0.000239        0.186         1.39       0.0258
     58  1200       0.0165       0.0164     7.63e-05        0.189        0.864       0.0161
     58  1300       0.0155       0.0153     0.000179        0.182        0.917        0.018
     58  1400       0.0162       0.0159     0.000281        0.181          1.4        0.031
     58  1500       0.0141        0.014     2.63e-05        0.171         0.53       0.0094
     58  1600       0.0216       0.0211     0.000542        0.207         2.54        0.041
     58  1601       0.0191       0.0191     1.46e-05        0.177        0.238      0.00693

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     58   100       0.0193       0.0193     1.59e-05        0.204        0.302      0.00642
     58   200       0.0255       0.0255     4.53e-05        0.233        0.685       0.0117
     58   203       0.0229       0.0229     7.81e-05        0.217        0.789       0.0164


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              58 6696.774    0.003       0.0232     0.000425       0.0237        0.219         1.62       0.0268
! Validation         58 6696.774    0.003       0.0231     0.000137       0.0233         0.22         1.05       0.0171
Wall time: 6696.773915503873

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     59   100       0.0287       0.0286     0.000106        0.243          1.6       0.0173
     59   200       0.0129       0.0121     0.000731        0.162         2.63       0.0506
     59   300       0.0189       0.0187     0.000158        0.206          1.2       0.0207
     59   400       0.0233       0.0232     0.000122        0.221        0.923       0.0192
     59   500       0.0314       0.0311     0.000273        0.247          1.6       0.0255
     59   600       0.0214       0.0208     0.000645        0.212         3.62        0.049
     59   700       0.0243        0.024     0.000247        0.224         2.65       0.0297
     59   800       0.0281       0.0277     0.000471         0.22          1.9       0.0399
     59   900       0.0202       0.0201     0.000107        0.217        0.806       0.0168
     59  1000       0.0355       0.0354     5.68e-05         0.28        0.874       0.0127
     59  1100        0.017       0.0169     0.000101        0.193         0.65       0.0167
     59  1200       0.0243       0.0239     0.000371        0.228         2.39       0.0358
     59  1300       0.0135       0.0132     0.000351        0.171         2.62       0.0353
     59  1400       0.0181        0.018     6.36e-05        0.206        0.773       0.0127
     59  1500       0.0527       0.0503      0.00238        0.279          5.6       0.0563
     59  1600       0.0294       0.0287     0.000665        0.245         2.84         0.04
     59  1601        0.018        0.018     7.33e-05        0.192         0.71       0.0148

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     59   100       0.0182        0.018     0.000178        0.197         1.11        0.025
     59   200       0.0237       0.0237     3.87e-05        0.226        0.721       0.0107
     59   203       0.0198       0.0198     4.04e-05        0.212        0.588       0.0123


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              59 6814.183    0.003       0.0234     0.000304       0.0237         0.22         1.61       0.0262
! Validation         59 6814.183    0.003        0.021     0.000104       0.0211        0.209         0.91       0.0144
Wall time: 6814.183081801981

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     60   100       0.0165        0.016     0.000516        0.187         2.46       0.0364
     60   200       0.0829       0.0798      0.00311        0.328         7.16       0.0858
     60   300       0.0297       0.0287     0.000987        0.231         5.94       0.0575
     60   400       0.0225       0.0225     7.49e-05        0.222         1.04       0.0159
     60   500       0.0217       0.0215     0.000211        0.214         1.14       0.0238
     60   600       0.0333       0.0316       0.0017        0.256         3.29       0.0779
     60   700       0.0123       0.0122     0.000129        0.161         1.04       0.0208
     60   800       0.0245       0.0233      0.00123        0.223         2.41       0.0591
     60   900       0.0268       0.0265     0.000224        0.234          1.2       0.0252
     60  1000       0.0182       0.0182     3.45e-05        0.192        0.399      0.00945
     60  1100       0.0201       0.0198     0.000222        0.207         1.63       0.0235
     60  1200       0.0166       0.0165     5.79e-05        0.174        0.518       0.0117
     60  1300       0.0238       0.0237      8.8e-05        0.216          1.1       0.0159
     60  1400       0.0357       0.0349     0.000751        0.264         2.28       0.0498
     60  1500       0.0256       0.0256     2.68e-05        0.239        0.427      0.00889
     60  1600        0.029       0.0288     0.000214        0.226          0.9       0.0249
     60  1601       0.0302       0.0302     2.21e-05        0.252        0.356      0.00742

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     60   100       0.0204       0.0203     9.94e-05         0.21         0.73       0.0172
     60   200        0.026        0.026     1.52e-05        0.238        0.662      0.00676
     60   203        0.024        0.024     3.38e-05        0.228         0.41      0.00853


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              60 6927.255    0.003       0.0249      0.00057       0.0255        0.227         1.91       0.0316
! Validation         60 6927.255    0.003       0.0249     0.000172        0.025        0.228         1.17         0.02
Wall time: 6927.255308124935

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     61   100       0.0165       0.0164     9.59e-05        0.196        0.613       0.0157
     61   200       0.0133       0.0133     3.91e-05        0.165        0.888       0.0103
     61   300        0.269        0.269     8.64e-05        0.347        0.912       0.0155
     61   400       0.0284       0.0283     0.000105        0.237        0.802       0.0176
     61   500       0.0247       0.0245     0.000229         0.23         1.75       0.0275
     61   600       0.0254       0.0251     0.000313         0.23         1.49       0.0311
     61   700       0.0172       0.0168     0.000467        0.188         1.96       0.0377
     61   800        0.025       0.0247     0.000283        0.235          1.5       0.0313
     61   900       0.0177       0.0175     0.000151        0.188        0.874       0.0195
     61  1000       0.0156       0.0155     0.000105        0.188        0.802       0.0167
     61  1100        0.019       0.0189     0.000151        0.198         1.02       0.0218
     61  1200       0.0259       0.0259     5.66e-05        0.231        0.984       0.0137
     61  1300       0.0295       0.0294     9.54e-05        0.246        0.995       0.0169
     61  1400       0.0148       0.0148     3.47e-05        0.169        0.618       0.0102
     61  1500       0.0174       0.0173     9.45e-05         0.18        0.443       0.0147
     61  1600       0.0198       0.0198     6.97e-05        0.207        0.918       0.0147
     61  1601       0.0356       0.0356      4.5e-05        0.274         2.02       0.0129

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     61   100       0.0186       0.0184     0.000261        0.198         1.25       0.0261
     61   200        0.027       0.0269     7.11e-05        0.241         1.05       0.0161
     61   203       0.0193       0.0192     0.000111        0.211        0.776       0.0162


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              61 7045.267    0.003        0.024     0.000329       0.0243        0.221         1.59       0.0262
! Validation         61 7045.267    0.003       0.0217     0.000184       0.0218        0.212         1.35       0.0207
Wall time: 7045.267494147876

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     62   100        0.014        0.014     6.75e-05        0.178         0.62       0.0129
     62   200       0.0149       0.0148      0.00014        0.161        0.884       0.0217
     62   300       0.0339        0.032      0.00192        0.227         4.87       0.0582
     62   400       0.0238       0.0235     0.000348        0.228         2.28       0.0332
     62   500       0.0422       0.0421     7.46e-05          0.3        0.652       0.0114
     62   600        0.021       0.0209     3.85e-05         0.21        0.345      0.00942
     62   700        0.027       0.0269     4.84e-05        0.234        0.977       0.0113
     62   800       0.0216       0.0213     0.000348        0.213         1.34       0.0333
     62   900      0.00981       0.0097     0.000109        0.135        0.627       0.0177
     62  1000      0.00929      0.00917     0.000121        0.126         1.08       0.0168
     62  1100       0.0236       0.0235     0.000106        0.225        0.667        0.014
     62  1200       0.0285       0.0284     0.000108        0.255        0.833       0.0174
     62  1300       0.0192       0.0192     2.78e-05        0.195        0.527        0.009
     62  1400       0.0167       0.0162     0.000462        0.189         2.16       0.0386
     62  1500      0.00874      0.00749      0.00125        0.121         1.78       0.0583
     62  1600       0.0298       0.0297      5.9e-05        0.244        0.434       0.0111
     62  1601       0.0225       0.0222     0.000314        0.217         1.31       0.0256

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     62   100       0.0177       0.0175     0.000227        0.194         1.25       0.0277
     62   200       0.0276       0.0275     5.88e-05        0.243         1.31      0.00919
     62   203       0.0215       0.0215     2.54e-05        0.219        0.439      0.00915


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              62 7164.693    0.003       0.0238     0.000315       0.0241        0.219         1.59        0.026
! Validation         62 7164.693    0.003        0.022     0.000172       0.0221        0.215         1.27       0.0178
Wall time: 7164.693500983063

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     63   100       0.0314       0.0301      0.00134        0.246         5.48       0.0683
     63   200       0.0258       0.0257     8.48e-05        0.232          1.5       0.0151
     63   300       0.0155       0.0154     5.61e-05        0.176        0.679       0.0113
     63   400       0.0251       0.0251     6.33e-05          0.2        0.509       0.0143
     63   500       0.0128        0.012     0.000807        0.142         1.53       0.0511
     63   600       0.0385       0.0381     0.000417         0.27         2.08       0.0343
     63   700       0.0222       0.0218     0.000339         0.21         1.86       0.0349
     63   800        0.018       0.0172      0.00084        0.175          1.6       0.0479
     63   900       0.0306       0.0303     0.000337        0.263         5.98       0.0317
     63  1000       0.0294       0.0291     0.000253        0.251         2.42       0.0275
     63  1100       0.0189       0.0186     0.000287          0.2         1.26       0.0315
     63  1200        0.019       0.0183     0.000636        0.189         1.98       0.0474
     63  1300       0.0215       0.0213     0.000157        0.209         1.39       0.0216
     63  1400       0.0225       0.0222     0.000237        0.216         4.95       0.0291
     63  1500       0.0314       0.0314     2.58e-05        0.251        0.481      0.00769
     63  1600       0.0236       0.0235      4.1e-05        0.225         0.55       0.0115
     63  1601        0.018       0.0179     3.77e-05          0.2        0.901       0.0112

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     63   100       0.0175       0.0174     0.000144        0.194        0.989       0.0216
     63   200       0.0254       0.0253     0.000128        0.232         0.98       0.0166
     63   203       0.0181       0.0181     5.29e-05        0.203        0.491       0.0102


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              63 7284.490    0.003       0.0223     0.000302       0.0227        0.215         1.56       0.0255
! Validation         63 7284.490    0.003       0.0208     0.000162        0.021        0.207         1.18        0.019
Wall time: 7284.490011607064

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     64   100       0.0117       0.0117        6e-06         0.15        0.195      0.00435
     64   200       0.0238       0.0231     0.000724        0.221         1.37       0.0425
     64   300       0.0216       0.0216     2.91e-05        0.211        0.849      0.00969
     64   400       0.0292       0.0282     0.000968        0.245         2.96       0.0564
     64   500       0.0382       0.0379     0.000282        0.269         1.92       0.0281
     64   600       0.0104       0.0102     0.000185        0.141         0.96       0.0248
     64   700       0.0139       0.0137     0.000186        0.162        0.889       0.0222
     64   800       0.0313       0.0313     4.28e-05        0.261        0.762       0.0096
     64   900       0.0264       0.0257     0.000644        0.233         2.14       0.0481
     64  1000       0.0325       0.0322     0.000255        0.235         1.78       0.0303
     64  1100       0.0329       0.0329     1.24e-05        0.275        0.246      0.00512
     64  1200       0.0304       0.0304     1.34e-05        0.259        0.753      0.00635
     64  1300       0.0176       0.0174     0.000158         0.19        0.937       0.0196
     64  1400        0.019       0.0187     0.000369        0.198         1.61       0.0297
     64  1500        0.032       0.0318     0.000234        0.257         2.76       0.0275
     64  1600       0.0131        0.013     0.000108        0.166         1.09       0.0188
     64  1601        0.033       0.0327     0.000283        0.269         8.71       0.0319

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     64   100       0.0171       0.0169     0.000239        0.189         1.26        0.027
     64   200       0.0252       0.0251     6.58e-05         0.23        0.908       0.0152
     64   203       0.0175       0.0174     4.94e-05          0.2        0.602       0.0125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              64 7400.804    0.003       0.0231      0.00041       0.0235        0.219         1.77       0.0292
! Validation         64 7400.804    0.003       0.0208     0.000123        0.021        0.207         1.04       0.0158
Wall time: 7400.804774696939

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     65   100       0.0212       0.0209     0.000348        0.209         2.41       0.0304
     65   200        0.021       0.0209     0.000139        0.194          1.1       0.0219
     65   300       0.0105       0.0103     0.000144        0.143        0.903        0.022
     65   400       0.0412       0.0411     0.000169        0.275         1.46       0.0231
     65   500      0.00816      0.00761      0.00055        0.125         1.71       0.0421
     65   600       0.0327       0.0319      0.00081        0.248         3.57       0.0548
     65   700       0.0189       0.0186     0.000335        0.198         1.79       0.0295
     65   800       0.0252        0.025     0.000111        0.215         1.55       0.0183
     65   900       0.0262       0.0261     6.05e-05        0.231        0.586       0.0123
     65  1000       0.0188       0.0186     0.000174        0.192         1.05       0.0245
     65  1100       0.0153       0.0153     5.87e-05        0.166        0.514       0.0141
     65  1200       0.0191        0.019     0.000186        0.205         1.56       0.0242
     65  1300       0.0367       0.0366     0.000127         0.28         1.75        0.021
     65  1400       0.0266       0.0262     0.000378        0.218         2.34       0.0291
     65  1500       0.0253       0.0248      0.00049        0.231         2.46       0.0369
     65  1600      0.00762      0.00752     9.88e-05        0.118        0.415       0.0129
     65  1601       0.0193       0.0192      0.00011        0.206         1.52       0.0179

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     65   100       0.0192       0.0186     0.000567        0.201         1.97       0.0447
     65   200       0.0262       0.0259     0.000331        0.237         2.13       0.0344
     65   203       0.0204       0.0201     0.000309         0.21         1.63       0.0339


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              65 7514.723    0.003       0.0226     0.000321       0.0229        0.216         1.59       0.0262
! Validation         65 7514.723    0.003       0.0218     0.000423       0.0222        0.213         2.25       0.0365
Wall time: 7514.722963572014

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     66   100       0.0276       0.0274      0.00022        0.233         2.05        0.028
     66   200        0.021       0.0208     0.000212        0.196         2.12       0.0256
     66   300       0.0284       0.0282     0.000166        0.235         1.38       0.0245
     66   400       0.0315       0.0312     0.000285        0.247         3.04        0.027
     66   500       0.0208       0.0205     0.000278        0.205         2.14       0.0316
     66   600       0.0195       0.0192     0.000352        0.196         1.56       0.0346
     66   700       0.0156       0.0156     7.61e-05         0.18        0.843       0.0152
     66   800       0.0152       0.0151      3.5e-05        0.162        0.435      0.00902
     66   900       0.0248       0.0248     3.44e-05        0.234        0.513       0.0107
     66  1000       0.0258       0.0258     4.06e-05         0.22        0.691       0.0107
     66  1100        0.017       0.0169     3.81e-05         0.19        0.505       0.0117
     66  1200       0.0231       0.0229     0.000217        0.218         1.79       0.0273
     66  1300       0.0282       0.0281     0.000131        0.245          1.2       0.0185
     66  1400       0.0354       0.0353     6.94e-05        0.261         1.34       0.0139
     66  1500       0.0207       0.0204     0.000327        0.196         1.13       0.0285
     66  1600       0.0242        0.024     0.000199        0.221         1.12       0.0266
     66  1601       0.0499       0.0498     0.000131        0.319         1.73        0.022

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     66   100       0.0204       0.0201     0.000345        0.205         1.51       0.0319
     66   200       0.0249       0.0247     0.000194        0.232         1.82       0.0266
     66   203       0.0209       0.0207     0.000213        0.214         1.35       0.0282


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              66 7632.488    0.003       0.0229     0.000351       0.0232        0.218         1.65       0.0274
! Validation         66 7632.488    0.003        0.022     0.000313       0.0223        0.214         1.89       0.0298
Wall time: 7632.487908978015

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     67   100      0.00871      0.00853     0.000182        0.128         0.98       0.0251
     67   200       0.0194       0.0194     2.96e-05        0.183        0.346      0.00724
     67   300       0.0171       0.0165     0.000572        0.182         2.43       0.0449
     67   400       0.0224       0.0223     7.89e-05        0.214          0.7        0.016
     67   500       0.0521       0.0472      0.00494        0.312         8.51       0.0892
     67   600       0.0224       0.0221     0.000287        0.189         1.22       0.0321
     67   700        0.011        0.011        8e-05        0.148         2.44       0.0152
     67   800       0.0172       0.0172     4.47e-05        0.192        0.767       0.0117
     67   900       0.0216       0.0207     0.000972        0.214          3.6       0.0597
     67  1000       0.0149       0.0135      0.00135        0.168         3.85        0.071
     67  1100       0.0159       0.0158     9.81e-05        0.177        0.856       0.0143
     67  1200       0.0107       0.0107     2.33e-05        0.139        0.273      0.00786
     67  1300        0.034       0.0339     0.000118        0.259         1.57       0.0176
     67  1400       0.0237       0.0237     2.65e-05        0.228        0.327      0.00704
     67  1500       0.0177       0.0173     0.000417        0.192         1.25       0.0331
     67  1600       0.0217       0.0216     0.000163        0.205         1.35       0.0204
     67  1601       0.0146       0.0145     0.000115        0.177         1.41       0.0207

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     67   100       0.0183       0.0183     3.76e-05        0.198        0.459      0.00959
     67   200       0.0236       0.0236     1.79e-05        0.225        0.264      0.00609
     67   203       0.0201       0.0201     1.72e-05        0.209        0.281      0.00586


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              67 7748.182    0.003        0.023     0.000341       0.0233        0.218         1.67       0.0273
! Validation         67 7748.182    0.003       0.0206     0.000118       0.0207        0.206        0.898       0.0147
Wall time: 7748.181862032041

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     68   100      0.00556      0.00552     4.45e-05        0.109        0.392       0.0109
     68   200       0.0111        0.011     0.000134        0.158         1.19       0.0201
     68   300       0.0244       0.0243     0.000168        0.233         1.21       0.0225
     68   400       0.0344       0.0341     0.000232        0.263         2.24       0.0288
     68   500       0.0209       0.0207     0.000146        0.208        0.719       0.0185
     68   600       0.0182        0.018     0.000176        0.195         1.44       0.0231
     68   700        0.027       0.0269     0.000123        0.246         1.24       0.0192
     68   800       0.0179       0.0169        0.001        0.182         2.78       0.0583
     68   900        0.036       0.0354     0.000543        0.256         2.49        0.044
     68  1000       0.0379       0.0349      0.00305        0.278         4.21        0.103
     68  1100       0.0231       0.0223     0.000839        0.219          3.1       0.0545
     68  1200       0.0342       0.0337     0.000447        0.271         1.73       0.0342
     68  1300       0.0222       0.0222     2.25e-05        0.204        0.171      0.00546
     68  1400       0.0338       0.0337     6.72e-05        0.268         1.34        0.015
     68  1500      0.00944      0.00928     0.000167        0.139        0.921       0.0225
     68  1600       0.0124       0.0122     0.000218        0.151        0.908       0.0265
     68  1601       0.0151        0.015     0.000115        0.174        0.496       0.0164

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     68   100       0.0177       0.0175     0.000161        0.194        0.548       0.0163
     68   200       0.0258       0.0256     0.000143        0.234         1.32       0.0219
     68   203       0.0191        0.019     0.000116        0.204         0.95       0.0198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              68 7864.303    0.003        0.023     0.000367       0.0233        0.217         1.68        0.028
! Validation         68 7864.303    0.003       0.0206     0.000192       0.0207        0.207         1.24       0.0218
Wall time: 7864.303295258898

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     69   100       0.0262       0.0261     0.000165        0.219         1.33       0.0244
     69   200       0.0157       0.0147      0.00107        0.163         2.72       0.0613
     69   300       0.0231       0.0213      0.00176        0.213         4.49       0.0808
     69   400       0.0164       0.0163     3.91e-05        0.183        0.647       0.0101
     69   500       0.0197       0.0192     0.000469        0.185         1.54         0.04
     69   600       0.0309       0.0309     7.14e-05         0.26        0.904       0.0137
     69   700       0.0404       0.0401     0.000256        0.285          2.2        0.024
     69   800       0.0215       0.0213      0.00026        0.199         1.79       0.0292
     69   900       0.0227       0.0223     0.000322        0.226         1.54        0.032
     69  1000       0.0143       0.0143     5.46e-05        0.164         1.94       0.0137
     69  1100       0.0261       0.0258      0.00031        0.238          1.5       0.0312
     69  1200       0.0215       0.0213     0.000118        0.208        0.876       0.0188
     69  1300       0.0326       0.0323     0.000285        0.249         1.83       0.0319
     69  1400       0.0144       0.0141     0.000284        0.166        0.972       0.0289
     69  1500       0.0089      0.00736      0.00154        0.123         3.48       0.0751
     69  1600       0.0206         0.02     0.000533         0.21         1.65       0.0378
     69  1601       0.0184       0.0183      3.9e-05        0.185        0.425       0.0118

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     69   100       0.0176       0.0174     0.000147        0.194        0.682       0.0185
     69   200       0.0252       0.0247     0.000422        0.231         3.01       0.0388
     69   203       0.0196       0.0194     0.000193        0.209         1.28       0.0266


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              69 7977.993    0.003       0.0249     0.000398       0.0253        0.224         1.66       0.0278
! Validation         69 7977.993    0.003        0.022     0.000321       0.0223        0.212         1.85       0.0311
Wall time: 7977.9933460189495

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     70   100       0.0487       0.0484      0.00026         0.31         1.84       0.0294
     70   200       0.0146       0.0144     0.000258        0.177         1.64       0.0279
     70   300       0.0217       0.0215     0.000182        0.211         1.82       0.0254
     70   400       0.0303       0.0302      0.00011        0.228         1.23       0.0184
     70   500       0.0311       0.0309     0.000202         0.26         1.07       0.0203
     70   600       0.0325       0.0325     2.93e-05        0.272        0.836       0.0101
     70   700       0.0277       0.0275     0.000178         0.24        0.917       0.0198
     70   800       0.0249        0.024     0.000864        0.217          5.2       0.0529
     70   900       0.0262       0.0241      0.00207        0.227            5       0.0856
     70  1000       0.0273       0.0273     4.45e-05        0.235        0.519       0.0108
     70  1100       0.0215       0.0211     0.000443        0.216         1.92       0.0399
     70  1200       0.0191        0.019     0.000123        0.204         1.39       0.0177
     70  1300       0.0185       0.0183     0.000167        0.202         1.05       0.0218
     70  1400       0.0215       0.0215     8.37e-05        0.214         1.26       0.0156
     70  1500       0.0246       0.0244     0.000133        0.227        0.949       0.0207
     70  1600       0.0188       0.0188     6.81e-05        0.195         1.76       0.0156
     70  1601       0.0287       0.0286     4.69e-05        0.254        0.527        0.011

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     70   100       0.0174       0.0173     5.78e-05         0.19        0.471       0.0123
     70   200       0.0234       0.0232     0.000108        0.223         1.56       0.0194
     70   203       0.0189       0.0188     0.000143        0.206         1.07       0.0223


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              70 8094.506    0.003       0.0228     0.000346       0.0232        0.217         1.68       0.0275
! Validation         70 8094.506    0.003       0.0208     0.000141        0.021        0.208         1.21       0.0194
Wall time: 8094.506265521981

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     71   100       0.0255       0.0254     0.000111        0.233        0.939       0.0196
     71   200       0.0162       0.0161     0.000108        0.177         0.68       0.0175
     71   300       0.0296       0.0296     2.44e-05         0.25         0.51      0.00892
     71   400       0.0275       0.0274     4.63e-05        0.239        0.603      0.00999
     71   500       0.0156       0.0156     2.84e-05         0.18        0.493         0.01
     71   600       0.0237       0.0236      8.6e-05         0.22        0.716       0.0162
     71   700        0.024       0.0238      0.00016        0.219        0.986       0.0204
     71   800       0.0189       0.0187     0.000141        0.196            2       0.0226
     71   900       0.0145       0.0137     0.000865        0.166         2.53       0.0559
     71  1000       0.0235       0.0232     0.000296        0.219         2.19       0.0306
     71  1100       0.0337       0.0337     4.94e-05        0.257        0.811       0.0133
     71  1200       0.0192       0.0189     0.000282        0.184         1.92       0.0307
     71  1300       0.0419       0.0418     0.000116        0.303          1.1       0.0162
     71  1400       0.0125       0.0118     0.000677         0.14         1.25       0.0428
     71  1500       0.0342        0.034     0.000286        0.276         1.86       0.0307
     71  1600       0.0142       0.0141     7.41e-05        0.177        0.938       0.0139
     71  1601       0.0403       0.0403     1.09e-06        0.287        0.158      0.00161

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     71   100       0.0195       0.0192     0.000386        0.205         1.54       0.0358
     71   200       0.0246       0.0244     0.000262        0.234         1.01       0.0232
     71   203       0.0186       0.0185     0.000114        0.207        0.927       0.0193


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              71 8210.619    0.003       0.0223     0.000343       0.0227        0.214         1.51        0.025
! Validation         71 8210.619    0.003       0.0217     0.000251       0.0219        0.213          1.4       0.0242
Wall time: 8210.619598268066

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     72   100       0.0233       0.0232      5.3e-05        0.217         1.29       0.0122
     72   200       0.0432       0.0424     0.000793        0.259         4.99       0.0516
     72   300       0.0275       0.0274     4.15e-05        0.237        0.849      0.00979
     72   400       0.0247       0.0245     0.000256        0.234         1.36       0.0265
     72   500       0.0187       0.0182     0.000465        0.198         1.69       0.0403
     72   600       0.0112        0.011     0.000196        0.149         1.02       0.0244
     72   700       0.0148       0.0145     0.000299        0.168        0.943       0.0211
     72   800       0.0119       0.0111     0.000834        0.146          1.5       0.0471
     72   900       0.0237       0.0233     0.000416        0.225         1.53       0.0365
     72  1000       0.0119       0.0114     0.000508        0.152          1.4       0.0362
     72  1100        0.022       0.0219      0.00012        0.202         1.06       0.0211
     72  1200        0.013       0.0115       0.0015         0.15         3.05       0.0691
     72  1300        0.034       0.0333     0.000714        0.267         2.77       0.0442
     72  1400        0.025       0.0243     0.000723        0.214         1.75       0.0499
     72  1500       0.0339       0.0332     0.000732        0.271         3.72         0.05
     72  1600       0.0141        0.014     0.000113        0.162        0.762       0.0173
     72  1601       0.0449       0.0444     0.000504        0.283         3.01       0.0433

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     72   100       0.0172       0.0172     5.81e-05        0.191        0.547        0.013
     72   200       0.0246       0.0243     0.000246        0.229          2.5       0.0297
     72   203       0.0176       0.0173     0.000225        0.196         1.33       0.0276


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              72 8322.586    0.003       0.0235     0.000352       0.0238         0.22         1.65       0.0277
! Validation         72 8322.586    0.003       0.0206     0.000213       0.0208        0.207         1.57       0.0243
Wall time: 8322.586114339996

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     73   100       0.0262       0.0262     2.86e-05        0.212        0.633      0.00909
     73   200       0.0281       0.0279     0.000157        0.227         1.77       0.0197
     73   300       0.0493       0.0477      0.00165        0.284         5.74       0.0668
     73   400       0.0227       0.0226     0.000114        0.215         1.09       0.0183
     73   500       0.0327       0.0318     0.000913        0.247         3.25       0.0582
     73   600       0.0267       0.0266     0.000113         0.23        0.704       0.0173
     73   700       0.0293       0.0291     0.000211        0.236         1.54       0.0247
     73   800        0.022       0.0218     0.000173         0.22         1.03       0.0215
     73   900        0.026       0.0259      0.00011         0.21        0.771       0.0149
     73  1000       0.0217       0.0206      0.00111        0.198         3.47        0.064
     73  1100       0.0398       0.0394     0.000429        0.287         2.51       0.0337
     73  1200       0.0198       0.0198     5.02e-05          0.2        0.543       0.0129
     73  1300       0.0299       0.0298     0.000104        0.259         2.01       0.0181
     73  1400       0.0259       0.0258     4.66e-05        0.241        0.804       0.0132
     73  1500       0.0161        0.016     0.000153        0.186         1.04        0.021
     73  1600       0.0148       0.0143     0.000482        0.177         2.27       0.0402
     73  1601      0.00806      0.00782     0.000239        0.122         1.16       0.0275

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     73   100       0.0193       0.0176      0.00169        0.194         3.14       0.0769
     73   200       0.0269       0.0246      0.00234        0.231         6.95       0.0933
     73   203       0.0227       0.0208      0.00193        0.211         4.07       0.0848


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              73 8436.443    0.003       0.0229     0.000468       0.0233        0.217         1.88       0.0313
! Validation         73 8436.443    0.003       0.0213      0.00219       0.0234         0.21         5.21       0.0888
Wall time: 8436.443760144059

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     74   100       0.0163        0.016     0.000339        0.182         1.42       0.0343
     74   200        0.022       0.0218     0.000177        0.208         1.01       0.0236
     74   300       0.0245       0.0242     0.000271        0.233         3.96       0.0304
     74   400       0.0237       0.0237     1.01e-05        0.211        0.325      0.00606
     74   500       0.0303       0.0301     0.000119        0.241         1.35       0.0203
     74   600         0.03       0.0298     0.000284         0.25         2.58       0.0301
     74   700       0.0146       0.0143     0.000281         0.17         1.82       0.0299
     74   800       0.0348       0.0348     9.37e-06        0.247        0.225      0.00522
     74   900        0.016       0.0151      0.00092         0.18         1.86       0.0537
     74  1000       0.0226        0.022     0.000574        0.221         2.49       0.0372
     74  1100       0.0174       0.0168     0.000695        0.174         1.99       0.0503
     74  1200       0.0222        0.022     0.000212        0.224         1.04       0.0216
     74  1300       0.0268       0.0261      0.00078        0.241         3.44       0.0522
     74  1400       0.0302         0.03     0.000179        0.244         1.48       0.0232
     74  1500       0.0117       0.0105      0.00118        0.136         2.17       0.0662
     74  1600       0.0576       0.0574     0.000178        0.309         1.67       0.0213
     74  1601       0.0194       0.0194     6.41e-05        0.211        0.677       0.0141

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     74   100       0.0215       0.0213     0.000238        0.208         1.21       0.0285
     74   200       0.0275       0.0274     0.000136        0.243        0.421       0.0134
     74   203       0.0198       0.0198     1.25e-05         0.21        0.322      0.00672


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              74 8550.447    0.003        0.024     0.000454       0.0244         0.22         1.74       0.0284
! Validation         74 8550.447    0.003       0.0274     0.000228       0.0276        0.235         1.23       0.0214
Wall time: 8550.447110764915

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     75   100       0.0366       0.0365     5.81e-05        0.272          0.8       0.0119
     75   200       0.0364       0.0363     8.91e-05        0.275         1.27       0.0161
     75   300       0.0314       0.0311     0.000333        0.254         1.69       0.0317
     75   400       0.0292       0.0287     0.000443        0.249         2.45       0.0405
     75   500       0.0209       0.0209      3.8e-05        0.196        0.312      0.00933
     75   600       0.0262       0.0261     8.79e-05        0.235        0.952       0.0155
     75   700       0.0109       0.0109     3.57e-05        0.151         0.43       0.0105
     75   800       0.0277       0.0276     8.53e-05        0.226         1.04       0.0136
     75   900        0.024       0.0239     0.000138         0.22        0.953       0.0198
     75  1000       0.0346       0.0345     7.37e-05        0.265         1.51       0.0157
     75  1100       0.0118       0.0116     0.000149         0.13        0.571       0.0196
     75  1200       0.0167       0.0166      6.7e-05        0.188        0.678       0.0154
     75  1300       0.0175       0.0175     1.48e-05        0.195        0.521      0.00707
     75  1400       0.0238       0.0238     7.05e-05         0.23        0.746       0.0155
     75  1500       0.0157       0.0155     0.000129        0.178        0.838       0.0201
     75  1600       0.0274       0.0265     0.000917        0.239         4.22       0.0559
     75  1601       0.0636       0.0526       0.0111        0.343         9.48        0.198

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     75   100       0.0174       0.0173     8.16e-05        0.193        0.748       0.0171
     75   200       0.0249       0.0249     4.22e-05         0.23        0.611      0.00919
     75   203       0.0185       0.0185     2.71e-05        0.205        0.414      0.00862


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              75 8662.470    0.003       0.0232     0.000269       0.0234        0.219         1.42       0.0236
! Validation         75 8662.470    0.003       0.0211     9.97e-05       0.0212        0.209        0.872       0.0139
Wall time: 8662.470720499055

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     76   100       0.0284       0.0283     3.88e-05        0.234        0.718       0.0104
     76   200       0.0287       0.0285     0.000189        0.249         1.39       0.0233
     76   300       0.0155       0.0152     0.000283        0.162         1.02       0.0298
     76   400      0.00729      0.00625      0.00104        0.115         2.25       0.0614
     76   500       0.0272        0.027     0.000222        0.243          1.8        0.027
     76   600       0.0206       0.0202      0.00039        0.195         1.55       0.0322
     76   700       0.0242       0.0241       0.0001        0.201         0.75       0.0165
     76   800        0.024       0.0238     0.000206        0.224         1.33       0.0252
     76   900       0.0259       0.0255     0.000352        0.241         1.66       0.0328
     76  1000       0.0153       0.0152     5.47e-05        0.181        0.533       0.0127
     76  1100       0.0153       0.0151     0.000116        0.178        0.798       0.0174
     76  1200       0.0265       0.0263     0.000224        0.244         1.23       0.0256
     76  1300       0.0137       0.0135     0.000182        0.165         1.45       0.0216
     76  1400       0.0127       0.0125      0.00014        0.155        0.868       0.0215
     76  1500       0.0166       0.0165     0.000162        0.188        0.966       0.0201
     76  1600       0.0146       0.0146     3.72e-05        0.169        0.435       0.0102
     76  1601       0.0241       0.0239     0.000157        0.228         1.16       0.0241

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     76   100       0.0175       0.0174     0.000125        0.192        0.774       0.0161
     76   200       0.0243       0.0243      8.5e-06         0.23        0.255      0.00415
     76   203       0.0215       0.0215     1.63e-05         0.22        0.279      0.00581


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              76 8776.048    0.003       0.0224      0.00034       0.0228        0.215         1.63       0.0269
! Validation         76 8776.048    0.003       0.0214     0.000136       0.0215        0.211         1.06       0.0165
Wall time: 8776.04805685603

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     77   100       0.0279       0.0272     0.000634        0.218         2.79       0.0349
     77   200       0.0168       0.0167     7.02e-05         0.19        0.988       0.0134
     77   300       0.0229       0.0225     0.000437        0.223         2.21       0.0292
     77   400       0.0122       0.0122     3.31e-05        0.158        0.674      0.00918
     77   500       0.0372       0.0371     0.000138        0.284         1.26       0.0207
     77   600       0.0294       0.0292     0.000219        0.236         1.76       0.0273
     77   700       0.0309       0.0306     0.000295        0.251         2.57        0.032
     77   800      0.00919       0.0091     8.81e-05        0.111         0.55       0.0159
     77   900       0.0331       0.0324     0.000749        0.257         3.76       0.0506
     77  1000       0.0449       0.0447     0.000166         0.28         1.48       0.0156
     77  1100       0.0216       0.0215     8.63e-05        0.213         0.78       0.0162
     77  1200       0.0178       0.0174     0.000462        0.178         1.27       0.0379
     77  1300       0.0434       0.0432     0.000231        0.213         1.67       0.0231
     77  1400       0.0214       0.0213     0.000123        0.213         1.68       0.0159
     77  1500       0.0185       0.0183      0.00018        0.201         1.18       0.0246
     77  1600       0.0301         0.03     3.01e-05        0.217        0.553      0.00936
     77  1601       0.0214       0.0214     4.88e-05        0.207         1.29       0.0126

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     77   100       0.0182        0.018     0.000218          0.2         1.18       0.0262
     77   200       0.0246       0.0246     2.71e-05        0.232        0.633      0.00982
     77   203       0.0222       0.0221     0.000101        0.225        0.765       0.0159


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              77 8890.448    0.003       0.0219     0.000283       0.0221        0.213         1.51       0.0249
! Validation         77 8890.448    0.003       0.0213     0.000139       0.0214        0.211         1.06       0.0174
Wall time: 8890.448593941983

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     78   100        0.029       0.0286     0.000451        0.259         2.47       0.0407
     78   200       0.0217       0.0205      0.00122        0.203         3.58       0.0651
     78   300       0.0248       0.0247     1.74e-05         0.22        0.355      0.00722
     78   400       0.0264       0.0263     9.94e-05        0.225         1.02       0.0173
     78   500       0.0201       0.0198     0.000344        0.207         1.67       0.0347
     78   600      0.00993      0.00992     1.52e-05        0.145        0.223      0.00585
     78   700       0.0294       0.0285     0.000945        0.249         7.43       0.0588
     78   800       0.0194       0.0189     0.000478          0.2          2.8       0.0407
     78   900       0.0238       0.0237     0.000151        0.232         1.28       0.0218
     78  1000       0.0192       0.0191     9.07e-05        0.199         1.19       0.0181
     78  1100        0.011        0.011     4.91e-05        0.137        0.486       0.0113
     78  1200       0.0276       0.0275     5.85e-05        0.221         1.28        0.014
     78  1300       0.0285       0.0285     1.73e-05        0.229        0.335      0.00737
     78  1400       0.0149       0.0143     0.000609        0.167         2.68       0.0476
     78  1500       0.0129       0.0126     0.000285        0.167         2.04       0.0251
     78  1600       0.0282       0.0281     7.85e-05        0.249        0.737       0.0154
     78  1601        0.032        0.032     4.03e-05        0.225         1.11       0.0113

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     78   100       0.0179       0.0176     0.000307        0.195         1.42       0.0309
     78   200       0.0255       0.0254     0.000101        0.234         1.26       0.0191
     78   203       0.0202       0.0201     9.64e-05         0.21        0.889       0.0185


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              78 9003.594    0.003       0.0226     0.000315        0.023        0.215         1.58       0.0258
! Validation         78 9003.594    0.003       0.0208     0.000206        0.021        0.208         1.43       0.0221
Wall time: 9003.594642698066

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     79   100       0.0209       0.0208     6.55e-05        0.204         1.13       0.0127
     79   200       0.0146       0.0145     8.35e-05        0.156        0.607        0.014
     79   300       0.0173       0.0169     0.000376         0.18         2.12       0.0255
     79   400        0.021       0.0209     8.48e-05        0.182        0.426       0.0129
     79   500       0.0202       0.0201     5.38e-05        0.196        0.511       0.0115
     79   600       0.0353       0.0353     1.84e-05        0.271        0.558      0.00709
     79   700       0.0353       0.0352     6.97e-05        0.265         1.31       0.0137
     79   800        0.015       0.0148     0.000222        0.155         1.12        0.028
     79   900       0.0168       0.0166     0.000183        0.176         1.43       0.0206
     79  1000       0.0231       0.0229     0.000179        0.197          1.5       0.0237
     79  1100       0.0241        0.024     3.95e-05        0.225        0.774       0.0115
     79  1200       0.0137       0.0136     7.77e-05        0.166        0.574       0.0161
     79  1300       0.0332       0.0328     0.000361        0.268         2.91       0.0321
     79  1400       0.0135       0.0127     0.000742        0.165         3.63       0.0518
     79  1500      0.00871      0.00865     5.91e-05        0.129        0.453       0.0126
     79  1600        0.019       0.0188     0.000231        0.194         1.52       0.0288
     79  1601      0.00252      0.00164     0.000875       0.0606          1.6       0.0571

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     79   100       0.0166       0.0166      2.8e-05        0.188        0.344       0.0084
     79   200       0.0234       0.0234     6.24e-05        0.225         1.25        0.014
     79   203       0.0185       0.0184     5.21e-05        0.204        0.654       0.0136


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              79 9117.469   0.0015       0.0203     0.000164       0.0205        0.205         1.14       0.0185
! Validation         79 9117.469   0.0015       0.0197     7.27e-05       0.0198        0.202        0.772       0.0118
Wall time: 9117.469159638975

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     80   100       0.0215       0.0211     0.000423        0.199         1.53       0.0379
     80   200        0.031       0.0309     9.85e-05        0.247        0.954       0.0171
     80   300       0.0197       0.0192     0.000484        0.199         2.45       0.0389
     80   400       0.0144       0.0139     0.000525        0.165         1.96       0.0403
     80   500       0.0145       0.0141     0.000389        0.163         1.95       0.0366
     80   600       0.0303       0.0302     6.33e-05        0.239        0.705        0.014
     80   700      0.00914      0.00897     0.000166        0.137         1.18       0.0242
     80   800      0.00945      0.00936     8.94e-05        0.133         1.45       0.0142
     80   900       0.0176       0.0174     0.000244        0.187         1.23       0.0294
     80  1000       0.0235       0.0233     0.000173        0.219        0.909       0.0222
     80  1100       0.0278       0.0277     6.88e-05        0.239        0.849       0.0152
     80  1200      0.00823      0.00795     0.000279        0.113         1.07       0.0322
     80  1300       0.0182        0.018     0.000115        0.194        0.787       0.0193
     80  1400       0.0153       0.0153     2.79e-05        0.158        0.444       0.0073
     80  1500        0.016       0.0157     0.000294        0.175          1.4       0.0322
     80  1600       0.0241        0.024     3.81e-05        0.225        0.594      0.00999
     80  1601       0.0352       0.0351     7.72e-05        0.237         1.71       0.0167

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     80   100       0.0167       0.0166     0.000152        0.185         0.75       0.0197
     80   200       0.0227       0.0224     0.000242         0.22         2.18         0.03
     80   203       0.0187       0.0185     0.000231        0.202         1.39        0.029


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              80 9232.756   0.0015       0.0205     0.000195       0.0207        0.205         1.25       0.0203
! Validation         80 9232.756   0.0015       0.0198      0.00027       0.0201        0.201         1.67       0.0289
Wall time: 9232.756531069987

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     81   100       0.0332        0.033     0.000171        0.253         1.26       0.0213
     81   200       0.0176       0.0175     9.67e-05        0.198        0.692       0.0144
     81   300      0.00986      0.00975     0.000108        0.136        0.498       0.0162
     81   400       0.0261       0.0259     0.000191        0.238         1.17       0.0245
     81   500       0.0245       0.0244     5.44e-05         0.22          0.7       0.0137
     81   600       0.0245       0.0242     0.000224        0.231         1.71       0.0261
     81   700       0.0164       0.0164     6.79e-05        0.153        0.347       0.0112
     81   800       0.0175       0.0173     0.000192        0.183         1.01       0.0233
     81   900      0.00897      0.00872     0.000255        0.129         1.44       0.0306
     81  1000       0.0139       0.0139     1.52e-05        0.162        0.182      0.00576
     81  1100       0.0275       0.0274     4.77e-05        0.246        0.464      0.00967
     81  1200       0.0175       0.0174     7.11e-05        0.189        0.644       0.0134
     81  1300       0.0247       0.0246     9.53e-05        0.206         1.09       0.0164
     81  1400       0.0223       0.0221     0.000168        0.219         0.89       0.0221
     81  1500       0.0231       0.0226     0.000498        0.208         1.78       0.0407
     81  1600       0.0318       0.0317     9.15e-05         0.26         1.34       0.0177
     81  1601       0.0207       0.0206     3.94e-05        0.212         1.27       0.0105

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     81   100       0.0165       0.0163     0.000163        0.186        0.998       0.0209
     81   200       0.0222       0.0222      2.3e-05        0.217         0.45      0.00772
     81   203       0.0181       0.0181     2.67e-05          0.2        0.428      0.00892


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              81 9345.868   0.0015       0.0203     0.000167       0.0205        0.205         1.14       0.0183
! Validation         81 9345.868   0.0015       0.0195     9.43e-05       0.0196          0.2        0.896       0.0133
Wall time: 9345.868105328875

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     82   100       0.0181        0.018      0.00011         0.18        0.848       0.0186
     82   200       0.0201       0.0198     0.000288        0.203         2.38       0.0325
     82   300       0.0131       0.0131     6.68e-05        0.165        0.896       0.0155
     82   400       0.0181       0.0177     0.000388          0.2          2.3       0.0379
     82   500       0.0163       0.0163     6.67e-05        0.181        0.613       0.0116
     82   600       0.0218       0.0216     0.000148        0.219         1.33       0.0221
     82   700       0.0312       0.0312     2.98e-06        0.264        0.236      0.00309
     82   800       0.0111       0.0109     0.000141        0.156         1.04       0.0217
     82   900       0.0205       0.0204     7.07e-05        0.208         1.38       0.0142
     82  1000       0.0208       0.0207     6.24e-05        0.207         1.14       0.0144
     82  1100       0.0211       0.0209     0.000223         0.21         1.59       0.0183
     82  1200       0.0489       0.0488     6.81e-05        0.328         1.14       0.0139
     82  1300       0.0311       0.0311     3.97e-05        0.254        0.942      0.00957
     82  1400       0.0187        0.018     0.000628        0.191         2.01       0.0466
     82  1500       0.0207       0.0204     0.000238        0.191         1.08        0.029
     82  1600       0.0158       0.0157     4.68e-05        0.177        0.718       0.0124
     82  1601       0.0161       0.0161     2.23e-05        0.171        0.479      0.00888

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     82   100       0.0167       0.0165     0.000161        0.186        0.816       0.0206
     82   200       0.0244       0.0243     8.44e-05        0.229        0.795       0.0132
     82   203       0.0191       0.0191     1.64e-05        0.206        0.369      0.00768


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              82 9460.689   0.0015       0.0204     0.000188       0.0206        0.205         1.23       0.0202
! Validation         82 9460.689   0.0015       0.0201      0.00014       0.0203        0.204         1.01       0.0181
Wall time: 9460.689388789935

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     83   100       0.0193        0.019     0.000316        0.186         1.43       0.0323
     83   200       0.0287       0.0283     0.000355        0.238         2.09       0.0338
     83   300        0.014       0.0139     6.73e-05        0.175        0.952       0.0154
     83   400       0.0115       0.0113     0.000211        0.151          1.7       0.0269
     83   500       0.0216       0.0215     0.000104        0.207         1.02       0.0188
     83   600       0.0195       0.0194        5e-05        0.203        0.924       0.0125
     83   700       0.0215       0.0215     1.85e-05        0.213        0.856       0.0062
     83   800       0.0244       0.0244     1.93e-05        0.226        0.363      0.00682
     83   900       0.0168       0.0168     4.67e-05        0.185        0.769      0.00867
     83  1000       0.0249       0.0248     4.65e-05        0.224        0.411       0.0104
     83  1100       0.0172       0.0168     0.000381        0.176         1.87       0.0348
     83  1200       0.0188       0.0187     5.73e-05          0.2        0.608       0.0135
     83  1300       0.0133       0.0132     8.51e-05        0.163         0.54       0.0152
     83  1400       0.0286       0.0285     7.98e-05        0.238         1.12        0.014
     83  1500       0.0226       0.0225     6.78e-05        0.216        0.983        0.014
     83  1600        0.018       0.0179     0.000107        0.192        0.871       0.0191
     83  1601       0.0379       0.0377     0.000194        0.291         2.19       0.0243

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     83   100        0.016       0.0159     9.11e-05        0.183        0.741       0.0157
     83   200       0.0234       0.0234     2.93e-06        0.223        0.268      0.00326
     83   203       0.0176       0.0176     1.26e-05        0.198        0.271      0.00566


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              83 9574.247   0.0015       0.0203     0.000195       0.0205        0.205         1.24       0.0202
! Validation         83 9574.247   0.0015       0.0198      7.9e-05       0.0198        0.202        0.764       0.0112
Wall time: 9574.247303366894

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     84   100       0.0195       0.0193      0.00025        0.199          1.3       0.0294
     84   200       0.0143       0.0141     0.000175        0.162        0.804       0.0232
     84   300       0.0113       0.0112     9.84e-05        0.131        0.439       0.0141
     84   400       0.0133        0.013     0.000267        0.155          1.3       0.0288
     84   500      0.00703      0.00701     1.51e-05        0.123        0.297      0.00691
     84   600       0.0205       0.0204     0.000156        0.198        0.898        0.019
     84   700       0.0138       0.0136     0.000153        0.149         1.75       0.0189
     84   800       0.0235       0.0235     5.87e-05        0.217        0.684        0.013
     84   900       0.0186       0.0185     0.000131        0.175         1.33       0.0193
     84  1000        0.021       0.0209     0.000102        0.205         1.01       0.0187
     84  1100       0.0142       0.0142     8.22e-05        0.173        0.648       0.0139
     84  1200        0.028       0.0278     0.000201        0.245         1.02        0.022
     84  1300       0.0134       0.0132      0.00017        0.161         1.33       0.0247
     84  1400       0.0191       0.0191     1.27e-05        0.184        0.194      0.00428
     84  1500       0.0137       0.0136     9.79e-05        0.172         0.73       0.0139
     84  1600       0.0216       0.0215     0.000113         0.21        0.928       0.0171
     84  1601       0.0191       0.0189      0.00021        0.201         1.26       0.0263

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     84   100       0.0169       0.0164     0.000491        0.185         1.85       0.0415
     84   200       0.0241       0.0238     0.000269        0.226         2.12       0.0312
     84   203       0.0185       0.0183     0.000173        0.201         1.22       0.0254


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              84 9690.918   0.0015       0.0201     0.000162       0.0203        0.204         1.13       0.0182
! Validation         84 9690.918   0.0015       0.0196     0.000411         0.02        0.201         2.16       0.0356
Wall time: 9690.918856651057

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     85   100       0.0144       0.0143     5.85e-05        0.171        0.583        0.014
     85   200       0.0298       0.0297     9.62e-05        0.256         1.42       0.0163
     85   300       0.0372        0.035      0.00218        0.272         4.95       0.0526
     85   400       0.0251       0.0245     0.000557         0.22         1.74       0.0427
     85   500       0.0164       0.0164     9.58e-06        0.181        0.221      0.00518
     85   600       0.0226       0.0226     4.68e-05        0.223         1.78       0.0115
     85   700       0.0195       0.0193     0.000159        0.187         0.85        0.021
     85   800       0.0396       0.0386     0.000996        0.275         1.83       0.0382
     85   900       0.0191        0.019     0.000103        0.192        0.999       0.0186
     85  1000       0.0192       0.0191     7.59e-05        0.197        0.687       0.0153
     85  1100       0.0139       0.0137     0.000136        0.162        0.801        0.017
     85  1200       0.0104       0.0102     0.000216        0.136         0.54       0.0171
     85  1300       0.0156       0.0154     0.000199        0.159        0.945       0.0256
     85  1400       0.0276       0.0274     0.000128        0.241         1.57       0.0213
     85  1500       0.0143       0.0142     2.08e-05        0.173          0.5      0.00828
     85  1600        0.031       0.0309     7.37e-05        0.257        0.957       0.0156
     85  1601       0.0166       0.0165     0.000108        0.173        0.598        0.018

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     85   100       0.0161        0.016     0.000158        0.182        0.995       0.0217
     85   200        0.023       0.0229      3.6e-05        0.222        0.533       0.0105
     85   203       0.0172       0.0171     4.34e-05        0.193        0.581       0.0121


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              85 9807.242   0.0015       0.0198     0.000156         0.02        0.203         1.11        0.018
! Validation         85 9807.242   0.0015       0.0195     0.000108       0.0196          0.2        0.982       0.0153
Wall time: 9807.242790977936

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     86   100       0.0216       0.0213     0.000234        0.208        0.837       0.0204
     86   200       0.0173       0.0173     4.02e-06        0.181        0.117      0.00293
     86   300       0.0201       0.0201      4.8e-05        0.203        0.791       0.0129
     86   400      0.00535      0.00527     7.94e-05        0.106        0.458       0.0157
     86   500       0.0108       0.0108     6.34e-05        0.143        0.558       0.0134
     86   600       0.0157       0.0157     3.89e-05        0.179        0.645       0.0118
     86   700       0.0131       0.0131     6.64e-05        0.171        0.633       0.0132
     86   800       0.0187       0.0184     0.000295        0.204         1.71       0.0295
     86   900       0.0101      0.00998      0.00011        0.133        0.624       0.0188
     86  1000       0.0127       0.0126     8.04e-05        0.153        0.668       0.0164
     86  1100       0.0191        0.019     2.82e-05        0.189         1.34      0.00889
     86  1200       0.0252        0.025     0.000148        0.232         2.91       0.0233
     86  1300       0.0132       0.0132     7.17e-05        0.167        0.669       0.0149
     86  1400       0.0154       0.0152     0.000183        0.162        0.958       0.0254
     86  1500       0.0333       0.0333     2.32e-05        0.262        0.471      0.00858
     86  1600       0.0123       0.0121     0.000123         0.15        0.798       0.0185
     86  1601      0.00168      0.00162     6.03e-05       0.0596        0.419        0.015

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     86   100       0.0164       0.0164      4.2e-05        0.187        0.449       0.0114
     86   200       0.0223       0.0222     0.000133        0.218         1.88       0.0202
     86   203       0.0182       0.0182     8.58e-05        0.199        0.822       0.0171


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              86 9917.786   0.0015       0.0201     0.000187       0.0203        0.204         1.17       0.0191
! Validation         86 9917.786   0.0015       0.0194     0.000138       0.0195        0.199          1.2        0.019
Wall time: 9917.786270706914

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     87   100       0.0143       0.0142     0.000148        0.162        0.896       0.0199
     87   200       0.0214       0.0212     0.000238        0.218         1.25       0.0261
     87   300       0.0249       0.0248     5.18e-05        0.225        0.932       0.0134
     87   400       0.0138       0.0137      0.00011        0.171        0.805        0.017
     87   500       0.0207       0.0206     0.000131        0.201        0.968       0.0191
     87   600       0.0227       0.0226     0.000109         0.21         1.02       0.0172
     87   700       0.0145       0.0141     0.000408        0.172         2.01       0.0386
     87   800        0.014        0.014     3.15e-06        0.178        0.158      0.00329
     87   900       0.0208       0.0206     0.000139        0.203        0.643        0.017
     87  1000       0.0203       0.0201     0.000118        0.211        0.833       0.0173
     87  1100       0.0196       0.0196     7.34e-05        0.192        0.598       0.0129
     87  1200       0.0197       0.0197     2.14e-05        0.197        0.323      0.00685
     87  1300       0.0383       0.0378     0.000539        0.278          3.8       0.0419
     87  1400       0.0195       0.0194     0.000122        0.208         1.36       0.0194
     87  1500      0.00906      0.00898     7.37e-05        0.124        0.454       0.0149
     87  1600       0.0148       0.0148     3.37e-05         0.13        0.327      0.00781
     87  1601       0.0092      0.00907      0.00013        0.137        0.848       0.0221

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     87   100       0.0169       0.0169     2.59e-05        0.189        0.323      0.00834
     87   200       0.0228       0.0228     7.96e-05        0.223         1.16       0.0165
     87   203       0.0184       0.0183      6.8e-05        0.202        0.736       0.0153


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              87 10023.900   0.0015       0.0201     0.000172       0.0203        0.204         1.18       0.0192
! Validation         87 10023.900   0.0015       0.0197       0.0001       0.0198        0.202        0.944        0.015
Wall time: 10023.900570902973

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     88   100       0.0255       0.0254     8.43e-05        0.211        0.795       0.0153
     88   200       0.0192       0.0191     7.67e-05        0.201        0.438       0.0113
     88   300       0.0147       0.0141     0.000643        0.168         2.78       0.0484
     88   400       0.0143       0.0143     6.18e-06        0.165        0.175      0.00395
     88   500       0.0184        0.018     0.000431        0.195         1.64       0.0372
     88   600       0.0164       0.0164     9.17e-05        0.172         1.52       0.0158
     88   700       0.0196       0.0195     9.04e-05        0.188        0.682       0.0178
     88   800       0.0275       0.0274     5.57e-05        0.236        0.304      0.00927
     88   900       0.0216       0.0215     7.71e-05        0.213         1.21       0.0159
     88  1000       0.0242       0.0241      5.7e-05        0.222        0.948       0.0131
     88  1100       0.0273       0.0262      0.00112        0.222         3.86       0.0395
     88  1200       0.0204       0.0203     0.000123        0.202         1.36        0.015
     88  1300         0.03       0.0297     0.000263         0.26         1.76       0.0303
     88  1400       0.0152       0.0151     1.59e-05        0.184        0.281      0.00586
     88  1500       0.0256       0.0253      0.00025        0.225         1.91       0.0276
     88  1600       0.0278       0.0274     0.000398        0.231         3.17       0.0258
     88  1601       0.0429       0.0419     0.000961        0.264         4.62       0.0463

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     88   100       0.0167       0.0164     0.000307        0.187          1.4       0.0308
     88   200       0.0233       0.0231     0.000135        0.223         1.43       0.0215
     88   203       0.0174       0.0173     0.000102        0.194        0.933       0.0194


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              88 10131.497   0.0015       0.0199     0.000211       0.0201        0.203         1.21       0.0199
! Validation         88 10131.497   0.0015       0.0198      0.00025         0.02        0.203          1.6       0.0261
Wall time: 10131.497724330053

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     89   100       0.0194       0.0193      2.8e-05          0.2        0.389       0.0085
     89   200       0.0239       0.0239     9.17e-06        0.229        0.254      0.00528
     89   300       0.0183       0.0182     9.04e-05        0.185        0.749       0.0176
     89   400       0.0124       0.0122      0.00017         0.16        0.773       0.0226
     89   500       0.0284       0.0283     7.16e-05        0.247        0.838        0.012
     89   600       0.0148       0.0145     0.000249        0.175         1.81       0.0287
     89   700       0.0224       0.0223     6.23e-05        0.223        0.633       0.0132
     89   800       0.0281        0.028     0.000135        0.227         1.28       0.0198
     89   900        0.017       0.0169     9.16e-05        0.186         0.72       0.0165
     89  1000       0.0189       0.0184     0.000466        0.201         1.82        0.038
     89  1100        0.015       0.0149      7.4e-05        0.179         1.06       0.0119
     89  1200       0.0231       0.0229     0.000163        0.205         1.94       0.0195
     89  1300       0.0274       0.0274     1.75e-05        0.246         0.33      0.00686
     89  1400       0.0167       0.0164     0.000256        0.175         1.49       0.0304
     89  1500       0.0151        0.015     0.000144        0.176        0.861       0.0212
     89  1600       0.0126       0.0125     0.000116        0.158        0.775       0.0193
     89  1601        0.018       0.0178     0.000224         0.18         1.08       0.0289

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     89   100       0.0164       0.0162     0.000222        0.186          1.2       0.0255
     89   200       0.0231       0.0231     6.24e-05        0.222        0.908       0.0143
     89   203       0.0187       0.0187     5.37e-05        0.206        0.667       0.0139


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              89 10235.776   0.0015         0.02      0.00016       0.0201        0.204         1.13       0.0183
! Validation         89 10235.776   0.0015       0.0196     0.000158       0.0198        0.201         1.22       0.0194
Wall time: 10235.77604269702

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     90   100       0.0258       0.0255     0.000285        0.244         1.41       0.0294
     90   200      0.00519      0.00515     3.82e-05       0.0937        0.304      0.00958
     90   300       0.0148       0.0145     0.000253        0.171         1.28       0.0304
     90   400       0.0234       0.0233      6.9e-05        0.213        0.833       0.0138
     90   500       0.0201         0.02     0.000104         0.19        0.614       0.0126
     90   600       0.0173       0.0173     5.38e-05        0.168         1.27       0.0139
     90   700       0.0195       0.0194     3.44e-05        0.191        0.348      0.00832
     90   800       0.0211        0.021     0.000117        0.209         1.16       0.0186
     90   900       0.0215       0.0213     0.000119        0.202         1.39       0.0183
     90  1000       0.0102      0.00973     0.000463        0.138         2.12       0.0415
     90  1100       0.0225       0.0224     4.73e-05        0.222         2.63      0.00965
     90  1200       0.0155       0.0153     0.000173        0.176         1.29       0.0237
     90  1300      0.00842      0.00816     0.000256        0.115         1.22       0.0304
     90  1400       0.0211       0.0211      6.5e-05        0.216        0.649       0.0135
     90  1500       0.0171       0.0166     0.000504        0.188         2.48       0.0425
     90  1600       0.0316       0.0314     0.000159        0.254         1.17       0.0199
     90  1601        0.029       0.0288     0.000207        0.233        0.949       0.0232

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     90   100       0.0162       0.0161     0.000149        0.185        0.973       0.0222
     90   200       0.0218       0.0218     1.55e-05        0.217        0.268      0.00563
     90   203       0.0204       0.0204     8.72e-06        0.211        0.261      0.00545


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              90 10340.446   0.0015         0.02     0.000199       0.0202        0.203         1.17       0.0192
! Validation         90 10340.446   0.0015       0.0197     9.48e-05       0.0198        0.202         0.85       0.0138
Wall time: 10340.446564794984

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     91   100       0.0186       0.0185     0.000163        0.185         0.69       0.0214
     91   200       0.0198       0.0197     7.78e-05        0.205         1.06       0.0164
     91   300       0.0232       0.0231     0.000114        0.228        0.842       0.0187
     91   400       0.0127       0.0127     3.58e-05        0.154        0.533       0.0107
     91   500       0.0173        0.017     0.000266        0.192        0.806       0.0231
     91   600       0.0329       0.0328     4.19e-05        0.247        0.794       0.0104
     91   700       0.0134       0.0134     4.17e-05         0.16        0.357       0.0108
     91   800       0.0275       0.0275     2.47e-05        0.246        0.596      0.00718
     91   900       0.0187       0.0185     0.000157        0.194        0.516       0.0152
     91  1000       0.0221        0.022     6.11e-05         0.22         1.27       0.0139
     91  1100        0.011       0.0109     3.08e-05        0.142        0.339      0.00899
     91  1200       0.0166       0.0165     4.64e-05        0.181        0.778       0.0104
     91  1300       0.0369       0.0366     0.000272        0.247         1.89       0.0225
     91  1400       0.0135       0.0135     1.57e-05        0.161        0.338      0.00705
     91  1500       0.0148       0.0147     0.000101        0.178        0.832        0.017
     91  1600        0.012       0.0119     8.69e-05        0.164        0.998       0.0173
     91  1601       0.0206       0.0206     2.55e-05        0.212        0.432      0.00899

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     91   100        0.016        0.016     6.28e-05        0.183        0.472       0.0124
     91   200       0.0228       0.0226     0.000201         0.22         2.05       0.0273
     91   203       0.0178       0.0177     0.000143        0.196         1.04       0.0217


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              91 10446.038   0.0015       0.0202     0.000163       0.0203        0.204         1.13       0.0184
! Validation         91 10446.038   0.0015       0.0196     0.000209       0.0198        0.201         1.49       0.0249
Wall time: 10446.03873270587

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     92   100       0.0265       0.0263     0.000188        0.229         1.22       0.0236
     92   200        0.019        0.019     2.75e-05        0.186        0.248      0.00805
     92   300       0.0124       0.0119     0.000415        0.146         1.47       0.0356
     92   400       0.0247       0.0247     2.24e-05         0.22        0.291      0.00726
     92   500        0.019       0.0189     4.03e-05        0.201        0.705      0.00892
     92   600        0.013       0.0129     6.04e-05        0.154        0.455       0.0134
     92   700       0.0235       0.0232     0.000326        0.227         3.15       0.0322
     92   800       0.0335       0.0327     0.000776        0.251         4.57       0.0452
     92   900       0.0322       0.0321     8.39e-05        0.257         1.03       0.0159
     92  1000       0.0249       0.0246     0.000321        0.238         2.08       0.0321
     92  1100        0.017        0.017     4.99e-05        0.189        0.758      0.00952
     92  1200       0.0224       0.0223     0.000102        0.214         1.07       0.0171
     92  1300       0.0369       0.0367     0.000183        0.278         1.19       0.0197
     92  1400       0.0281       0.0281      3.3e-05        0.249        0.657      0.00904
     92  1500       0.0207       0.0207     6.96e-05        0.216         1.44       0.0152
     92  1600        0.022       0.0219     0.000101        0.216         1.15       0.0178
     92  1601       0.0357       0.0357     5.54e-06        0.278        0.359      0.00372

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     92   100       0.0164       0.0163     2.68e-05        0.183        0.298      0.00788
     92   200       0.0234       0.0234     4.07e-05        0.224         1.08       0.0114
     92   203       0.0175       0.0174     4.96e-05        0.198        0.562       0.0117


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              92 10550.346   0.0015       0.0201     0.000181       0.0203        0.204         1.17        0.019
! Validation         92 10550.346   0.0015       0.0198     8.36e-05       0.0199        0.202        0.867       0.0136
Wall time: 10550.34590656287

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     93   100       0.0234       0.0233     0.000134        0.224         1.52       0.0199
     93   200       0.0194       0.0193      0.00012        0.191         1.58       0.0195
     93   300       0.0221        0.022     8.37e-05         0.22        0.788       0.0164
     93   400       0.0221       0.0221     3.11e-05        0.214        0.405      0.00844
     93   500       0.0228       0.0227     0.000113        0.222        0.903       0.0188
     93   600       0.0532       0.0513      0.00199         0.29         4.98        0.049
     93   700       0.0074      0.00736     4.12e-05        0.111        0.418       0.0115
     93   800       0.0168       0.0167     5.89e-05         0.19        0.879       0.0122
     93   900       0.0249       0.0246     0.000369        0.228            2       0.0338
     93  1000      0.00686      0.00684     2.48e-05        0.126        0.483      0.00825
     93  1100       0.0191        0.019     6.79e-05        0.201        0.614        0.011
     93  1200       0.0222       0.0222     3.92e-05        0.222        0.496       0.0103
     93  1300        0.017       0.0162     0.000838        0.182          3.2       0.0558
     93  1400       0.0304       0.0303     9.41e-05        0.242         1.64       0.0178
     93  1500       0.0198       0.0197     8.51e-05        0.184         0.87       0.0167
     93  1600       0.0137       0.0136     5.49e-05        0.156         0.53       0.0139
     93  1601       0.0214       0.0214     6.47e-05        0.196          1.1       0.0154

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     93   100       0.0159       0.0154     0.000464        0.179         1.76       0.0411
     93   200        0.023       0.0227     0.000339        0.219         2.37       0.0336
     93   203       0.0186       0.0184     0.000159        0.202         1.13       0.0234


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              93 10654.688   0.0015       0.0199     0.000299       0.0202        0.203         1.24       0.0201
! Validation         93 10654.688   0.0015       0.0195     0.000377       0.0199          0.2          2.1       0.0339
Wall time: 10654.688315471867

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     94   100       0.0161       0.0158     0.000344        0.181         1.53       0.0354
     94   200       0.0134       0.0128     0.000586        0.164         1.98       0.0466
     94   300       0.0248       0.0247     0.000111        0.236         3.63       0.0175
     94   400       0.0114       0.0113     0.000121         0.16        0.795       0.0165
     94   500       0.0235       0.0234     6.32e-05        0.223         1.31       0.0137
     94   600       0.0272       0.0272     6.39e-05        0.225         1.16       0.0103
     94   700       0.0264        0.026     0.000369        0.239         2.26       0.0368
     94   800       0.0294       0.0294      7.4e-06        0.215        0.312      0.00387
     94   900       0.0212        0.021     0.000152         0.21         1.59       0.0221
     94  1000       0.0249       0.0249     9.13e-06        0.236        0.302      0.00448
     94  1100       0.0106       0.0106     1.77e-05        0.124        0.233       0.0069
     94  1200       0.0218       0.0202      0.00159        0.185         3.33       0.0741
     94  1300       0.0178       0.0176     0.000225        0.181         1.34        0.028
     94  1400       0.0278       0.0278     2.78e-05        0.238        0.477      0.00897
     94  1500       0.0269       0.0253      0.00161        0.225         4.26       0.0413
     94  1600      0.00163      0.00161     2.57e-05       0.0493        0.254      0.00803
     94  1601        0.021       0.0209     5.58e-05        0.197        0.351       0.0115

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     94   100       0.0161        0.016     6.18e-05        0.183        0.577        0.012
     94   200        0.022        0.022     4.52e-06        0.216        0.272      0.00371
     94   203       0.0164       0.0163     1.44e-05        0.188        0.298      0.00621


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              94 10760.297   0.0015       0.0197     0.000157       0.0199        0.202         1.12       0.0181
! Validation         94 10760.297   0.0015       0.0192      5.9e-05       0.0192        0.198        0.637      0.00986
Wall time: 10760.296938319923
! Best model       94    0.010

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     95   100       0.0289       0.0287     0.000128        0.251         1.94       0.0183
     95   200       0.0169       0.0167      0.00014        0.185         1.28       0.0212
     95   300      0.00822      0.00815     6.73e-05        0.117        0.719       0.0142
     95   400       0.0156       0.0156     1.35e-05         0.18         0.24      0.00573
     95   500       0.0248       0.0248     3.97e-05        0.221        0.513       0.0104
     95   600       0.0275       0.0275     3.86e-05        0.234        0.761      0.00962
     95   700       0.0288       0.0286     0.000174         0.24         1.52       0.0184
     95   800       0.0217       0.0214     0.000221          0.2         2.24       0.0255
     95   900       0.0226       0.0225     0.000117        0.214         1.57       0.0206
     95  1000       0.0117       0.0116     9.45e-05        0.156        0.964       0.0169
     95  1100       0.0105       0.0102      0.00032         0.15         1.31       0.0326
     95  1200       0.0251        0.025     6.77e-05        0.217        0.956       0.0122
     95  1300       0.0303       0.0297      0.00058        0.254         2.87       0.0297
     95  1400       0.0267       0.0267     5.96e-05        0.244         2.01       0.0147
     95  1500       0.0244       0.0243      1.5e-05        0.219        0.306      0.00668
     95  1600       0.0292       0.0292     4.62e-05        0.238        0.487       0.0113
     95  1601       0.0114       0.0113     7.29e-05        0.146        0.497       0.0149

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     95   100       0.0167       0.0166     6.13e-05        0.186        0.619       0.0136
     95   200       0.0224       0.0224     7.29e-06        0.219        0.247      0.00405
     95   203       0.0176       0.0176     7.72e-06        0.196        0.219      0.00456


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              95 10865.372   0.0015       0.0197     0.000158       0.0199        0.202         1.12       0.0182
! Validation         95 10865.372   0.0015       0.0194      6.1e-05       0.0195          0.2        0.665       0.0101
Wall time: 10865.372761128936

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     96   100       0.0148       0.0147     4.91e-05        0.171        0.539        0.012
     96   200        0.014        0.014     1.95e-05        0.172        0.732      0.00849
     96   300       0.0162        0.016     0.000163        0.189        0.986       0.0205
     96   400       0.0265       0.0264      4.6e-05        0.232        0.845       0.0105
     96   500       0.0248       0.0247     5.82e-05        0.225        0.679       0.0122
     96   600        0.015        0.015     1.78e-05        0.181        0.284       0.0064
     96   700        0.017       0.0167     0.000235        0.175         1.07       0.0259
     96   800      0.00289      0.00288     6.89e-06       0.0772        0.134      0.00479
     96   900        0.016       0.0159     0.000106        0.183        0.694       0.0159
     96  1000       0.0184       0.0183     0.000133        0.189         1.36       0.0219
     96  1100        0.016       0.0159      0.00015        0.183        0.994       0.0207
     96  1200       0.0228       0.0227     0.000181        0.222         1.45       0.0237
     96  1300       0.0221        0.022     9.97e-05        0.223        0.779       0.0162
     96  1400       0.0232       0.0232     2.61e-05        0.214        0.476      0.00901
     96  1500       0.0152       0.0151      6.2e-05         0.16        0.554       0.0125
     96  1600       0.0151        0.015     7.02e-05        0.181        0.691       0.0124
     96  1601       0.0137       0.0136     5.83e-05        0.167          1.2       0.0138

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     96   100       0.0157       0.0157     2.46e-05        0.181        0.349      0.00787
     96   200       0.0218       0.0218     1.14e-05        0.216        0.526      0.00496
     96   203       0.0177       0.0176     3.05e-05        0.199        0.481         0.01


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              96 10971.914   0.0015       0.0198     0.000141       0.0199        0.202         1.07       0.0172
! Validation         96 10971.914   0.0015       0.0195     6.24e-05       0.0196          0.2        0.686       0.0105
Wall time: 10971.914599725977

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     97   100       0.0247       0.0247     2.47e-05         0.23         0.41      0.00716
     97   200        0.012       0.0119     8.86e-05        0.156        0.611       0.0131
     97   300       0.0182       0.0181     0.000106        0.192         0.82       0.0171
     97   400       0.0113       0.0112      2.2e-05        0.147        0.306      0.00672
     97   500         0.02       0.0199     5.53e-05        0.199        0.596       0.0136
     97   600      0.00962      0.00961     6.68e-06        0.136        0.122      0.00402
     97   700      0.00585      0.00563     0.000215       0.0933        0.927       0.0249
     97   800       0.0239       0.0237     0.000187        0.206        0.984       0.0244
     97   900        0.019        0.019     8.14e-06        0.199        0.235      0.00471
     97  1000       0.0291       0.0289     0.000219         0.25         2.06        0.024
     97  1100       0.0422       0.0421     1.92e-05         0.27        0.544      0.00808
     97  1200       0.0262       0.0262     1.99e-05        0.209        0.501      0.00718
     97  1300       0.0173       0.0172     8.19e-05        0.188         0.64       0.0134
     97  1400       0.0308       0.0307     0.000123        0.248         1.38       0.0211
     97  1500       0.0163       0.0162     0.000125        0.166        0.878       0.0201
     97  1600        0.021       0.0208     0.000211        0.212         1.34        0.028
     97  1601       0.0204       0.0203     7.66e-05        0.194        0.613       0.0168

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     97   100       0.0162       0.0162     1.95e-05        0.184         0.31       0.0076
     97   200       0.0214       0.0214     4.46e-05        0.214         1.03       0.0112
     97   203       0.0178       0.0177     5.61e-05        0.195        0.554       0.0115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              97 11076.132   0.0015       0.0197     0.000163       0.0198        0.202         1.15       0.0189
! Validation         97 11076.132   0.0015       0.0193     8.61e-05       0.0194        0.198        0.884       0.0137
Wall time: 11076.132082823897

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     98   100       0.0189       0.0189     1.98e-05        0.191        0.635      0.00666
     98   200       0.0273        0.027     0.000334        0.224         2.02       0.0218
     98   300       0.0221        0.022     1.76e-05        0.216        0.253      0.00527
     98   400       0.0182       0.0179     0.000293        0.189         1.83       0.0289
     98   500        0.017        0.017     5.29e-05        0.178        0.476       0.0123
     98   600       0.0254       0.0253     0.000163        0.222          2.4       0.0202
     98   700        0.016       0.0155     0.000489        0.186          1.6       0.0401
     98   800       0.0308       0.0306     0.000201        0.247         2.56       0.0254
     98   900       0.0182       0.0175     0.000714        0.189         2.71       0.0502
     98  1000       0.0201         0.02     7.69e-05        0.206         0.78       0.0132
     98  1100       0.0196       0.0196     2.58e-05        0.212        0.412      0.00859
     98  1200        0.012        0.012      6.2e-05        0.157        0.749       0.0128
     98  1300      0.00181       0.0018     1.35e-05       0.0556        0.173      0.00617
     98  1400       0.0107       0.0106     9.22e-05         0.14        0.706       0.0157
     98  1500       0.0159       0.0158     1.98e-05        0.185        0.479      0.00674
     98  1600       0.0253       0.0252     3.23e-05        0.229        0.557      0.00851
     98  1601      0.00242      0.00235     6.35e-05       0.0713        0.385       0.0138

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     98   100        0.016       0.0159     7.25e-05        0.181        0.416       0.0119
     98   200       0.0226       0.0225     9.66e-05        0.219         1.43        0.019
     98   203       0.0164       0.0163     0.000125        0.189        0.944       0.0197


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              98 11180.709   0.0015       0.0198     0.000162       0.0199        0.202         1.14       0.0185
! Validation         98 11180.709   0.0015        0.019     0.000167       0.0192        0.198          1.3       0.0218
Wall time: 11180.709259981988

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     99   100       0.0146       0.0144     0.000217        0.177         1.77       0.0202
     99   200       0.0193       0.0189     0.000387        0.205         1.46       0.0358
     99   300       0.0242        0.024     0.000137        0.229          1.7       0.0193
     99   400       0.0164       0.0163     3.87e-05        0.172        0.478       0.0106
     99   500       0.0154       0.0151     0.000257        0.173         1.74       0.0309
     99   600       0.0274       0.0272     0.000231        0.218         2.23       0.0284
     99   700       0.0143       0.0142     0.000138        0.162        0.638       0.0189
     99   800       0.0175       0.0173     0.000143        0.194         1.55       0.0224
     99   900       0.0166       0.0164     0.000195        0.175         1.04       0.0264
     99  1000       0.0235       0.0234     0.000156        0.212         2.49       0.0235
     99  1100       0.0183       0.0183     4.94e-05        0.191        0.333       0.0109
     99  1200       0.0157       0.0157     1.59e-05        0.185        0.231      0.00562
     99  1300       0.0106       0.0102     0.000404        0.132          1.2       0.0382
     99  1400       0.0247       0.0247     2.67e-05        0.227         1.59      0.00858
     99  1500       0.0196       0.0193     0.000281        0.182         1.25       0.0314
     99  1600       0.0204       0.0203     0.000131        0.202         1.57       0.0199
     99  1601       0.0214       0.0213     2.72e-05        0.218        0.396      0.00974

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     99   100       0.0161       0.0159      0.00014        0.183        0.959       0.0218
     99   200       0.0216       0.0216      7.1e-05        0.217        0.539       0.0134
     99   203       0.0172       0.0172     4.08e-05        0.194        0.567       0.0118


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              99 11288.170   0.0015       0.0196     0.000174       0.0197        0.201         1.16        0.019
! Validation         99 11288.170   0.0015       0.0188     0.000106       0.0189        0.196        0.919       0.0154
Wall time: 11288.170610460918

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
    100   100       0.0227       0.0225     0.000181        0.223         1.59       0.0244
    100   200      0.00967      0.00964     2.92e-05        0.138        0.683      0.00893
    100   300       0.0117       0.0117     2.09e-05        0.139        0.292      0.00816
    100   400       0.0309       0.0308     9.49e-05        0.259         1.22       0.0174
    100   500       0.0228       0.0227     0.000117        0.219         1.33       0.0186
    100   600       0.0153       0.0153     2.15e-05        0.169        0.257      0.00714
    100   700       0.0199       0.0199     3.72e-05        0.185        0.481       0.0097
    100   800       0.0203       0.0202     0.000178        0.205         1.19       0.0254
    100   900       0.0312       0.0296      0.00158        0.256         4.35        0.074
    100  1000       0.0257       0.0256     0.000113        0.219        0.786       0.0165
    100  1100       0.0149       0.0149     2.86e-05        0.168        0.353      0.00987
    100  1200       0.0309       0.0308     0.000117        0.235         1.42       0.0194
    100  1300       0.0281        0.028     6.76e-05        0.221        0.936       0.0133
    100  1400       0.0214       0.0208     0.000569        0.194         1.81       0.0424
    100  1500       0.0232       0.0231     0.000152        0.228        0.966       0.0201
    100  1600       0.0157       0.0157     5.98e-05        0.183        0.584        0.014
    100  1601       0.0194       0.0194     6.89e-06        0.203        0.352      0.00498

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
    100   100       0.0167       0.0163     0.000355        0.185         1.52       0.0323
    100   200       0.0232       0.0231     7.46e-05        0.224         1.04       0.0147
    100   203       0.0186       0.0185      0.00011          0.2         0.96         0.02


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train             100 11392.112   0.0015       0.0196     0.000172       0.0197        0.202         1.16       0.0189
! Validation        100 11392.112   0.0015       0.0196     0.000181       0.0198        0.201         1.31         0.02
Wall time: 11392.111876094947
! Stop training: max epochs
Wall time: 11392.140776969958
Cumulative wall time: 11392.140776969958
Testset is used.
Using all frames from the specified test dataset, yielding a test set size of 811 frames.
Starting...

--- Evaluation Time consumption: 5.724960s ---

--- Evaluation Final result: ---
               f_mae =  0.217459           
              f_rmse =  0.303196           
             N_f_mae =  0.197710           
            Si_f_mae =  0.239583           
         psavg_f_mae =  0.218646           
            N_f_rmse =  0.284107           
           Si_f_rmse =  0.323244           
        psavg_f_rmse =  0.303676           
               e_mae =  1.803032           
             e/N_mae =  0.030170           
Training QAT Model...
After QAT training...
loaded model from training session
               f_mae =  0.217459           
              f_rmse =  0.303196           
             N_f_mae =  0.197710           
            Si_f_mae =  0.239583           
         psavg_f_mae =  0.218646           
            N_f_rmse =  0.284107           
           Si_f_rmse =  0.323244           
        psavg_f_rmse =  0.303676           
               e_mae =  1.803032           
             e/N_mae =  0.030170           
