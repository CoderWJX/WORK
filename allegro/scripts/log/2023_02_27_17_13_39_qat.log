Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat_bs16', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs16', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 16, 'max_epochs': 100, 'learning_rate': 0.005, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_e/N_mae', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
Torch device: cuda
{'_jit_bailout_depth': 2, '_jit_fusion_strategy': [('DYNAMIC', 3)], 'root': '/mnt/yujie.zeng/project_2023/allegro_models/', 'run_name': 'Light-Allegro-3Layer-6rmax_qat_bs16', 'wandb': False, 'wandb_project': 'aspirin', 'model_builders': ['allegro.model.Allegro', 'PerSpeciesRescale', 'ForceOutput', 'RescaleEnergyEtc'], 'dataset_statistics_stride': 1, 'default_dtype': 'float32', 'allow_tf32': False, 'verbose': 'info', 'model_debug_mode': False, 'equivariance_test': False, 'grad_anomaly_mode': False, 'append': True, 'taskname': 'qat', 'base_train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0', 'train_dir': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-6rmax_qat_bs16', 'qat_batch_size': 16, 'repeat': 1, 'quan': {'ptq_batches': 200, 'act': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'weight': {'mode': 'lsq', 'bit': 8, 'all_positive': False, 'per_channel': False, 'symmetric': True}, 'excepts': {'conv1': {'act': {'bit': 8, 'all_positive': False, 'symmetric': True}, 'weight': {'bit': 8}}, 'fc': {'act': {'bit': 8}, 'weight': {'bit': 8}}, 'linear': {'act': {'bit': 8}, 'weight': {'bit': 8}}}}, 'seed': 123456, 'dataset_seed': 123456, 'r_max': 6.0, 'avg_num_neighbors': 72.66349029541016, 'BesselBasis_trainable': True, 'PolynomialCutoff_p': 6, 'l_max': 2, 'parity': 'o3_restricted', 'num_layers': 3, 'env_embed_multiplicity': 16, 'embed_initial_edge': True, 'two_body_latent_mlp_latent_dimensions': [32, 32, 32, 32], 'two_body_latent_mlp_nonlinearity': 'silu', 'two_body_latent_mlp_initialization': 'uniform', 'latent_mlp_latent_dimensions': [32], 'latent_mlp_nonlinearity': 'silu', 'latent_mlp_initialization': 'uniform', 'latent_resnet': True, 'env_embed_mlp_latent_dimensions': [], 'env_embed_mlp_initialization': 'uniform', 'edge_eng_mlp_latent_dimensions': [32], 'edge_eng_mlp_nonlinearity': None, 'edge_eng_mlp_initialization': 'uniform', 'dataset': 'ase', 'dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Trainset.xyz', 'ase_args': {'format': 'extxyz'}, 'chemical_symbol_to_type': {'N': 0, 'Si': 1}, 'validation_dataset': 'ase', 'validation_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Validset.xyz', 'evaluate_dataset': 'ase', 'evaluate_dataset_file_name': '/mnt/wjing.chen/2022/dataset/SiN_reduced_dataset/Testset.xyz', 'log_batch_freq': 100, 'log_epoch_freq': 1, 'save_checkpoint_freg': -1, 'save_ema_checkpoint_freq': -1, 'n_train': 6402, 'n_val': 810, 'batch_size': 16, 'max_epochs': 100, 'learning_rate': 0.005, 'train_val_split': 'random', 'shuffle': True, 'metrics_key': 'validation_e/N_mae', 'use_ema': True, 'ema_decay': 0.99, 'ema_use_num_updates': True, 'loss_coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}, 'optimizer_name': 'Adam', 'optimizer_params': {'amsgrad': False, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0}, 'lr_scheduler_name': 'ReduceLROnPlateau', 'lr_scheduler_patience': 50, 'lr_scheduler_factor': 0.5, 'early_stopping_upper_bounds': {'cumulative_wall': 604800.0}, 'early_stopping_lower_bounds': {'LR': 1e-05}, 'early_stopping_patiences': {'validation_loss': 100}, 'metrics_components': [['forces', 'mae'], ['forces', 'mae'], ['total_energy', 'mae'], ['total_energy', 'mae', {'PerAtom': True}]], 'torch_version': '1.11.0+cu113', 'e3nn_version': '0.4.4', 'nequip_version': '0.5.4', 'code_commits': {}, 'device': 'cuda', 'train_on_keys': ['forces', 'total_energy'], 'early_stopping': None, 'early_stopping_kwargs': None, 'lr_scheduler_kwargs': None, 'optimizer_kwargs': None, 'max_gradient_norm': inf, 'exclude_keys': [], 'dataloader_num_workers': 0, 'train_idcs': None, 'val_idcs': None, 'init_callbacks': [], 'end_of_epoch_callbacks': [], 'end_of_batch_callbacks': [], 'end_of_train_callbacks': [], 'final_callbacks': [], 'save_checkpoint_freq': -1, 'report_init_validation': True, 'parallel': False, 'dataset_extra_fixed_fields': {'r_max': 6.0}, 'validation_dataset_extra_fixed_fields': {'r_max': 6.0}, 'dataset_config': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml', 'metrics_config': PosixPath('/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/config.yaml'), 'base_model_file': '/mnt/yujie.zeng/project_2023/allegro_models/Light-Allegro-3Layer-rmax6.0/best_model.pth', 'output_fields': []}
Trainset is used.
Successfully loaded the data set of type ASEDataset(6402)...
Validset is used.
Successfully loaded the validation data set of type ASEDataset(810)...
Using device: cuda
WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`
Loading model... 
Atomic outputs are scaled by: [N, Si: 1.000000], shifted by [N, Si: 0.000000].
loaded model from training session
Successfully load the pretrained model...
RescaleOutput(
  (model): GradientOutput(
    (func): SequentialGraphNetwork(
      (one_hot): OneHotAtomEncoding()
      (radial_basis): RadialBasisEdgeEncoding(
        (basis): NormalizedBasis(
          (basis): BesselBasis()
        )
        (cutoff): PolynomialCutoff()
      )
      (spharm): SphericalHarmonicEdgeAttrs(
        (sh): SphericalHarmonics()
      )
      (allegro): Allegro_Module(
        (latents): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (env_embed_mlps): ModuleList(
          (0): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (1): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
          (2): QuantScalarMLPFunction(
            (_forward): RecursiveScriptModule(original_name=GraphModule)
            (quan_w_fn): LsqQuan()
            (quan_a_fn): LsqQuan()
            (_qt_forward): RecursiveScriptModule(
              original_name=GraphModule
              (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
            )
          )
        )
        (tps): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (linears): ModuleList(
          (0): RecursiveScriptModule(original_name=GraphModule)
          (1): RecursiveScriptModule(original_name=GraphModule)
          (2): RecursiveScriptModule(original_name=GraphModule)
        )
        (env_linears): ModuleList(
          (0): Identity()
          (1): Identity()
          (2): Identity()
        )
        (_env_weighter): MakeWeightedChannels()
        (final_latent): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng): ScalarMLP(
        (_module): QuantScalarMLPFunction(
          (_forward): RecursiveScriptModule(original_name=GraphModule)
          (quan_w_fn): LsqQuan()
          (quan_a_fn): LsqQuan()
          (_qt_forward): RecursiveScriptModule(
            original_name=GraphModule
            (quan_w_fn): RecursiveScriptModule(original_name=LsqQuan)
          )
        )
      )
      (edge_eng_sum): EdgewiseEnergySum()
      (per_species_rescale): PerSpeciesScaleShift()
      (total_energy_sum): AtomwiseReduce()
    )
  )
)
Number of weights: 43096
! Starting training ...

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      0    51         1.63         1.03        0.591          1.4          153         1.48


  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Initial Validation          0   14.102    0.005         1.18        0.804         1.98         1.51         90.7         1.64
Wall time: 14.102418143069372
! Best model        0    1.644

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1   100        0.319        0.305       0.0148        0.749         11.2         0.21
      1   200        0.223        0.221      0.00197        0.688         4.51       0.0667
      1   300        0.202         0.17       0.0319        0.592         20.4        0.324
      1   400         0.11        0.109     0.000799        0.473         2.12       0.0487
      1   401        0.151        0.136       0.0153        0.577         11.4        0.238

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      1    51        0.143        0.143     0.000678         0.55         3.96       0.0422


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               1   94.272    0.005        0.269       0.0169        0.286        0.701         10.4        0.175
! Validation          1   94.272    0.005        0.141      0.00179        0.143         0.54         3.97       0.0615
Wall time: 94.27252443600446
! Best model        1    0.062

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2   100        0.092         0.09      0.00194        0.441         5.24       0.0576
      2   200         0.11        0.109     0.000425        0.473          1.6       0.0306
      2   300       0.0837       0.0809      0.00283        0.398         5.58        0.097
      2   400        0.115        0.113      0.00173        0.493         6.83       0.0652
      2   401       0.0819       0.0816     0.000345        0.427         2.67       0.0312

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      2    51       0.0938        0.092      0.00174        0.444         7.66       0.0719


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               2  156.564    0.005        0.106      0.00345         0.11        0.462         5.16       0.0848
! Validation          2  156.564    0.005       0.0917      0.00195       0.0936        0.439         4.09       0.0719
Wall time: 156.56469639507122

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3   100        0.122         0.12      0.00296        0.493         5.13       0.0872
      3   200       0.0817       0.0805      0.00119        0.399         3.38       0.0558
      3   300       0.0767       0.0758     0.000919        0.397          2.7       0.0495
      3   400        0.109        0.103      0.00525        0.429         6.97        0.133
      3   401       0.0913        0.091     0.000337        0.456         1.29       0.0268

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      3    51       0.0768       0.0685      0.00829        0.382           17         0.17


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               3  220.235    0.005       0.0764       0.0028       0.0792        0.394          4.6        0.076
! Validation          3  220.235    0.005       0.0649        0.012       0.0768        0.368         11.6        0.197
Wall time: 220.23520746896975

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4   100       0.0839       0.0823      0.00154        0.411         4.71       0.0706
      4   200       0.0923       0.0761       0.0163        0.402         15.8        0.239
      4   300       0.0726       0.0716      0.00101        0.371         2.85        0.059
      4   400       0.0588        0.057      0.00182        0.346          4.4       0.0788
      4   401       0.0537       0.0532     0.000495         0.34         1.61       0.0335

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      4    51       0.0882       0.0851       0.0031        0.425         10.9        0.103


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               4  279.416    0.005       0.0744      0.00271       0.0771         0.39         4.63       0.0755
! Validation          4  279.416    0.005       0.0866      0.00449       0.0911        0.429          6.2        0.115
Wall time: 279.416049499996

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5   100       0.0594       0.0586     0.000778        0.352         2.12       0.0451
      5   200       0.0387       0.0362      0.00247        0.273         3.91       0.0939
      5   300       0.0544        0.052      0.00245        0.336         5.44       0.0893
      5   400       0.0525        0.052     0.000484        0.331         2.25       0.0389
      5   401       0.0426       0.0418     0.000778        0.303         2.47       0.0515

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      5    51       0.0551       0.0549     0.000197        0.343         2.34       0.0239


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               5  338.467    0.005       0.0613       0.0017        0.063        0.354         3.75       0.0614
! Validation          5  338.467    0.005       0.0537     0.000612       0.0543        0.333         2.14       0.0334
Wall time: 338.46751390211284
! Best model        5    0.033

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6   100        0.072        0.071     0.000976         0.38         4.09       0.0473
      6   200       0.0603       0.0601     0.000244        0.345         1.87       0.0247
      6   300       0.0555       0.0548     0.000717        0.337         1.74       0.0374
      6   400       0.0551       0.0535      0.00166        0.336         4.08       0.0664
      6   401        0.101       0.0995      0.00121        0.457         6.28       0.0598

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      6    51       0.0661       0.0636      0.00245        0.371         9.62       0.0884


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               6  398.686    0.005       0.0604       0.0028       0.0632        0.347         4.43       0.0734
! Validation          6  398.686    0.005       0.0633      0.00246       0.0658        0.366         4.85       0.0847
Wall time: 398.6863003310282

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7   100       0.0465       0.0455      0.00105        0.312         3.07       0.0525
      7   200       0.0471       0.0466     0.000502        0.316         2.47       0.0341
      7   300       0.0502       0.0496     0.000647        0.311         2.05       0.0339
      7   400       0.0693       0.0667      0.00254        0.378         8.51       0.0943
      7   401       0.0616       0.0564       0.0052        0.329         4.37        0.129

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      7    51       0.0467       0.0465      0.00014        0.318         1.81       0.0197


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               7  457.360    0.005       0.0517      0.00128        0.053        0.323         3.22       0.0522
! Validation          7  457.360    0.005       0.0453     0.000475       0.0458        0.306         1.92       0.0279
Wall time: 457.35988782695495
! Best model        7    0.028

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8   100       0.0566       0.0563      0.00025        0.346         1.16       0.0228
      8   200        0.065       0.0634      0.00154        0.364         4.21       0.0535
      8   300        0.048       0.0459      0.00209        0.301         4.34       0.0848
      8   400       0.0466       0.0459     0.000679        0.305         2.08       0.0435
      8   401       0.0303       0.0302     7.79e-05        0.257        0.814        0.017

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      8    51       0.0529       0.0517      0.00117         0.33         5.53       0.0574


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               8  516.970    0.005       0.0505      0.00154       0.0521         0.32         3.43       0.0571
! Validation          8  516.970    0.005         0.05      0.00322       0.0533        0.323         4.37       0.0822
Wall time: 516.9705405109562

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9   100        0.053       0.0526     0.000385        0.328         1.69       0.0312
      9   200       0.0357       0.0353     0.000397        0.267         1.92       0.0335
      9   300       0.0542       0.0476      0.00656        0.307         5.91       0.0687
      9   400       0.0459       0.0449        0.001        0.291         3.04       0.0484
      9   401       0.0416       0.0416     6.52e-05        0.309        0.675       0.0141

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
      9    51       0.0483       0.0473     0.000983        0.323         5.86       0.0588


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train               9  576.407    0.005       0.0474      0.00123       0.0487         0.31         3.07       0.0497
! Validation          9  576.407    0.005       0.0468      0.00101       0.0478        0.312         3.37       0.0541
Wall time: 576.4072620880324

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10   100       0.0565       0.0558     0.000757        0.341         3.52       0.0422
     10   200       0.0386       0.0383     0.000255        0.292         1.44       0.0255
     10   300       0.0535       0.0528     0.000668        0.329         2.82       0.0386
     10   400       0.0422        0.042     0.000238        0.294        0.985       0.0221
     10   401       0.0431       0.0412      0.00196        0.298         6.19       0.0857

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     10    51       0.0447       0.0445     0.000198         0.31         2.43       0.0219


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              10  637.546    0.005       0.0509       0.0014       0.0523        0.323         3.28       0.0545
! Validation         10  637.546    0.005        0.045     0.000458       0.0455        0.307         1.87       0.0306
Wall time: 637.5465065930039

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11   100       0.0376       0.0367     0.000881        0.278         2.13       0.0494
     11   200       0.0431       0.0421     0.000933        0.294         2.73       0.0538
     11   300       0.0469       0.0465     0.000332        0.312          2.5       0.0279
     11   400       0.0617         0.06      0.00168        0.329         3.63        0.066
     11   401       0.0223       0.0217     0.000557        0.222         2.18       0.0453

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     11    51       0.0519       0.0494      0.00248        0.326         9.72       0.0939


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              11  695.433    0.005       0.0468      0.00122        0.048        0.311         3.16       0.0523
! Validation         11  695.433    0.005       0.0472      0.00225       0.0494        0.313          5.2       0.0868
Wall time: 695.4329731869511

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12   100       0.0441       0.0402      0.00393        0.292          5.6        0.113
     12   200       0.0405       0.0402     0.000288        0.287         1.53       0.0261
     12   300        0.048       0.0467      0.00127        0.294         4.02       0.0671
     12   400       0.0487       0.0479     0.000834        0.317         3.28       0.0474
     12   401       0.0326       0.0299      0.00265        0.249          3.7       0.0992

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     12    51       0.0417       0.0415     0.000229        0.303         2.69       0.0252


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              12  754.395    0.005        0.045      0.00132       0.0463        0.302         3.31       0.0546
! Validation         12  754.395    0.005       0.0414     0.000327       0.0417        0.294         1.65       0.0266
Wall time: 754.3950197820086
! Best model       12    0.027

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13   100       0.0374       0.0372     0.000255        0.274         1.28       0.0248
     13   200       0.0658       0.0562      0.00956        0.333         10.8        0.183
     13   300       0.0346       0.0344     0.000275        0.266         1.54       0.0249
     13   400       0.0408       0.0404      0.00038        0.296         3.08       0.0297
     13   401        0.065       0.0646     0.000412        0.386         3.06       0.0392

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     13    51       0.0502       0.0491      0.00116        0.327         6.16       0.0612


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              13  812.770    0.005       0.0435      0.00118       0.0447        0.297         2.95       0.0481
! Validation         13  812.770    0.005       0.0495      0.00198       0.0515        0.322         3.81       0.0712
Wall time: 812.770315180067

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14   100       0.0345       0.0339     0.000671        0.272         2.39        0.045
     14   200       0.0435       0.0431     0.000421        0.282         1.95        0.029
     14   300       0.0414       0.0404      0.00103        0.279         2.63       0.0545
     14   400       0.0533       0.0524     0.000967        0.327         2.26       0.0508
     14   401       0.0414       0.0404     0.000968        0.307         5.65       0.0589

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     14    51       0.0403       0.0398     0.000469        0.292          3.7       0.0363


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              14  871.236    0.005       0.0426       0.0011       0.0437        0.293         2.96       0.0484
! Validation         14  871.236    0.005       0.0383     0.000512       0.0388        0.281         2.23       0.0366
Wall time: 871.2358357480261

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15   100       0.0484       0.0481     0.000229        0.307         1.74       0.0231
     15   200       0.0348       0.0343     0.000425         0.27         2.05       0.0371
     15   300       0.0498       0.0483       0.0014        0.301         3.01       0.0379
     15   400       0.0416       0.0414     0.000236        0.298         1.82       0.0214
     15   401        0.018        0.018     7.05e-05        0.187        0.558       0.0157

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     15    51       0.0397        0.039     0.000727        0.292         4.68       0.0474


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              15  929.390    0.005       0.0401     0.000729       0.0408        0.285         2.42       0.0395
! Validation         15  929.390    0.005        0.038     0.000906       0.0389        0.281         3.05       0.0479
Wall time: 929.390720320167

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16   100       0.0447       0.0445     0.000218        0.302         2.25       0.0255
     16   200       0.0322       0.0313     0.000943        0.257         3.01       0.0487
     16   300       0.0379       0.0375     0.000367        0.268         1.81       0.0337
     16   400       0.0329       0.0327     0.000134        0.253        0.811       0.0168
     16   401      0.00395      0.00343     0.000517       0.0878         1.23       0.0439

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     16    51       0.0468       0.0435      0.00329        0.309         11.3        0.108


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              16  986.980    0.005       0.0379     0.000737       0.0386        0.277         2.49       0.0403
! Validation         16  986.980    0.005       0.0448        0.004       0.0488        0.307         6.27        0.113
Wall time: 986.9807505260687

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17   100       0.0419       0.0417      0.00015        0.286          1.1       0.0192
     17   200       0.0363        0.036     0.000371        0.269         1.84       0.0335
     17   300       0.0332        0.032      0.00123        0.262         2.68        0.063
     17   400       0.0375       0.0373     0.000231        0.261         1.58       0.0241
     17   401       0.0307       0.0296      0.00113        0.227         2.54       0.0604

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     17    51       0.0368       0.0364      0.00034         0.28         2.77       0.0313


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              17 1045.298    0.005       0.0367     0.000702       0.0374        0.273         2.43       0.0393
! Validation         17 1045.298    0.005       0.0363     0.000647       0.0369        0.276         2.37       0.0388
Wall time: 1045.2979683361482

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18   100       0.0288       0.0286     0.000206        0.247         1.22       0.0215
     18   200       0.0336       0.0335     9.64e-05        0.268         1.37       0.0139
     18   300       0.0411       0.0391      0.00197        0.286         3.15       0.0413
     18   400       0.0411        0.041     0.000128        0.289         1.24       0.0159
     18   401       0.0185       0.0182     0.000347        0.188         1.38       0.0359

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     18    51       0.0387       0.0377      0.00103        0.287         5.84       0.0584


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              18 1152.681    0.005        0.037     0.000725       0.0378        0.274         2.46       0.0398
! Validation         18 1152.681    0.005       0.0351       0.0014       0.0365        0.269            4       0.0679
Wall time: 1152.6809951420873

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19   100       0.0287       0.0286     0.000126        0.245        0.889       0.0184
     19   200       0.0303       0.0299     0.000432        0.238         1.31       0.0364
     19   300       0.0342       0.0336       0.0006        0.267         2.58       0.0444
     19   400       0.0279       0.0273     0.000632        0.242         2.35        0.039
     19   401         0.04       0.0397      0.00027        0.289         2.59         0.03

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     19    51       0.0411       0.0407     0.000409        0.298         3.58       0.0361


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              19 1212.961    0.005       0.0355     0.000656       0.0361        0.268         2.31        0.038
! Validation         19 1212.961    0.005       0.0375     0.000487        0.038        0.279         2.14       0.0336
Wall time: 1212.9617371500935

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20   100       0.0329       0.0303      0.00263        0.242          5.3       0.0955
     20   200       0.0301       0.0299     0.000161        0.241        0.998       0.0197
     20   300       0.0401       0.0397     0.000475        0.281         2.48       0.0385
     20   400       0.0345       0.0344     0.000128        0.265         1.25       0.0182
     20   401       0.0405       0.0405     2.38e-05        0.282        0.988      0.00866

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     20    51       0.0333       0.0323      0.00108        0.265         6.17       0.0613


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              20 1272.434    0.005       0.0346     0.000672       0.0352        0.265         2.27       0.0376
! Validation         20 1272.434    0.005       0.0317       0.0017       0.0334        0.254         4.58       0.0744
Wall time: 1272.4348099939525

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21   100       0.0276       0.0272      0.00031        0.245         1.64       0.0292
     21   200       0.0374       0.0371     0.000285        0.282         1.59       0.0277
     21   300       0.0296       0.0295     0.000131        0.246         1.25       0.0188
     21   400       0.0363       0.0362     5.77e-05        0.278         0.86       0.0114
     21   401       0.0056       0.0045      0.00111       0.0814         1.79       0.0638

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     21    51       0.0327       0.0318     0.000957        0.263         5.89       0.0563


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              21 1330.254    0.005       0.0327     0.000411       0.0331        0.257         1.84       0.0297
! Validation         21 1330.254    0.005       0.0319     0.000722       0.0327        0.256         2.79       0.0466
Wall time: 1330.2542876100633

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22   100       0.0318       0.0315     0.000233        0.248        0.997       0.0196
     22   200       0.0337       0.0335     0.000224        0.265         1.34       0.0244
     22   300       0.0355       0.0353     0.000149        0.273        0.726       0.0192
     22   400       0.0395       0.0381      0.00132        0.274         4.94        0.062
     22   401       0.0342       0.0338     0.000436        0.272         1.91       0.0399

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     22    51       0.0434       0.0433     0.000126        0.306         1.46       0.0175


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              22 1389.019    0.005       0.0366      0.00136       0.0379        0.271         2.98       0.0497
! Validation         22 1389.019    0.005       0.0393     0.000241       0.0396        0.282         1.35       0.0225
Wall time: 1389.0189905960578
! Best model       22    0.022

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23   100       0.0245        0.024     0.000511        0.225         1.58       0.0379
     23   200       0.0559       0.0554     0.000423        0.338         1.66       0.0311
     23   300       0.0345       0.0336     0.000928        0.267         3.45       0.0526
     23   400       0.0462       0.0457     0.000482        0.309         2.25        0.038
     23   401        0.015       0.0135      0.00148        0.159          2.9       0.0689

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     23    51       0.0759       0.0675      0.00842         0.38         17.9        0.174


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              23 1447.194    0.005       0.0395      0.00139       0.0409        0.281         3.19       0.0543
! Validation         23 1447.194    0.005       0.0593       0.0119       0.0712        0.346         10.9        0.196
Wall time: 1447.1940686651506

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24   100        0.034       0.0336     0.000463        0.265         1.99       0.0371
     24   200       0.0302       0.0301     0.000122        0.253         1.12       0.0174
     24   300       0.0356       0.0355     8.66e-05        0.271         0.73        0.015
     24   400       0.0344       0.0334      0.00096        0.265         3.34       0.0559
     24   401       0.0264       0.0257     0.000705        0.215         1.63       0.0477

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     24    51       0.0496       0.0446      0.00504        0.313         14.1        0.135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              24 1505.170    0.005       0.0383     0.000892       0.0392        0.276         2.66       0.0445
! Validation         24 1505.170    0.005       0.0459      0.00555       0.0515        0.308         7.96        0.138
Wall time: 1505.1706146360375

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25   100       0.0348       0.0341     0.000657        0.265         2.57       0.0424
     25   200       0.0306       0.0298     0.000832        0.253         3.09       0.0501
     25   300       0.0316       0.0313     0.000273        0.256         1.94       0.0212
     25   400       0.0406       0.0399      0.00071        0.285         2.72       0.0453
     25   401       0.0415       0.0414     0.000117        0.299         1.71       0.0194

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     25    51       0.0361       0.0347      0.00135        0.274         6.95       0.0655


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              25 1563.810    0.005       0.0337     0.000694       0.0344        0.261         2.33       0.0389
! Validation         25 1563.810    0.005       0.0338      0.00107       0.0348        0.264         3.44       0.0574
Wall time: 1563.8106831470504

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26   100       0.0356       0.0351     0.000516        0.268         2.28       0.0374
     26   200       0.0339       0.0326      0.00131         0.25         3.38       0.0628
     26   300       0.0338       0.0335     0.000283        0.256         1.81       0.0266
     26   400       0.0388        0.038     0.000787        0.282         2.77       0.0494
     26   401       0.0181       0.0174     0.000631        0.187         3.08       0.0484

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     26    51       0.0391        0.039     0.000156         0.29          1.4       0.0172


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              26 1622.282    0.005        0.033     0.000593       0.0336        0.259          2.2       0.0365
! Validation         26 1622.282    0.005       0.0364     0.000243       0.0366        0.274          1.4       0.0223
Wall time: 1622.282510843128
! Best model       26    0.022

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27   100        0.029       0.0288     0.000177        0.248         1.46       0.0217
     27   200       0.0386       0.0378     0.000775        0.281         2.03       0.0286
     27   300       0.0352       0.0347     0.000475        0.274         3.72       0.0367
     27   400       0.0498       0.0426      0.00715        0.294         8.97        0.157
     27   401        0.102        0.101      0.00137        0.454         5.82       0.0648

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     27    51       0.0368       0.0356      0.00122        0.279         6.73       0.0646


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              27 1680.784    0.005       0.0331     0.000853        0.034        0.258         2.36       0.0396
! Validation         27 1680.784    0.005       0.0338      0.00142       0.0352        0.263         4.23       0.0675
Wall time: 1680.7846823991276

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28   100       0.0315       0.0306     0.000899        0.252         3.66       0.0538
     28   200       0.0364        0.036     0.000378        0.265          1.8       0.0322
     28   300       0.0307       0.0305     0.000238        0.252         1.69       0.0262
     28   400       0.0357       0.0351     0.000599        0.245         1.99       0.0375
     28   401       0.0223       0.0222     0.000164        0.219         2.02        0.023

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     28    51       0.0314       0.0312     0.000208         0.26         1.68       0.0207


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              28 1738.739    0.005       0.0335     0.000662       0.0342         0.26         2.22        0.037
! Validation         28 1738.739    0.005       0.0305     0.000288       0.0308        0.252          1.6       0.0236
Wall time: 1738.7397482299712

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29   100       0.0334       0.0318      0.00159        0.241         3.46       0.0551
     29   200       0.0346       0.0344     0.000247        0.267         1.04       0.0238
     29   300        0.027       0.0268     0.000123        0.231        0.924       0.0174
     29   400       0.0283       0.0282     0.000135        0.239        0.997       0.0198
     29   401       0.0391       0.0381     0.000988        0.281         3.67       0.0602

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     29    51         0.03       0.0295     0.000535        0.253         4.26       0.0411


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              29 1796.603    0.005       0.0316     0.000607       0.0322        0.253         2.25       0.0373
! Validation         29 1796.603    0.005        0.028     0.000446       0.0285        0.239         2.06       0.0346
Wall time: 1796.6031914909836

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30   100       0.0923       0.0802       0.0121        0.411         11.8        0.205
     30   200       0.0361       0.0359     0.000168        0.272         2.23        0.019
     30   300        0.028       0.0276     0.000387        0.232            2       0.0338
     30   400       0.0294       0.0284      0.00102         0.24         2.28       0.0488
     30   401       0.0508       0.0508     2.71e-05        0.308        0.761      0.00946

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     30    51       0.0346       0.0344     0.000214        0.275         1.91       0.0187


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              30 1854.133    0.005       0.0371      0.00157       0.0387        0.271         2.69       0.0447
! Validation         30 1854.133    0.005       0.0335     0.000289       0.0338        0.264         1.43       0.0243
Wall time: 1854.1337743310723

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31   100       0.0317       0.0315     0.000214        0.258         1.13       0.0227
     31   200       0.0267       0.0265     0.000158        0.237         1.05       0.0205
     31   300       0.0374       0.0352      0.00224        0.256         4.74       0.0891
     31   400       0.0278       0.0276     0.000138        0.232        0.744       0.0187
     31   401       0.0279       0.0274     0.000523        0.251         2.12       0.0442

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     31    51       0.0307       0.0302     0.000415        0.257         2.99       0.0312


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              31 1912.149    0.005       0.0326      0.00061       0.0332        0.256          2.2       0.0364
! Validation         31 1912.149    0.005       0.0291     0.000635       0.0297        0.244         2.44       0.0402
Wall time: 1912.1493118191138

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32   100       0.0302         0.03     0.000163        0.239         1.14       0.0187
     32   200       0.0321       0.0316      0.00051        0.254         2.29        0.037
     32   300       0.0439       0.0351      0.00877        0.266         9.98        0.174
     32   400       0.0366       0.0365     0.000142        0.261        0.982       0.0199
     32   401       0.0299       0.0297     0.000262        0.254         1.26       0.0263

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     32    51       0.0302       0.0301     0.000157        0.256         1.87       0.0208


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              32 1970.462    0.005        0.033     0.000596       0.0336        0.257         2.15       0.0355
! Validation         32 1970.462    0.005        0.029     0.000203       0.0292        0.244         1.28       0.0205
Wall time: 1970.461912570987
! Best model       32    0.021

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33   100       0.0442       0.0439     0.000261         0.28         1.49        0.025
     33   200       0.0354       0.0347     0.000736        0.267          3.3        0.047
     33   300        0.032       0.0319     0.000141        0.254         0.93       0.0187
     33   400       0.0347       0.0345      0.00016        0.267        0.935       0.0171
     33   401        0.042       0.0405      0.00148        0.304         5.45       0.0741

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     33    51       0.0303       0.0296     0.000694        0.255         4.73       0.0462


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              33 2028.329    0.005       0.0336     0.000663       0.0343        0.261         2.28       0.0374
! Validation         33 2028.329    0.005       0.0285     0.000623       0.0292        0.242         2.56       0.0436
Wall time: 2028.3290643759537

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34   100       0.0296       0.0295     0.000154        0.244         1.04       0.0202
     34   200       0.0398       0.0365      0.00329        0.278         5.47        0.109
     34   300       0.0289       0.0288     8.22e-05        0.239         0.79        0.014
     34   400        0.041       0.0394      0.00152        0.285         4.23       0.0719
     34   401       0.0372       0.0343      0.00289        0.271         10.8        0.103

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     34    51        0.029       0.0289     5.87e-05        0.252        0.944       0.0134


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              34 2086.071    0.005       0.0312      0.00056       0.0318        0.251         2.12       0.0348
! Validation         34 2086.071    0.005       0.0289     0.000197       0.0291        0.244         1.24       0.0198
Wall time: 2086.071422177134
! Best model       34    0.020

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35   100       0.0413       0.0409     0.000316         0.29         1.16       0.0243
     35   200       0.0299       0.0297     0.000263         0.25         1.16        0.021
     35   300       0.0375       0.0367     0.000787         0.26         1.89       0.0474
     35   400       0.0231       0.0229     0.000196        0.218         1.26       0.0226
     35   401       0.0161        0.016     0.000165        0.185        0.879       0.0244

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     35    51       0.0289       0.0287     0.000167        0.253         1.87       0.0197


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              35 2144.403    0.005       0.0319      0.00065       0.0326        0.253         2.27       0.0379
! Validation         35 2144.403    0.005       0.0283     0.000148       0.0285        0.241         1.11       0.0167
Wall time: 2144.403474735096
! Best model       35    0.017

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36   100       0.0305       0.0301      0.00039        0.248         1.73       0.0254
     36   200       0.0309       0.0308     0.000155        0.257         1.22       0.0214
     36   300       0.0359       0.0356     0.000357        0.269          2.3       0.0322
     36   400       0.0296       0.0294     0.000177        0.254         1.03       0.0218
     36   401       0.0339       0.0339      2.1e-05        0.271        0.322       0.0067

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     36    51       0.0509       0.0473      0.00363        0.318         11.8        0.111


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              36 2203.637    0.005       0.0394      0.00157        0.041        0.281         3.16       0.0523
! Validation         36 2203.637    0.005       0.0507      0.00359       0.0543        0.321         5.71        0.103
Wall time: 2203.63705846807

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37   100       0.0651       0.0606      0.00447        0.357         6.07        0.116
     37   200       0.0486       0.0482     0.000403        0.314         2.29       0.0329
     37   300       0.0452        0.045     0.000257          0.3         1.43       0.0254
     37   400       0.0266       0.0264     0.000181        0.235         1.04       0.0214
     37   401       0.0251       0.0251     1.92e-05        0.219        0.277      0.00801

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     37    51       0.0354       0.0346     0.000742        0.277            5       0.0456


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              37 2262.705    0.005       0.0372     0.000978       0.0382        0.277         2.81       0.0466
! Validation         37 2262.705    0.005       0.0328     0.000521       0.0333        0.262         2.21       0.0372
Wall time: 2262.7059021899477

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38   100       0.0299       0.0284      0.00154        0.239         6.39       0.0693
     38   200        0.031       0.0306     0.000386        0.251         1.89       0.0314
     38   300       0.0416       0.0407     0.000907        0.272         2.61       0.0381
     38   400       0.0473       0.0453      0.00202        0.297         3.05       0.0362
     38   401       0.0332        0.033     0.000148         0.28         1.78       0.0222

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     38    51        0.034       0.0339     0.000155        0.274         2.22       0.0224


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              38 2321.246    0.005       0.0347     0.000931       0.0357        0.265         2.72       0.0452
! Validation         38 2321.246    0.005       0.0333     0.000327       0.0336        0.264         1.66       0.0272
Wall time: 2321.2463776229415

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39   100       0.0278       0.0262      0.00157        0.237         4.34        0.075
     39   200       0.0309       0.0307     0.000124         0.25        0.874       0.0179
     39   300       0.0331       0.0325     0.000604        0.246         1.95       0.0424
     39   400       0.0268       0.0262     0.000546        0.226         1.93       0.0409
     39   401       0.0329       0.0323     0.000566        0.261         1.48       0.0431

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     39    51        0.034       0.0336     0.000375        0.271          3.5       0.0332


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              39 2380.046    0.005       0.0317     0.000526       0.0322        0.253         2.06       0.0339
! Validation         39 2380.046    0.005       0.0312     0.000637       0.0318        0.253         2.57       0.0427
Wall time: 2380.0465744079556

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40   100         0.02         0.02     8.61e-05        0.202        0.689       0.0159
     40   200       0.0312       0.0309     0.000317        0.248         2.01       0.0306
     40   300       0.0309       0.0305      0.00038        0.252         2.12       0.0304
     40   400         0.03       0.0296      0.00041        0.245         2.25       0.0326
     40   401        0.114        0.112      0.00165        0.515         3.31       0.0689

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     40    51       0.0371       0.0369     0.000151        0.282          2.2       0.0212


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              40 2438.554    0.005       0.0321     0.000595       0.0327        0.253         2.07       0.0339
! Validation         40 2438.554    0.005       0.0338     0.000387       0.0342        0.266          1.8       0.0313
Wall time: 2438.554648622172

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41   100       0.0306       0.0298     0.000814        0.252         2.82       0.0442
     41   200       0.0311       0.0308     0.000287        0.256          1.3       0.0279
     41   300       0.0304       0.0299     0.000511         0.24         1.79       0.0398
     41   400       0.0197       0.0193     0.000393        0.195         1.51       0.0304
     41   401       0.0216       0.0214     0.000198        0.215         1.72       0.0263

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     41    51        0.037       0.0368     0.000115        0.282         1.68       0.0176


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              41 2497.307    0.005       0.0306     0.000686       0.0313        0.249         2.34       0.0388
! Validation         41 2497.307    0.005       0.0335      0.00033       0.0338         0.26         1.64       0.0283
Wall time: 2497.307020534994

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42   100       0.0272       0.0271     0.000129        0.231        0.989        0.018
     42   200       0.0283       0.0274     0.000848        0.238         2.86       0.0551
     42   300       0.0229       0.0227      0.00021         0.21         1.42       0.0243
     42   400       0.0315        0.031     0.000403        0.251         1.64       0.0257
     42   401       0.0279       0.0278     7.08e-05         0.24         1.23       0.0153

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     42    51       0.0305       0.0302     0.000335        0.259         3.42       0.0318


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              42 2555.509    0.005        0.032     0.000745       0.0328        0.253         2.46       0.0405
! Validation         42 2555.509    0.005       0.0296      0.00047       0.0301        0.246         2.32       0.0361
Wall time: 2555.5097289669793

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43   100       0.0347       0.0346     0.000101        0.262         1.19       0.0151
     43   200       0.0409       0.0402     0.000655        0.287         2.56       0.0292
     43   300        0.028       0.0278     0.000215        0.245         2.22       0.0254
     43   400        0.026       0.0259     0.000142        0.233        0.857       0.0188
     43   401       0.0433       0.0415      0.00179        0.304         3.86       0.0803

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     43    51       0.0298       0.0293     0.000411        0.254         3.58       0.0352


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              43 2613.834    0.005       0.0308     0.000469       0.0313         0.25         1.94       0.0321
! Validation         43 2613.834    0.005       0.0297      0.00028       0.0299        0.247          1.6       0.0267
Wall time: 2613.8343482669443

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44   100        0.031       0.0307     0.000234        0.252         1.93       0.0263
     44   200        0.025       0.0244     0.000587        0.225         1.82        0.024
     44   300       0.0249       0.0246      0.00032        0.227         1.96       0.0299
     44   400       0.0243       0.0242     9.95e-05        0.216        0.889       0.0166
     44   401       0.0351        0.035     0.000101        0.274         1.51       0.0194

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     44    51       0.0331       0.0327     0.000394        0.267          3.5       0.0341


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              44 2671.845    0.005       0.0295     0.000484         0.03        0.244         1.99       0.0329
! Validation         44 2671.845    0.005       0.0313     0.000275       0.0316        0.253         1.63       0.0271
Wall time: 2671.8453467229847

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45   100       0.0262        0.026     0.000131         0.23        0.861       0.0195
     45   200       0.0297       0.0292     0.000441        0.238         2.04       0.0355
     45   300       0.0286       0.0284     0.000284        0.243         1.64       0.0268
     45   400       0.0201         0.02      0.00017        0.207        0.962        0.017
     45   401       0.0212        0.021     0.000234        0.194         1.15       0.0295

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     45    51       0.0279       0.0278     0.000105        0.247         1.38       0.0152


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              45 2730.015    0.005       0.0283     0.000437       0.0287        0.239         1.91       0.0311
! Validation         45 2730.015    0.005       0.0274     0.000134       0.0276        0.236        0.939        0.016
Wall time: 2730.014977467945
! Best model       45    0.016

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46   100       0.0259       0.0258     7.87e-05        0.231        0.659       0.0144
     46   200       0.0208       0.0206     0.000154         0.21         1.21       0.0185
     46   300       0.0232       0.0229     0.000388         0.21         1.67       0.0339
     46   400       0.0299       0.0298     0.000127         0.25        0.958       0.0164
     46   401       0.0123       0.0123     3.82e-05        0.158        0.459       0.0119

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     46    51       0.0285       0.0284     0.000164         0.25         2.48       0.0219


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              46 2788.514    0.005       0.0289     0.000436       0.0293        0.241         1.76        0.029
! Validation         46 2788.514    0.005       0.0268       0.0003       0.0271        0.233         1.65       0.0259
Wall time: 2788.5143126051407

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47   100       0.0266       0.0264     0.000128        0.236         1.22       0.0181
     47   200        0.037       0.0367     0.000301        0.275         1.75       0.0286
     47   300       0.0329       0.0324     0.000485        0.254         1.65       0.0335
     47   400        0.036       0.0345      0.00148        0.263         6.28       0.0663
     47   401         0.02       0.0197     0.000306        0.211         2.09       0.0338

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     47    51        0.026       0.0259     0.000122        0.238         1.55       0.0166


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              47 2846.843    0.005       0.0271     0.000388       0.0275        0.234         1.82       0.0295
! Validation         47 2846.843    0.005       0.0254     0.000108       0.0255        0.227        0.939       0.0147
Wall time: 2846.8431361580733
! Best model       47    0.015

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48   100       0.0238       0.0235     0.000222        0.223         1.92       0.0267
     48   200       0.0308       0.0304     0.000443        0.252         2.91       0.0389
     48   300       0.0225       0.0225     7.72e-05        0.218        0.451       0.0105
     48   400       0.0255       0.0253     0.000242        0.224          1.9       0.0272
     48   401       0.0552       0.0552     1.83e-05         0.31        0.345      0.00644

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     48    51       0.0263       0.0259     0.000372        0.239         3.34       0.0344


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              48 2905.709    0.005       0.0274      0.00037       0.0278        0.236         1.76       0.0284
! Validation         48 2905.709    0.005       0.0257     0.000232        0.026        0.228          1.6       0.0252
Wall time: 2905.709513655165

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49   100       0.0228       0.0227     8.93e-05        0.216        0.705       0.0126
     49   200       0.0223       0.0223     5.84e-05         0.21         1.15       0.0131
     49   300       0.0683        0.064      0.00432        0.276          6.6        0.125
     49   400       0.0254       0.0253     5.94e-05        0.229         1.43       0.0126
     49   401       0.0394       0.0391     0.000375        0.295         1.75       0.0365

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     49    51       0.0257       0.0255     0.000149        0.237         2.11       0.0199


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              49 2964.701    0.005       0.0285     0.000429       0.0289        0.238         1.82       0.0305
! Validation         49 2964.701    0.005       0.0251     0.000404       0.0255        0.226         2.03       0.0333
Wall time: 2964.7012027259916

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50   100       0.0208       0.0182      0.00254        0.192         6.33       0.0955
     50   200       0.0253       0.0252      0.00013        0.224         1.08       0.0161
     50   300       0.0232       0.0229     0.000298        0.216         1.76       0.0305
     50   400       0.0314        0.031     0.000348        0.254         1.75       0.0303
     50   401       0.0313       0.0312     9.55e-05        0.255        0.737       0.0187

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     50    51       0.0268       0.0265     0.000316        0.241         3.01       0.0305


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              50 3022.888    0.005        0.027      0.00049       0.0275        0.233         1.88       0.0315
! Validation         50 3022.888    0.005       0.0264     0.000267       0.0267        0.232         1.49       0.0258
Wall time: 3022.888821881963

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     51   100       0.0502       0.0499     0.000314        0.268         1.63       0.0312
     51   200       0.0292       0.0288     0.000373        0.244         2.15        0.035
     51   300       0.0295       0.0292     0.000375         0.25         2.29       0.0328
     51   400       0.0344       0.0343     0.000112        0.262         1.06       0.0168
     51   401        0.035       0.0343     0.000617         0.27          4.8       0.0479

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     51    51       0.0272        0.027      0.00028        0.245         2.88        0.027


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              51 3081.448    0.005        0.031     0.000633       0.0317         0.25         2.19       0.0362
! Validation         51 3081.448    0.005       0.0266     0.000238       0.0269        0.233         1.43       0.0245
Wall time: 3081.448817049153

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     52   100       0.0344       0.0342     0.000174        0.268         1.96         0.02
     52   200       0.0267        0.026     0.000725        0.239         2.86       0.0478
     52   300       0.0315       0.0314     0.000127        0.254         1.24       0.0171
     52   400       0.0387       0.0385     0.000162        0.286         1.25       0.0217
     52   401        0.052       0.0519     5.34e-05        0.336         1.15       0.0136

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     52    51       0.0274       0.0273     8.85e-05        0.244         1.47       0.0156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              52 3139.274    0.005       0.0281     0.000412       0.0285        0.238         1.79       0.0293
! Validation         52 3139.274    0.005       0.0258     0.000263        0.026        0.228         1.49       0.0238
Wall time: 3139.2739437590353

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     53   100        0.023       0.0228     0.000192         0.21         1.62       0.0229
     53   200       0.0256       0.0255     8.43e-05        0.226        0.843       0.0131
     53   300       0.0276       0.0271     0.000486        0.237          2.9       0.0337
     53   400       0.0318       0.0314     0.000436        0.254         2.33       0.0301
     53   401       0.0246       0.0245     0.000171         0.23        0.533       0.0185

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     53    51       0.0242       0.0242     4.01e-05        0.232         1.12       0.0112


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              53 3197.671    0.005       0.0265     0.000323       0.0268        0.231         1.62       0.0265
! Validation         53 3197.671    0.005       0.0246     0.000157       0.0248        0.222         1.18       0.0173
Wall time: 3197.671362522058

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     54   100       0.0264       0.0262     0.000205        0.234         1.59        0.025
     54   200       0.0321       0.0299       0.0022        0.247         4.33       0.0514
     54   300       0.0242        0.024     0.000193         0.22         1.22       0.0236
     54   400       0.0492       0.0466      0.00269        0.316         4.35       0.0859
     54   401       0.0501       0.0438      0.00639        0.316         16.3        0.141

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     54    51       0.0469       0.0454      0.00149        0.315         6.92       0.0667


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              54 3257.416    0.005       0.0388      0.00776       0.0466        0.264         3.05       0.0497
! Validation         54 3257.416    0.005       0.0482      0.00253       0.0507        0.319         5.27       0.0757
Wall time: 3257.4160885610618

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     55   100       0.0268       0.0253       0.0015        0.226         4.84       0.0711
     55   200       0.0305       0.0302     0.000296        0.253         2.13       0.0308
     55   300       0.0354        0.035     0.000326        0.252         1.88       0.0278
     55   400        0.035       0.0348     0.000191        0.264         1.32       0.0231
     55   401       0.0168       0.0162     0.000602        0.195         3.42       0.0474

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     55    51       0.0303       0.0301     0.000176        0.256         2.03       0.0211


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              55 3315.493    0.005       0.0341     0.000621       0.0347        0.263          2.2       0.0345
! Validation         55 3315.493    0.005       0.0296      0.00025       0.0299        0.245         1.39       0.0215
Wall time: 3315.4939092430286

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     56   100       0.0364       0.0361     0.000267        0.277          2.1       0.0265
     56   200       0.0298       0.0284      0.00138        0.237         3.45       0.0701
     56   300         0.04       0.0393     0.000728        0.284          2.7       0.0466
     56   400        0.033       0.0324     0.000667        0.262          2.5       0.0431
     56   401       0.0156       0.0143      0.00132        0.164         2.11       0.0634

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     56    51       0.0274        0.027      0.00039        0.243          3.7       0.0349


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              56 3373.769    0.005        0.031     0.000512       0.0315        0.251         2.04       0.0334
! Validation         56 3373.769    0.005       0.0274     0.000315       0.0277        0.235         1.71       0.0287
Wall time: 3373.7694380781613

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     57   100       0.0381       0.0379     0.000228        0.263         1.24       0.0237
     57   200       0.0222        0.022     0.000226        0.217         1.12       0.0236
     57   300       0.0252       0.0251     4.79e-05        0.221        0.492       0.0108
     57   400       0.0311        0.031      0.00018        0.243         1.18       0.0194
     57   401       0.0246       0.0242     0.000321         0.24         1.22       0.0339

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     57    51       0.0268       0.0266     0.000191        0.243         2.64       0.0238


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              57 3431.866    0.005       0.0283     0.000405       0.0287        0.239         1.78       0.0292
! Validation         57 3431.866    0.005       0.0264     0.000426       0.0269        0.231          2.2       0.0343
Wall time: 3431.865887111053

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     58   100       0.0317        0.031     0.000695        0.248         2.88       0.0466
     58   200       0.0251       0.0246     0.000529        0.218         2.95       0.0426
     58   300       0.0271       0.0269     0.000198        0.241         1.27       0.0229
     58   400       0.0231       0.0228     0.000289        0.218         1.43       0.0291
     58   401       0.0193       0.0191     0.000274         0.18         1.25       0.0318

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     58    51       0.0267       0.0266     9.91e-05         0.24         1.52       0.0163


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              58 3490.852    0.005       0.0285     0.000533        0.029         0.24         2.06       0.0337
! Validation         58 3490.852    0.005       0.0263      0.00024       0.0265         0.23         1.42       0.0218
Wall time: 3490.8521506390534

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     59   100       0.0294        0.029      0.00044        0.247         1.73       0.0358
     59   200       0.0315       0.0306     0.000882        0.239         2.84       0.0537
     59   300       0.0296       0.0295      6.7e-05        0.245        0.999       0.0134
     59   400       0.0312       0.0307      0.00052        0.249         2.84       0.0377
     59   401       0.0348       0.0335      0.00135        0.267         3.41       0.0709

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     59    51       0.0264        0.026      0.00037         0.24          3.6       0.0346


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              59 3549.176    0.005       0.0292      0.00048       0.0297        0.242         1.97       0.0321
! Validation         59 3549.176    0.005       0.0271     0.000735       0.0279        0.237         2.99       0.0471
Wall time: 3549.175919784

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     60   100        0.033       0.0325     0.000502         0.25         2.24       0.0395
     60   200       0.0311       0.0307     0.000373        0.241         2.07       0.0311
     60   300       0.0222        0.022     0.000149        0.214        0.869       0.0198
     60   400       0.0288       0.0287     0.000123        0.236         0.88        0.019
     60   401       0.0332       0.0331     9.26e-06        0.269        0.282      0.00588

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     60    51       0.0293       0.0292     9.52e-05        0.255        0.963       0.0116


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              60 3607.428    0.005        0.031     0.000559       0.0316         0.25         2.16       0.0357
! Validation         60 3607.428    0.005       0.0286     0.000173       0.0287         0.24         1.12       0.0184
Wall time: 3607.4282188380603

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     61   100       0.0252       0.0251     0.000103        0.218        0.726       0.0175
     61   200       0.0292       0.0288     0.000413        0.237         1.76       0.0319
     61   300       0.0237       0.0236     0.000181        0.212         1.61       0.0202
     61   400       0.0214       0.0209      0.00055        0.205         1.71       0.0261
     61   401       0.0406       0.0404     0.000232        0.286         5.52       0.0286

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     61    51       0.0263       0.0262     0.000112         0.24         1.77       0.0177


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              61 3665.867    0.005       0.0286     0.000499       0.0291         0.24         2.02       0.0332
! Validation         61 3665.867    0.005        0.026     0.000268       0.0263        0.228         1.59       0.0248
Wall time: 3665.867756904103

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     62   100       0.0255       0.0248      0.00075        0.223         2.59       0.0393
     62   200       0.0309       0.0301     0.000795        0.257          2.6       0.0529
     62   300       0.0271       0.0267     0.000392         0.24         1.86       0.0348
     62   400       0.0265       0.0265     2.67e-05        0.233        0.547      0.00882
     62   401       0.0269       0.0262     0.000723        0.243          3.1        0.048

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     62    51       0.0274       0.0273     5.93e-05        0.245         1.36       0.0119


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              62 3724.883    0.005       0.0275     0.000452        0.028        0.235         1.85       0.0305
! Validation         62 3724.883    0.005       0.0262     0.000326       0.0266        0.232         1.26       0.0246
Wall time: 3724.8833379370626

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     63   100       0.0274       0.0248      0.00266        0.208         6.31       0.0991
     63   200        0.027       0.0269     8.72e-05        0.238         1.32       0.0136
     63   300       0.0225        0.022     0.000424        0.214          1.9       0.0367
     63   400        0.026       0.0257     0.000318         0.23         1.12       0.0289
     63   401       0.0326        0.032     0.000626        0.257         3.61       0.0479

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     63    51       0.0275        0.027     0.000544        0.245         4.06       0.0405


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              63 3783.332    0.005       0.0288     0.000507       0.0294        0.241         1.97       0.0326
! Validation         63 3783.332    0.005       0.0261     0.000645       0.0268        0.231         2.72       0.0446
Wall time: 3783.3324792410713

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     64   100       0.0235       0.0227      0.00079        0.219         2.45       0.0449
     64   200       0.0362        0.035      0.00127        0.268         3.84       0.0601
     64   300        0.039       0.0389     0.000145        0.275          1.5       0.0204
     64   400       0.0288       0.0287     0.000106        0.244         1.73       0.0167
     64   401       0.0404       0.0401      0.00032        0.296          9.1       0.0342

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     64    51       0.0326       0.0325     0.000182         0.27          1.7       0.0181


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              64 3842.294    0.005       0.0326     0.000794       0.0334        0.257         2.38       0.0396
! Validation         64 3842.294    0.005       0.0315     0.000226       0.0317        0.253         1.25       0.0217
Wall time: 3842.294625583105

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     65   100       0.0352       0.0343     0.000953        0.265         3.14       0.0566
     65   200        0.024       0.0239     0.000136        0.222         1.42       0.0178
     65   300       0.0269       0.0266     0.000368        0.238         1.76       0.0324
     65   400        0.024       0.0239     7.55e-05        0.217        0.586       0.0122
     65   401       0.0211       0.0207      0.00034        0.216         2.69       0.0326

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     65    51       0.0291       0.0288     0.000227        0.253         2.57       0.0256


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              65 3900.591    0.005       0.0296     0.000449       0.0301        0.247         1.89       0.0313
! Validation         65 3900.591    0.005       0.0285     0.000312       0.0289        0.244         1.48       0.0257
Wall time: 3900.591228076024

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     66   100       0.0285       0.0279      0.00059        0.237          2.8       0.0445
     66   200       0.0303       0.0225      0.00778        0.216           11        0.169
     66   300       0.0278       0.0273     0.000488        0.236         2.68       0.0407
     66   400         0.03       0.0294     0.000546        0.237         2.85       0.0365
     66   401       0.0562       0.0557     0.000538        0.338         3.48       0.0448

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     66    51       0.0258       0.0255     0.000347        0.238         3.17       0.0343


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              66 3958.555    0.005       0.0292       0.0006       0.0298        0.243         2.14       0.0354
! Validation         66 3958.555    0.005       0.0261     0.000235       0.0263         0.23         1.55       0.0256
Wall time: 3958.555599967949

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     67   100       0.0267       0.0266     0.000104        0.237        0.899       0.0177
     67   200       0.0233       0.0231     0.000222        0.215         2.03       0.0262
     67   300       0.0232       0.0228       0.0004        0.213         1.89       0.0272
     67   400       0.0405       0.0321      0.00835        0.255          9.1        0.173
     67   401       0.0288        0.027      0.00175        0.237            6       0.0781

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     67    51       0.0273        0.027     0.000244        0.243          2.9       0.0274


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              67 4016.972    0.005       0.0276      0.00049       0.0281        0.237          1.9       0.0312
! Validation         67 4016.972    0.005       0.0265     0.000401       0.0269        0.232         2.08       0.0344
Wall time: 4016.9727056680713

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     68   100       0.0316       0.0315     0.000143         0.25         1.18       0.0184
     68   200       0.0215       0.0215     6.13e-05        0.211        0.708       0.0104
     68   300       0.0271        0.027     0.000102        0.241         1.71       0.0153
     68   400       0.0277       0.0259       0.0018        0.222         4.57       0.0766
     68   401       0.0342       0.0289      0.00539        0.241         5.58        0.138

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     68    51        0.027       0.0264      0.00057        0.239         4.29       0.0444


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              68 4074.986    0.005       0.0272     0.000572       0.0278        0.234         2.06       0.0342
! Validation         68 4074.986    0.005       0.0262     0.000433       0.0266        0.231         1.99       0.0359
Wall time: 4074.985901586013

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     69   100        0.027       0.0269     0.000102        0.235         0.65       0.0137
     69   200       0.0215       0.0214     6.71e-05        0.208        0.863       0.0132
     69   300        0.024       0.0239     0.000136        0.212        0.884       0.0194
     69   400       0.0241       0.0238     0.000245        0.224         2.15        0.026
     69   401       0.0196       0.0191     0.000425        0.193         1.56       0.0394

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     69    51       0.0242        0.024     0.000121        0.231         1.78       0.0175


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              69 4132.249    0.005       0.0262      0.00043       0.0267         0.23         1.85       0.0303
! Validation         69 4132.249    0.005       0.0244     0.000121       0.0245        0.222         1.04       0.0155
Wall time: 4132.249098462053

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     70   100       0.0264       0.0262     0.000276         0.22         1.58       0.0232
     70   200       0.0244       0.0243     0.000131        0.224         1.51       0.0179
     70   300       0.0243       0.0242     0.000107        0.223         1.06        0.016
     70   400       0.0356       0.0275       0.0081        0.242           10        0.172
     70   401       0.0452       0.0378      0.00741        0.293         7.99        0.166

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     70    51       0.0369       0.0355      0.00136         0.28         7.16       0.0677


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              70 4190.575    0.005       0.0268     0.000609       0.0274        0.231         1.88       0.0314
! Validation         70 4190.575    0.005       0.0364      0.00174       0.0382        0.275         4.93       0.0758
Wall time: 4190.575565346051

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     71   100       0.0266       0.0266     7.54e-05        0.235        0.774       0.0129
     71   200       0.0266       0.0263     0.000245        0.238         1.98       0.0263
     71   300       0.0218       0.0217     6.88e-05        0.206        0.614        0.013
     71   400       0.0191       0.0184     0.000681        0.188         2.05       0.0457
     71   401       0.0425       0.0424     0.000169        0.293         1.79       0.0248

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     71    51       0.0261       0.0259     0.000228        0.239         2.81       0.0277


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              71 4248.102    0.005       0.0285      0.00054        0.029        0.236         1.91       0.0313
! Validation         71 4248.102    0.005       0.0248     0.000187        0.025        0.224         1.39       0.0217
Wall time: 4248.1020217379555

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     72   100       0.0222       0.0218     0.000329         0.21          1.7       0.0306
     72   200         0.03       0.0295     0.000486        0.248         1.18       0.0246
     72   300       0.0384        0.038      0.00038        0.285          3.3       0.0295
     72   400       0.0185       0.0183     0.000222        0.193        0.846       0.0223
     72   401        0.056       0.0547      0.00127        0.323         4.57        0.069

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     72    51       0.0294       0.0287     0.000624        0.252         4.69       0.0453


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              72 4306.856    0.005       0.0304      0.00125       0.0317        0.244         2.28       0.0377
! Validation         72 4306.856    0.005       0.0288     0.000808       0.0296        0.244         3.21       0.0506
Wall time: 4306.855995254125

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     73   100       0.0216       0.0215      0.00011        0.215        0.772       0.0167
     73   200       0.0308       0.0302     0.000618        0.258         2.51       0.0451
     73   300       0.0295       0.0291     0.000476        0.245         1.55       0.0347
     73   400       0.0281        0.028     8.49e-05        0.249        0.781       0.0153
     73   401        0.013       0.0127     0.000269        0.166         1.18       0.0317

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     73    51       0.0286       0.0284     0.000169         0.25         1.87       0.0223


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              73 4364.216    0.005       0.0304     0.000524       0.0309        0.247         1.82       0.0304
! Validation         73 4364.216    0.005       0.0279     0.000511       0.0284        0.241         2.06       0.0357
Wall time: 4364.216585783986

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     74   100       0.0264       0.0263      0.00013        0.235        0.811       0.0159
     74   200       0.0274       0.0272     0.000128        0.224        0.589       0.0166
     74   300       0.0268       0.0265     0.000333        0.236         2.04       0.0312
     74   400       0.0397       0.0396     8.15e-05        0.281        0.879       0.0143
     74   401       0.0298       0.0276      0.00223        0.247         4.38       0.0912

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     74    51       0.0323       0.0317     0.000581        0.266         4.57       0.0413


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              74 4422.507    0.005       0.0297     0.000712       0.0305        0.246         2.26       0.0381
! Validation         74 4422.507    0.005       0.0321     0.000695       0.0328        0.258         2.63       0.0455
Wall time: 4422.507761730114

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     75   100       0.0293       0.0268      0.00255        0.239         4.95       0.0955
     75   200       0.0318       0.0315     0.000303        0.253         1.99       0.0271
     75   300       0.0326       0.0322     0.000323        0.262         2.21         0.03
     75   400       0.0363       0.0361     0.000277        0.267         1.13       0.0234
     75   401       0.0305         0.03     0.000442        0.266         1.94       0.0404

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     75    51         0.04       0.0343      0.00573        0.274         14.9        0.144


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              75 4480.707    0.005        0.032      0.00113       0.0331        0.253         2.68       0.0452
! Validation         75 4480.707    0.005       0.0352      0.00547       0.0407        0.271         8.09         0.14
Wall time: 4480.7070253321435

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     76   100       0.0172       0.0168     0.000405        0.181         1.43        0.034
     76   200       0.0278       0.0268     0.000954        0.238         2.85        0.036
     76   300       0.0305       0.0299     0.000586        0.248         4.25       0.0419
     76   400       0.0269       0.0267     0.000191         0.24         1.13       0.0222
     76   401       0.0352       0.0348     0.000402        0.274         1.86       0.0387

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     76    51       0.0258       0.0258     2.57e-05        0.242        0.888      0.00845


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              76 4538.218    0.005       0.0276     0.000457        0.028        0.237         1.86       0.0307
! Validation         76 4538.218    0.005       0.0266     0.000175       0.0268        0.234         1.21       0.0187
Wall time: 4538.218576794025

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     77   100        0.022       0.0213     0.000695        0.211         2.87         0.05
     77   200       0.0236        0.023     0.000569        0.214         2.68       0.0435
     77   300       0.0315       0.0303       0.0012        0.235          2.9       0.0617
     77   400       0.0251       0.0242     0.000897        0.214          3.1       0.0555
     77   401       0.0287       0.0282     0.000464        0.232         4.03       0.0395

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     77    51       0.0257       0.0256     0.000137        0.237         1.98       0.0188


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              77 4596.864    0.005        0.027     0.000502       0.0275        0.235         2.02       0.0337
! Validation         77 4596.864    0.005       0.0258     0.000193       0.0259         0.23         1.24       0.0216
Wall time: 4596.864755303133

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     78   100       0.0291       0.0267      0.00238        0.226         4.82        0.089
     78   200       0.0208       0.0207     9.38e-05        0.207        0.837       0.0158
     78   300       0.0374       0.0367     0.000773        0.262         3.13        0.033
     78   400       0.0255       0.0254     4.02e-05        0.226        0.517       0.0108
     78   401       0.0338       0.0334     0.000367        0.237         4.78       0.0365

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     78    51       0.0254       0.0251     0.000345        0.235          3.3       0.0331


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              78 4654.122    0.005       0.0262     0.000504       0.0267         0.23         2.01       0.0333
! Validation         78 4654.122    0.005       0.0247      0.00038        0.025        0.223         1.84        0.032
Wall time: 4654.122488353169

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     79   100       0.0331       0.0328     0.000272        0.248          1.4       0.0272
     79   200       0.0265       0.0264       0.0001        0.227         1.42       0.0161
     79   300       0.0216       0.0214     0.000213        0.214          1.1       0.0246
     79   400        0.024       0.0235     0.000468        0.218         2.31       0.0389
     79   401      0.00224      0.00165     0.000589       0.0619         1.31       0.0469

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     79    51       0.0242       0.0242     4.23e-05        0.231        0.843       0.0103


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              79 4712.678    0.005       0.0256     0.000485       0.0261        0.228         1.92       0.0321
! Validation         79 4712.678    0.005       0.0242     0.000151       0.0244        0.221         1.07       0.0184
Wall time: 4712.678561476059

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     80   100       0.0187       0.0185      0.00018        0.188         1.02       0.0209
     80   200       0.0196       0.0194     0.000148        0.194         1.36       0.0198
     80   300       0.0166       0.0165     9.54e-05         0.18        0.648       0.0167
     80   400       0.0241       0.0236     0.000478        0.224         2.37       0.0385
     80   401       0.0277       0.0275      0.00019        0.225         2.15       0.0259

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     80    51       0.0252       0.0247     0.000533        0.232         4.11       0.0416


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              80 4772.339    0.005       0.0257     0.000467       0.0262        0.227         1.95       0.0324
! Validation         80 4772.339    0.005       0.0238     0.000417       0.0242        0.219         2.07        0.036
Wall time: 4772.339124121005

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     81   100       0.0314       0.0309     0.000502         0.25         1.79       0.0231
     81   200        0.027       0.0269     0.000114        0.229        0.976       0.0186
     81   300       0.0211       0.0205     0.000618        0.208         2.29       0.0471
     81   400       0.0233       0.0232     9.93e-05        0.216         0.84       0.0171
     81   401        0.024       0.0239     0.000118        0.231          2.6        0.019

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     81    51       0.0239       0.0239     7.01e-05        0.231         1.18       0.0126


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              81 4832.245    0.005       0.0251      0.00042       0.0255        0.225         1.83       0.0304
! Validation         81 4832.245    0.005       0.0248     0.000119       0.0249        0.225         1.01       0.0147
Wall time: 4832.24506537104

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     82   100       0.0208       0.0203     0.000468          0.2         2.18       0.0367
     82   200       0.0175       0.0164      0.00105        0.184         3.01       0.0614
     82   300        0.036       0.0357      0.00031        0.258         1.39       0.0262
     82   400       0.0224        0.022     0.000375        0.212         1.97       0.0355
     82   401       0.0202       0.0198     0.000446        0.191         1.79       0.0376

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     82    51       0.0231        0.023     0.000138        0.225          1.9       0.0199


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              82 4890.180    0.005       0.0247     0.000495       0.0252        0.222         1.95       0.0326
! Validation         82 4890.180    0.005       0.0229     0.000141        0.023        0.215         1.09       0.0187
Wall time: 4890.180843865033

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     83   100       0.0252        0.025     0.000171        0.224         1.59       0.0192
     83   200       0.0238       0.0236     0.000174        0.217          1.3        0.023
     83   300       0.0176       0.0174     0.000163        0.191        0.965       0.0195
     83   400       0.0251       0.0249     0.000141        0.224        0.877       0.0184
     83   401        0.042        0.042     6.31e-06         0.31        0.374      0.00374

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     83    51       0.0233       0.0233     4.49e-05        0.227        0.763      0.00976


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              83 4949.202    0.005        0.025     0.000371       0.0254        0.224         1.69        0.028
! Validation         83 4949.202    0.005       0.0234     9.12e-05       0.0235        0.218        0.829       0.0132
Wall time: 4949.201971068047
! Best model       83    0.013

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     84   100       0.0211       0.0208     0.000275        0.203         1.72       0.0284
     84   200       0.0233       0.0232     0.000109        0.209         0.72       0.0169
     84   300       0.0316       0.0311     0.000483        0.254         3.08        0.027
     84   400       0.0311        0.031     0.000121         0.25         1.05       0.0176
     84   401       0.0261       0.0255     0.000604        0.231         2.27       0.0474

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     84    51         0.03       0.0279      0.00212        0.246         8.73       0.0868


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              84 5006.773    0.005       0.0254     0.000365       0.0257        0.227         1.74       0.0284
! Validation         84 5006.773    0.005       0.0279      0.00185       0.0298        0.239         4.64       0.0804
Wall time: 5006.773356882157

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     85   100       0.0203       0.0202     0.000106        0.202        0.788       0.0156
     85   200       0.0277       0.0267      0.00101        0.231         3.22       0.0534
     85   300       0.0214       0.0211     0.000271        0.204         1.78       0.0298
     85   400        0.025       0.0247     0.000246        0.227         1.57       0.0224
     85   401       0.0176       0.0174     0.000201         0.19        0.878       0.0256

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     85    51       0.0235       0.0234     6.75e-05        0.228         1.07       0.0115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              85 5065.254    0.005       0.0242     0.000339       0.0245         0.22         1.63        0.027
! Validation         85 5065.254    0.005       0.0238     0.000177        0.024        0.219         1.21       0.0204
Wall time: 5065.254085347988

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     86   100       0.0256       0.0254     0.000174        0.208         1.32       0.0227
     86   200       0.0272       0.0261      0.00119        0.232         5.02       0.0651
     86   300       0.0263       0.0262     7.44e-05        0.238        0.761       0.0107
     86   400       0.0197       0.0195     0.000173        0.199         1.09       0.0214
     86   401      0.00434      0.00427      6.9e-05       0.0975        0.447        0.016

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     86    51       0.0282       0.0279     0.000335        0.244         3.45       0.0335


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              86 5123.475    0.005       0.0254     0.000465       0.0259        0.226         1.97       0.0326
! Validation         86 5123.475    0.005       0.0268     0.000331       0.0272        0.233         1.73       0.0307
Wall time: 5123.475513563026

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     87   100       0.0235       0.0226     0.000826        0.217         2.82       0.0529
     87   200       0.0222       0.0218     0.000379         0.21         1.76       0.0342
     87   300       0.0202       0.0201     0.000103        0.202         0.71        0.016
     87   400       0.0227       0.0226     9.51e-05         0.21        0.825       0.0167
     87   401       0.0116       0.0101      0.00147        0.145         2.28       0.0679

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     87    51       0.0252       0.0249     0.000359        0.231         3.46       0.0339


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              87 5182.798    0.005       0.0253     0.000354       0.0256        0.224          1.7       0.0281
! Validation         87 5182.798    0.005        0.024     0.000248       0.0243        0.218         1.58       0.0264
Wall time: 5182.798463735962

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     88   100       0.0307       0.0305     0.000261        0.245         1.68       0.0282
     88   200       0.0247       0.0245     0.000206        0.217         1.23       0.0262
     88   300       0.0311       0.0309     0.000157        0.255         1.33       0.0191
     88   400       0.0307       0.0302     0.000566        0.251         2.39       0.0435
     88   401       0.0449        0.044     0.000877        0.278         4.66        0.055

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     88    51        0.026       0.0256     0.000331        0.238         3.19       0.0324


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              88 5242.118    0.005       0.0254     0.000345       0.0257        0.226         1.69       0.0281
! Validation         88 5242.118    0.005       0.0273     0.000339       0.0276        0.237         1.69       0.0305
Wall time: 5242.118702856125

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     89   100       0.0176       0.0176     3.89e-05        0.189        0.462       0.0101
     89   200       0.0272        0.027     0.000167        0.234         1.78       0.0223
     89   300       0.0257       0.0256      9.1e-05        0.226         1.25       0.0151
     89   400       0.0234       0.0232      0.00023        0.214          1.2       0.0236
     89   401       0.0224       0.0222     0.000195        0.199         1.06       0.0264

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     89    51       0.0239       0.0235      0.00043        0.227          3.7       0.0381


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              89 5300.326    0.005       0.0235     0.000267       0.0237        0.217         1.46       0.0241
! Validation         89 5300.326    0.005        0.023     0.000413       0.0234        0.215         1.99       0.0351
Wall time: 5300.326743056066

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     90   100        0.026       0.0258     0.000227        0.234         1.59        0.025
     90   200       0.0262       0.0261     9.31e-05        0.233         1.41       0.0142
     90   300        0.024       0.0233     0.000684        0.219         2.76       0.0418
     90   400       0.0239       0.0238     0.000148        0.214         1.44       0.0186
     90   401        0.033       0.0328     0.000163        0.255         1.61       0.0247

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     90    51       0.0235       0.0234     0.000103        0.227         1.63       0.0157


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              90 5360.183    0.005       0.0232      0.00022       0.0234        0.216         1.35       0.0219
! Validation         90 5360.183    0.005       0.0235     0.000222       0.0238        0.218         1.22       0.0227
Wall time: 5360.183410718106

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     91   100       0.0171       0.0169     0.000232        0.182         1.01       0.0227
     91   200        0.023       0.0229     0.000154        0.214         1.22       0.0201
     91   300       0.0253       0.0248     0.000506        0.226         1.86       0.0392
     91   400       0.0202       0.0198     0.000321        0.204         1.55       0.0293
     91   401       0.0252       0.0251     7.61e-05        0.236        0.799       0.0166

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     91    51       0.0228       0.0227     0.000183        0.223         2.45       0.0231


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              91 5418.361    0.005       0.0242     0.000312       0.0245         0.22         1.56       0.0258
! Validation         91 5418.361    0.005       0.0232     0.000361       0.0235        0.214         2.12       0.0321
Wall time: 5418.361671966035

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     92   100       0.0244       0.0243     0.000139        0.212        0.804        0.021
     92   200       0.0335       0.0318      0.00169        0.246         3.34       0.0705
     92   300       0.0253       0.0251     0.000169        0.229         1.23       0.0192
     92   400       0.0242       0.0241     5.19e-05        0.215        0.741        0.012
     92   401       0.0355       0.0354     0.000144        0.275         1.73       0.0166

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     92    51       0.0222       0.0222     6.97e-05        0.221         1.28        0.013


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              92 5477.709    0.005       0.0251     0.000324       0.0254        0.222         1.61       0.0267
! Validation         92 5477.709    0.005       0.0223     0.000136       0.0224        0.211        0.938       0.0167
Wall time: 5477.709879842121

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     93   100       0.0264       0.0263     3.21e-05        0.237        0.541      0.00855
     93   200       0.0309       0.0302     0.000631        0.251         2.79       0.0315
     93   300         0.03       0.0299     0.000128        0.249        0.986       0.0171
     93   400       0.0252       0.0241      0.00111        0.219         3.15       0.0623
     93   401       0.0335       0.0307      0.00279        0.243         5.88          0.1

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     93    51       0.0244        0.024     0.000421        0.229         3.98        0.036


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              93 5534.834    0.005       0.0247     0.000368       0.0251        0.224         1.71       0.0285
! Validation         93 5534.834    0.005       0.0243     0.000683        0.025        0.222         2.73       0.0473
Wall time: 5534.834466887172

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     94   100       0.0186       0.0183     0.000339        0.192         1.71       0.0317
     94   200       0.0239       0.0239     4.19e-05         0.22        0.593         0.01
     94   300       0.0415         0.04      0.00148         0.29         4.66       0.0564
     94   400       0.0196       0.0193     0.000267        0.193         1.12       0.0288
     94   401       0.0197        0.019     0.000702        0.196         1.99       0.0509

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     94    51       0.0418       0.0408        0.001        0.295          4.5       0.0492


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              94 5593.157    0.005       0.0363       0.0064       0.0427        0.261         3.05       0.0521
! Validation         94 5593.157    0.005        0.043      0.00169       0.0447        0.296         3.22       0.0626
Wall time: 5593.157724423101

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     95   100       0.0314       0.0309     0.000435        0.241         3.25       0.0322
     95   200       0.0313       0.0311     0.000234        0.256         1.75       0.0245
     95   300       0.0359       0.0349     0.000975         0.27         4.13       0.0543
     95   400         0.03         0.03     7.56e-05         0.25        0.654       0.0137
     95   401       0.0125       0.0124     0.000104        0.157        0.713       0.0195

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     95    51       0.0254       0.0253     0.000141        0.236         1.97        0.019


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              95 5650.641    0.005       0.0283     0.000476       0.0287        0.239         2.01       0.0324
! Validation         95 5650.641    0.005       0.0255     0.000322       0.0258        0.228         1.85       0.0284
Wall time: 5650.641779233003

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     96   100       0.0249       0.0248     4.67e-05        0.225        0.516      0.00928
     96   200       0.0213       0.0212     0.000101        0.197        0.805       0.0148
     96   300       0.0257       0.0255     0.000164        0.228        0.852       0.0181
     96   400       0.0296        0.029      0.00052         0.25         3.05       0.0395
     96   401       0.0165       0.0164     1.43e-05        0.195        0.516      0.00721

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     96    51       0.0278       0.0247      0.00308        0.232         10.8        0.106


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              96 5709.335    0.005       0.0258     0.000308       0.0261        0.227         1.57       0.0254
! Validation         96 5709.335    0.005        0.025      0.00302        0.028        0.224         5.92        0.102
Wall time: 5709.335565716028

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     97   100       0.0294       0.0292     0.000269        0.246          2.1       0.0266
     97   200       0.0272       0.0268     0.000436        0.239         1.87       0.0374
     97   300       0.0353       0.0352     0.000129        0.266        0.736       0.0168
     97   400        0.024       0.0235     0.000446         0.22          1.9       0.0382
     97   401       0.0216       0.0215     0.000127        0.201        0.761       0.0213

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     97    51        0.026       0.0245      0.00154        0.233         7.87       0.0744


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              97 5768.842    0.005        0.027     0.000431       0.0274        0.233         1.85       0.0303
! Validation         97 5768.842    0.005       0.0249      0.00168       0.0266        0.224         4.18       0.0751
Wall time: 5768.842770474032

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     98   100       0.0266       0.0264      0.00021        0.232         1.34       0.0244
     98   200       0.0402       0.0401     0.000118        0.249         1.13       0.0171
     98   300        0.023       0.0229     5.12e-05        0.219         0.64       0.0114
     98   400       0.0264       0.0263     5.59e-05        0.237        0.659       0.0103
     98   401      0.00259      0.00258     3.16e-06       0.0733       0.0779      0.00278

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     98    51       0.0287       0.0285     0.000203        0.251         2.79       0.0245


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              98 5827.738    0.005       0.0262     0.000419       0.0266        0.229         1.69       0.0277
! Validation         98 5827.738    0.005       0.0268     0.000375       0.0272        0.232         1.99       0.0306
Wall time: 5827.738861269085

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     99   100       0.0266       0.0262     0.000335        0.233         1.83       0.0306
     99   200       0.0236       0.0235     6.19e-05        0.217        0.703       0.0126
     99   300       0.0251       0.0225      0.00256        0.219         6.91        0.097
     99   400       0.0171       0.0169     0.000218        0.176         1.78       0.0247
     99   401       0.0244       0.0244     2.43e-05        0.235        0.374      0.00926

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
     99    51        0.026       0.0247      0.00129        0.233         7.09       0.0685


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train              99 5885.337    0.005       0.0262     0.000402       0.0266        0.229         1.78       0.0293
! Validation         99 5885.337    0.005        0.024      0.00115       0.0252        0.221         3.65       0.0631
Wall time: 5885.337692899164

training
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
    100   100       0.0338       0.0335     0.000347        0.256         1.98       0.0316
    100   200       0.0316       0.0294      0.00213         0.25         4.44       0.0831
    100   300       0.0346       0.0345     0.000123        0.264         1.37       0.0189
    100   400       0.0249       0.0244     0.000501        0.226         2.46       0.0364
    100   401       0.0255       0.0255     5.83e-06        0.239          0.2      0.00368

validation
# Epoch batch         loss       loss_f       loss_e        f_mae        e_mae      e/N_mae
    100    51       0.0236       0.0236      3.8e-05        0.227        0.744      0.00992


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae        e_mae      e/N_mae
! Train             100 5943.095    0.005       0.0261     0.000374       0.0265        0.229          1.7        0.028
! Validation        100 5943.095    0.005       0.0239     0.000125        0.024        0.219        0.994       0.0154
Wall time: 5943.095224694116
! Stop training: max epochs
Wall time: 5943.1472136341035
Cumulative wall time: 5943.1472136341035
Testset is used.
Using all frames from the specified test dataset, yielding a test set size of 811 frames.
Starting...

--- Evaluation Time consumption: 3.215233s ---

--- Evaluation Final result: ---
               f_mae =  0.238736           
              f_rmse =  0.326470           
             N_f_mae =  0.216545           
            Si_f_mae =  0.263597           
         psavg_f_mae =  0.240071           
            N_f_rmse =  0.302362           
           Si_f_rmse =  0.351520           
        psavg_f_rmse =  0.326941           
               e_mae =  2.895758           
             e/N_mae =  0.048483           
Training QAT Model...
After QAT training...
loaded model from training session
               f_mae =  0.238736           
              f_rmse =  0.326470           
             N_f_mae =  0.216545           
            Si_f_mae =  0.263597           
         psavg_f_mae =  0.240071           
            N_f_rmse =  0.302362           
           Si_f_rmse =  0.351520           
        psavg_f_rmse =  0.326941           
               e_mae =  2.895758           
             e/N_mae =  0.048483           
